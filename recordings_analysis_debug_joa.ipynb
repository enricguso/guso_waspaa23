{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.io import wavfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.fft\n",
    "import scipy\n",
    "from scipy.signal import resample_poly\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "\n",
    "\n",
    "# import my modules (helpers.py where I stored all the functions):\n",
    "import helpers as hlp\n",
    "import importlib \n",
    "importlib.reload(hlp)\n",
    "from clarity.evaluator.hasqi import hasqi_v2\n",
    "from clarity.evaluator.haspi import haspi_v2 \n",
    "from clarity.evaluator.mbstoi import mbstoi \n",
    "import torch\n",
    "import sys\n",
    "from multiprocessing import Pool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All our directories in which we store recordings or dnn-processed recordings:\n",
    "data_source_dirs=[\n",
    "    '/home/ubuntu/Data/ha_listening_situations/recordings/ku_recordings/',\n",
    "    '/home/ubuntu/Data/ha_listening_situations/processed_m1_alldata_normal/ku_processed/',\n",
    "    '/home/ubuntu/Data/ha_listening_situations/processed_m3_alldata_mild/ku_processed/',\n",
    "    '/home/ubuntu/Data/ha_listening_situations/processed_m4_alldata_normal_causal/ku_processed/',\n",
    "    '/home/ubuntu/Data/ha_listening_situations/processed_m5_alldata_mild_causal/ku_processed/'\n",
    "]\n",
    "\n",
    "# Directory where all recordings used as reference are stored\n",
    "data_ref_dir='/home/ubuntu/Data/ha_listening_situations/recordings/ku_recordings/'\n",
    "\n",
    "# Names of hearing devices\n",
    "ha_models=[\"si3_s\",\"si3_m\",\"si3_p\",\"ph4_s\",\"ph4_m\",\"ph4_p\",\"ph5_s\",\"ph5_m\",\"ph5_p\",\n",
    "           \"gn5_l\",\"gn5_m\",\"gn5_h\",\"gn3_l\",\"gn3_m\",\"gn3_h\"]\n",
    "\n",
    "# Different listening scenes:\n",
    "scenenames=['party_0deg','party_30deg','restaurant_0deg','restaurant_30deg','meeting_0deg','meeting_30deg']\n",
    "\n",
    "# Initialize dataframe, in which each row will represent one pair of plus and minus recording\n",
    "# and all the info and objective measures associated with that pair. \n",
    "recordings_df=pd.DataFrame(columns=['device','dnn_applied','plus_file','minus_file', 'plus_ref_file','minus_ref_file', 'scene'])\n",
    "\n",
    "# initialize lists to be filled inside the loop\n",
    "dnntypes=[]\n",
    "pluses=[]\n",
    "minuses=[]\n",
    "bypass_pluses=[]\n",
    "bypass_minuses=[]\n",
    "rawku_pluses=[]\n",
    "rawku_minuses=[]\n",
    "scenes=[]\n",
    "devices=[]\n",
    "\n",
    "for i, data_source_dir in enumerate(data_source_dirs):\n",
    "    for item in sorted(os.listdir(data_source_dir)):\n",
    "        if os.path.isdir(data_source_dir+item):\n",
    "            recording_name=item\n",
    "            # this line identifies the current device name:\n",
    "            device_id=[model for model in ha_models if model in recording_name]\n",
    "            if len(device_id)>0:\n",
    "                # this line finds the corresponding bypass recording name:\n",
    "                ref_recording_name = [dirname for dirname in os.listdir(data_source_dir)\n",
    "                if os.path.isdir(data_source_dir+dirname) and device_id[0] in dirname and \"bypass\" in dirname][0]\n",
    "            else:\n",
    "                ref_recording_name=recording_name\n",
    "            \n",
    "            for scene in scenenames:\n",
    "                # paths for recorded plus and minus signals (data_source_dir + recording_name)\n",
    "                plusfilepath=data_source_dir+recording_name+'/'+recording_name+'_plus_'+scene+'.wav'\n",
    "                minusfilepath=data_source_dir+recording_name+'/'+recording_name+'_minus_'+scene+'.wav'\n",
    "                # paths for corresponding bypass plus and minus signals (data_ref_dir + ref_recording_name)\n",
    "                bypass_plusrefpath=data_ref_dir+ref_recording_name+'/'+ref_recording_name+'_plus_'+scene+'.wav'\n",
    "                bypass_minusrefpath=data_ref_dir+ref_recording_name+'/'+ref_recording_name+'_minus_'+scene+'.wav'\n",
    "                # paths for corresponding ku100 plus and minus signals \n",
    "                ku_plusrefpath=data_ref_dir+'001_ku100/001_ku100_plus_'+scene+'.wav'\n",
    "                ku_minusrefpath=data_ref_dir+'001_ku100/001_ku100_minus_'+scene+'.wav'\n",
    "                # append all lists:\n",
    "                applieddnntype=i\n",
    "                devices.append(recording_name)\n",
    "                pluses.append(plusfilepath)\n",
    "                minuses.append(minusfilepath)\n",
    "                bypass_pluses.append(bypass_plusrefpath)\n",
    "                bypass_minuses.append(bypass_minusrefpath)\n",
    "                rawku_pluses.append(ku_plusrefpath)\n",
    "                rawku_minuses.append(ku_minusrefpath)\n",
    "                scenes.append(scene)\n",
    "                dnntypes.append(applieddnntype)\n",
    "\n",
    "# fill the data frame with lists appended in the loop above:\n",
    "recordings_df['device']=devices            \n",
    "recordings_df['dnn_applied']=dnntypes\n",
    "recordings_df['plus_file']=pluses\n",
    "recordings_df['minus_file']=minuses\n",
    "recordings_df['plus_ref_bypass']=bypass_pluses\n",
    "recordings_df['minus_ref_bypass']=bypass_minuses\n",
    "recordings_df['plus_ref_ku']=rawku_pluses\n",
    "recordings_df['minus_ref_ku']=rawku_minuses\n",
    "recordings_df['scene']=scenes\n",
    "\n",
    "# Make sure to remove the lines where the \"enabled\" recording is processed and lines where ku100 recording is processed \n",
    "# (we are only interested in dnn-processed bypass recordings):\n",
    "print(f'before: {len(recordings_df)=}')\n",
    "recordings_df=recordings_df[~((recordings_df[\"device\"].str.contains(\"enabled\")) & (recordings_df[\"dnn_applied\"]>0))]\n",
    "recordings_df=recordings_df[~((recordings_df[\"device\"].str.contains(\"001_ku100\")) & (recordings_df[\"dnn_applied\"]>0))]\n",
    "recordings_df=recordings_df[~(recordings_df[\"device\"].str.contains(\"fulldenoising\"))]\n",
    "print(f'after: {len(recordings_df)=}')\n",
    "\n",
    "# Within the group that is not processed by any dnn model we have to distinguish 3 categories and give them labels: \n",
    "# ---> unprocessed reference: ku100 recordings without a hearing aid\n",
    "recordings_df.loc[recordings_df[\"device\"].str.contains(\"001_ku100\"), \"dnn_applied\"]=0.1\n",
    "# ---> unprocessed bypass: recordings with hearing aids in bypass\n",
    "recordings_df.loc[((recordings_df[\"device\"].str.contains(\"bypass\")) & (recordings_df[\"dnn_applied\"]==0)), \"dnn_applied\"]=0.2\n",
    "# ---> unprocessed enabled: recordings with hearing aids enabled\n",
    "recordings_df.loc[((recordings_df[\"device\"].str.contains(\"enabled\")) & (recordings_df[\"dnn_applied\"]==0)), \"dnn_applied\"]=0.3\n",
    "\n",
    "# Check if numbers match: \n",
    "print(f'Number of dnn-processed recordings should be {15*4*6}')\n",
    "print(len(recordings_df.loc[(recordings_df[\"dnn_applied\"]>=1)]))\n",
    "\n",
    "\n",
    "print(f'Number of enabled recordings should be {15*6}')\n",
    "print(len(recordings_df.loc[(recordings_df[\"dnn_applied\"]==0.3)])) \n",
    "\n",
    "\n",
    "print(f'Number of bypass recordings should be {15*6}')\n",
    "print(len(recordings_df.loc[(recordings_df[\"dnn_applied\"]==0.2)])) \n",
    "\n",
    "\n",
    "print(f'Number of ku100 recordings should be {6}')\n",
    "print(len(recordings_df.loc[(recordings_df[\"dnn_applied\"]==0.1)])) \n",
    "\n",
    "# Keep only recordings processed with HA or DNN\n",
    "recordings_only_processed=recordings_df[(recordings_df[\"dnn_applied\"]>0.2)]\n",
    "print(f'Number of all processed recordings should be {15*5*6}')\n",
    "print(len(recordings_only_processed))\n",
    "\n",
    "recordings_only_processed.to_csv('recordings_processed.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SISDR(s, s_hat):\n",
    "    \"\"\"Computes the Scale-Invariant SDR as in [1]_.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Le Roux, Jonathan, et al. \"SDRâ€“half-baked or well done?.\" ICASSP 2019-2019 IEEE International Conference on\n",
    "    Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2019.\n",
    "    Parameters:\n",
    "        s: list of targets of any shape\n",
    "        s_hat: list of corresponding estimates of any shape\n",
    "    \"\"\"\n",
    "    s = torch.stack(s).view(-1)\n",
    "    EPS = torch.finfo(s.dtype).eps\n",
    "    s_hat = torch.stack(s_hat).view(-1)\n",
    "    a = (torch.dot(s_hat, s) * s) / ((s ** 2).sum() + EPS)\n",
    "    b = a - s_hat\n",
    "    return 10*torch.log10(((a*a).sum()) / ((b*b).sum()+EPS))\n",
    "\n",
    "def SNRLoss(target, input):\n",
    "    EPS = torch.finfo(target.dtype).eps\n",
    "    input_mean = torch.mean(input, dim=-1, keepdim=True)\n",
    "    target_mean = torch.mean(target, dim=-1, keepdim=True)\n",
    "    input = input - input_mean\n",
    "    target = target - target_mean\n",
    "    res = input - target\n",
    "    losses = 10 * torch.log10(\n",
    "        (target ** 2).sum(-1) / ((res ** 2).sum(-1) + EPS) + EPS\n",
    "    )\n",
    "    # apply reduction\n",
    "    losses = losses.mean()\n",
    "    return losses\n",
    "\n",
    "def compute_obj_measures(idx, row, ref_method):\n",
    "    # Function: Compute objective measures based on one row of a data frame \n",
    "    # ----- Input: -----\n",
    "    # ref_method - method for computing clean reference signal\n",
    "    # idx - index in the original data frame\n",
    "    # row - row containing filenames of plus and minus recording\n",
    "    # ----- Output: -----\n",
    "    # tuple of objective measures: \n",
    "    # - snr_val: snr estimated with phase inversion technique\n",
    "    # - mbstoi_val: binaural speech intelligibility model\n",
    "    # - hasqi_left_val: hearing aid speech quality for 1 ear\n",
    "    # - hasqi_left_val: hearing aid speech perception index for 1 ear\n",
    "    # - sisdr_val: sudo-rm-rf method for computing sdr\n",
    "    # ----------------------------------------------------------------------\n",
    "    # print sth when the row is done:\n",
    "    print( \"Processing row \" +str(idx)+ \".\")\n",
    "\n",
    "    FS_TARGET=16e3\n",
    "    fs, plus = wavfile.read(row['plus_file'])\n",
    "    fs, minus = wavfile.read(row['minus_file'])\n",
    "    if fs!=16000:\n",
    "        plus = resample_poly(plus.astype(np.float32), FS_TARGET, fs)\n",
    "        minus = resample_poly(minus.astype(np.float32), FS_TARGET, fs)\n",
    "\n",
    "    \n",
    "    # ------------- Objective measure : SNR -------------\n",
    "    # plus, minus =hlp.synch_sigs(plus,minus)\n",
    "    s=0.5*(plus+minus)\n",
    "    n=0.5*(plus-minus)\n",
    "    snr_L= 10 * np.log10(hlp.power(s[:,0]) / hlp.power(n[:,0]))\n",
    "    snr_R = 10 * np.log10(hlp.power(s[:,1]) / hlp.power(n[:,1]))\n",
    "\n",
    "    # ---------- Compute clean reference signal for further methods ----------\n",
    "\n",
    "    \n",
    "    if ref_method==\"it1\":\n",
    "    # Referencing_method 1 ----> our first iteration\n",
    "        clean_ref=s\n",
    "    \n",
    "    elif ref_method==\"it2\":\n",
    "    # Referencing_method 2 ----> our second iteration \n",
    "        fs, refplus = wavfile.read(row['plus_ref_bypass'])\n",
    "        fs, refminus = wavfile.read(row['minus_ref_bypass'])\n",
    "        if fs!=16000:\n",
    "            refplus = resample_poly(refplus.astype(np.float32), FS_TARGET, fs)\n",
    "            refminus = resample_poly(refminus.astype(np.float32), FS_TARGET, fs)\n",
    "        # refplus, refminus =hlp.synch_sigs(refplus,refminus)\n",
    "        clean_ref=0.5*(refplus+refminus)\n",
    "\n",
    "    elif ref_method==\"it3\":\n",
    "    # Referencing_method 3 ----> our third iteration \n",
    "        fs, refplus = wavfile.read(row['plus_ref_ku'])\n",
    "        fs, refminus = wavfile.read(row['minus_ref_ku'])\n",
    "        if fs!=16000:\n",
    "            refplus = resample_poly(refplus.astype(np.float32), FS_TARGET, fs)\n",
    "            refminus = resample_poly(refminus.astype(np.float32), FS_TARGET, fs)\n",
    "        # refplus, refminus =hlp.synch_sigs(refplus,refminus)\n",
    "        clean_ref=0.5*(refplus+refminus)\n",
    "\n",
    "\n",
    "    # Synchronize signals \n",
    "    plus, clean_ref =hlp.synch_sigs(plus,clean_ref)\n",
    "    \n",
    "    # Equalize energy \n",
    "    nrgy_1 = (plus ** 2).sum()\n",
    "    clean_ref *= np.sqrt(nrgy_1 /((clean_ref**2).sum()))\n",
    "\n",
    "    # Save signals\n",
    "    sig2save=np.concatenate((plus,clean_ref), axis=0)\n",
    "    name2save=os.path.basename(row['plus_file'])[0:-4]\n",
    "    scipy.io.wavfile.write(\"/home/ubuntu/Data/ha_listening_situations/debug/\"+ref_method+\"_\"+name2save+\".wav\", int(FS_TARGET), sig2save)\n",
    "\n",
    "    # ------------- Objective measure : SI-SDR -------------\n",
    "    sisdr_L=SISDR([torch.from_numpy(clean_ref[:,0])],[torch.from_numpy(plus[:,0])]).item()\n",
    "    sisdr_R=SISDR([torch.from_numpy(clean_ref[:,1])],[torch.from_numpy(plus[:,1])]).item()\n",
    "    # ------------- Objective measure : SNR Losss -------------\n",
    "    snrloss_L=SNRLoss(torch.from_numpy(clean_ref[:,0]),torch.from_numpy(plus[:,0])).item() \n",
    "    snrloss_R=SNRLoss(torch.from_numpy(clean_ref[:,1]),torch.from_numpy(plus[:,1])).item() \n",
    "\n",
    "    # ------------- Objective measure : MBSTOI -------------\n",
    "    mbstoi_B = mbstoi(\n",
    "        left_ear_clean=clean_ref[:,0],\n",
    "        right_ear_clean=clean_ref[:,1],\n",
    "        left_ear_noisy=plus[:,0],\n",
    "        right_ear_noisy=plus[:,1],\n",
    "        fs_signal=FS_TARGET,  # signal sample rate\n",
    "        sample_rate=9000,  # operating sample rate\n",
    "        fft_size_in_samples=64,\n",
    "        n_third_octave_bands=5,\n",
    "        centre_freq_first_third_octave_hz=500,\n",
    "        dyn_range=60,\n",
    "    )\n",
    "    # ------------- Objective measures : HASQI and HASPI -------------\n",
    "    hearing_loss = np.array([0, 0, 0, 0, 0, 0])\n",
    "    equalisation_mode=1\n",
    "    level1=70\n",
    "    hasqi_L, _, _, _ = hasqi_v2(clean_ref[:,0], FS_TARGET, plus[:,0], FS_TARGET, hearing_loss, equalisation_mode, level1)\n",
    "    hasqi_R, _, _, _ = hasqi_v2(clean_ref[:,1], FS_TARGET, plus[:,1], FS_TARGET, hearing_loss, equalisation_mode, level1)\n",
    "    if plus[:,0].shape!=clean_ref[:,0].shape :\n",
    "        print(f'Plus and clean have different shapes for idx = {idx}')\n",
    "    haspi_L, _ = haspi_v2(clean_ref[:,0], FS_TARGET, hlp.add_signals(plus[:,0],clean_ref[:,0]) , FS_TARGET, hearing_loss, level1)\n",
    "    haspi_R, _ = haspi_v2(clean_ref[:,1], FS_TARGET, hlp.add_signals(plus[:,1],clean_ref[:,1]) , FS_TARGET, hearing_loss, level1)\n",
    "\n",
    "    return idx, snr_L, snr_R, hasqi_L, hasqi_R, haspi_L, haspi_R, sisdr_L, sisdr_R, snrloss_L, snrloss_R, mbstoi_B \n",
    "\n",
    "# Test function compute_obj_measures():\n",
    "measures=pd.read_csv('recordings_processed.csv')\n",
    "\n",
    "# idx, snr_L, snr_R, hasqi_L, hasqi_R, haspi_L, haspi_R, sisdr_L, sisdr_R, snrloss_L, snrloss_R, mbstoi_B = compute_obj_measures(120,measures.loc[120],\"it1\")\n",
    "# print(f'Measures for {measures.loc[idx,\"plus_file\"]}\\n{snr_L=}\\n{hasqi_L=}\\n{haspi_L=}\\n{sisdr_L=}\\n{snrloss_L=}\\n{mbstoi_B=}')\n",
    "\n",
    "# Multiprocessing - compute measures\n",
    "# The main script has to be in the same cell as the definition of the function\n",
    "if __name__ == '__main__':\n",
    "    NUM_OF_WORKERS = 8\n",
    "    with Pool(NUM_OF_WORKERS) as pool:\n",
    "        results = [pool.apply_async(compute_obj_measures, [idx, row, \"it1\"]) for idx, row in measures.iterrows()]\n",
    "        for result in results:\n",
    "            idx, snr_L, snr_R, hasqi_L, hasqi_R, haspi_L, haspi_R, sisdr_L, sisdr_R, snrloss_L, snrloss_R, mbstoi_B  = result.get()\n",
    "            measures.loc[idx, 'snr_L'] = snr_L\n",
    "            measures.loc[idx, 'snr_R'] = snr_R\n",
    "            measures.loc[idx, 'haspi_L'] = haspi_L\n",
    "            measures.loc[idx, 'haspi_R'] = haspi_R\n",
    "            measures.loc[idx, 'hasqi_L'] = hasqi_L\n",
    "            measures.loc[idx, 'hasqi_R'] = hasqi_R\n",
    "            measures.loc[idx, 'sisdr_L'] = sisdr_L\n",
    "            measures.loc[idx, 'sisdr_R'] = sisdr_R\n",
    "            measures.loc[idx, 'snrloss_L'] = snrloss_L\n",
    "            measures.loc[idx, 'snrloss_R'] = snrloss_R\n",
    "            measures.loc[idx, 'mbstoi_B'] = mbstoi_B\n",
    "\n",
    "measures.to_csv('bla.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log10(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures_computed=pd.read_csv('objective_measures2.csv')\n",
    "\n",
    "# For a better visibility, we add one column which specifies the hearing aid model (without division into different receivers)\n",
    "ha_models=[\"gn3\",\"gn5\",\"ph5\",\"ph4\",\"si3\"]\n",
    "for modelname in ha_models:\n",
    "    measures_computed.loc[measures_computed['device'].str.contains(modelname), \"device_group\"]=modelname\n",
    "\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "  \n",
    "# Settings the warnings to be ignored\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def plot_1_measure(df,measure):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(25, 5), sharey=True) \n",
    "    sns.set(font_scale=0.8)\n",
    "    sns.stripplot(ax=axes[1],data=df,x=\"dnn_applied\", y=measure, hue=\"device_group\")\n",
    "    sns.stripplot(ax=axes[2],data=df,x=\"dnn_applied\", y=measure, hue=\"scene\")\n",
    "    df.boxplot(ax=axes[0],column=measure,by=\"dnn_applied\")\n",
    "    axes[0].set_xlabel('')\n",
    "    axes[1].set_xlabel('')\n",
    "    axes[2].set_xlabel('')\n",
    "    axes[0].set_title('Standard boxplot')\n",
    "    axes[1].set_title('Colored by devices')\n",
    "    axes[2].set_title('Colored by scene')\n",
    "    axes[0].set_xticklabels(['HA','DNN-normal','DNN-mild','DNN-normal_C','DNN-mild_C'], rotation=45)\n",
    "    axes[1].set_xticklabels(['HA','DNN-normal','DNN-mild','DNN-normal_C','DNN-mild_C'], rotation=45)\n",
    "    axes[2].set_xticklabels(['HA','DNN-normal','DNN-mild','DNN-normal_C','DNN-mild_C'], rotation=45)\n",
    "    fig.suptitle('Measure: '+ measure)\n",
    "    plt.show()\n",
    "\n",
    "# Plot all measures:\n",
    "plot_1_measure(measures_computed,\"snrloss_L\")\n",
    "plot_1_measure(measures_computed,\"snrloss_R\")\n",
    "plot_1_measure(measures_computed,\"sisdr_L\")\n",
    "plot_1_measure(measures_computed,\"sisdr_R\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_1_measure(measures_computed,\"sisdr_L\")\n",
    "plot_1_measure(measures_computed,\"sisdr_R\")\n",
    "plot_1_measure(measures_computed,\"snrloss_L\")\n",
    "\n",
    "plot_1_measure(measures_computed,\"snrloss_R\")\n",
    "#plot_1_measure(measures_computed,\"hasqi_R\")\n",
    "#plot_1_measure(measures_computed,\"haspi_R\")\n",
    "#plot_1_measure(measures_computed,\"mbstoi_B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

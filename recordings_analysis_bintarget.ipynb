{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.io import wavfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.fft\n",
    "from scipy.signal import resample_poly\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "\n",
    "import tqdm\n",
    "import time\n",
    "import seaborn as sns\n",
    "# import my modules (helpers.py where I stored all the functions):\n",
    "import helpers as hlp\n",
    "import importlib \n",
    "importlib.reload(hlp)\n",
    "from clarity.evaluator.hasqi import hasqi_v2\n",
    "from clarity.evaluator.haspi import haspi_v2 \n",
    "from clarity.evaluator.mbstoi import mbstoi \n",
    "import torch\n",
    "import sys\n",
    "from multiprocessing import Pool\n",
    "import copy\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_rms(x):\n",
    "    y = copy.deepcopy(x)\n",
    "    return y / np.sqrt(np.mean(x ** 2))\n",
    "\n",
    "def SISDR(s, s_hat):\n",
    "    \"\"\"Computes the Scale-Invariant SDR as in [1]_.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Le Roux, Jonathan, et al. \"SDRâ€“half-baked or well done?.\" ICASSP 2019-2019 IEEE International Conference on\n",
    "    Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2019.\n",
    "    Parameters:\n",
    "        s: targets of any shape\n",
    "        s_hat: corresponding estimates of any shape\n",
    "    \"\"\"\n",
    "    s = torch.from_numpy(s)\n",
    "    s_hat = torch.from_numpy(s_hat)\n",
    "    s = s.view(-1)\n",
    "    EPS = torch.finfo(s.dtype).eps\n",
    "    s_hat = s_hat.view(-1)\n",
    "    a = (torch.dot(s_hat, s) * s) / ((s ** 2).sum() + EPS)\n",
    "    b = a - s_hat\n",
    "    return 10*torch.log10(((a*a).sum()) / ((b*b).sum()+EPS))\n",
    "\n",
    "def SNRLoss(target, input):\n",
    "    EPS = torch.finfo(target.dtype).eps\n",
    "    input_mean = torch.mean(input, dim=-1, keepdim=True)\n",
    "    target_mean = torch.mean(target, dim=-1, keepdim=True)\n",
    "    input = input - input_mean\n",
    "    target = target - target_mean\n",
    "    res = input - target\n",
    "    losses = 10 * torch.log10(\n",
    "        (target ** 2).sum(-1) / ((res ** 2).sum(-1) + EPS) + EPS\n",
    "    )\n",
    "    # apply reduction\n",
    "    losses = losses.mean()\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where all recordings used as reference are stored\n",
    "data_ref_dir='/home/ubuntu/Data/ha_listening_situations/'\n",
    "folders = os.listdir(data_ref_dir+'recordings/ku_recordings/')\n",
    "recnames = ['_'.join(x.split('_')[1:]) for x in folders]\n",
    "folders = {recnames[i]: folders[i] for i in range(len(folders))}\n",
    "\n",
    "FS_DNN = 16000\n",
    "\n",
    "# Names of hearing devices\n",
    "ha_models=[\"si3_s\",\"si3_m\",\"si3_p\",\"ph4_s\",\"ph4_m\",\"ph4_p\",\"ph5_s\",\"ph5_m\",\"ph5_p\",\n",
    "           \"gn5_l\",\"gn5_m\",\"gn5_h\",\"gn3_l\",\"gn3_m\",\"gn3_h\"]\n",
    "\n",
    "# GN3 bad phase inversion unusable\n",
    "# GN5 bad phase inversion unusable\n",
    "\n",
    "# PH5 good\n",
    "# PH4 good\n",
    "# SI3 good\n",
    "\n",
    "#ha_models=[\"si3_s\",\"si3_m\",\"si3_p\",\"ph4_s\",\"ph4_m\",\"ph4_p\",\"ph5_s\",\"ph5_m\",\"ph5_p\"]\n",
    "           \n",
    "# Different listening scenes:\n",
    "scenes=['party','restaurant','meeting']\n",
    "\n",
    "degrees = ['0', '30']\n",
    "\n",
    "processings = ['bypass', 'ha', 'dnn_normal_noncausal', 'dnn_normal_causal', 'dnn_mild_noncausal', 'dnn_mild_causal']\n",
    "\n",
    "process_folders = {'dnn_normal_noncausal' : 'processed_m1_alldata_normal',\n",
    "                  'dnn_normal_causal' : 'processed_m4_alldata_normal_causal',\n",
    "                  'dnn_mild_noncausal' : 'processed_m3_alldata_mild',\n",
    "                  'dnn_mild_causal' : 'processed_m5_alldata_mild_causal'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "\n",
    "for ha_model in ha_models:\n",
    "    for scene in scenes:\n",
    "        for degree in degrees:\n",
    "            for processing in processings:\n",
    "                # first let's listen to GN3_H\n",
    "                if processing == 'ha':\n",
    "                    # the plus recording from that device, \"enabled\"\n",
    "                    meas_path = data_ref_dir+'recordings/ku_recordings/' \\\n",
    "                    +folders[ha_model+'_enabled_ku100']+'/' \\\n",
    "                    +folders[ha_model+'_enabled_ku100'] \\\n",
    "                    +'_plus_'+scene+'_'+degree+'deg.wav'\n",
    "                    \n",
    "                elif processing == 'bypass':\n",
    "                    try:\n",
    "                        # measurement is the bypass recording from the device processed by the dnn\n",
    "                        meas_path = data_ref_dir+'recordings/ku_recordings/' \\\n",
    "                        +folders[ha_model+'_bypass_ku100']+'/' \\\n",
    "                        +folders[ha_model+'_bypass_ku100'] \\\n",
    "                        +'_plus_'+scene+'_'+degree+'deg.wav'\n",
    "                    except:\n",
    "                        # measurement is the bypassed recording from the device processed by the dnn\n",
    "                        meas_path = data_ref_dir+'recordings/ku_recordings/' \\\n",
    "                        +folders[ha_model+'_bypassed_ku100']+'/' \\\n",
    "                        +folders[ha_model+'_bypassed_ku100'] \\\n",
    "                        +'_plus_'+scene+'_'+degree+'deg.wav'\n",
    "\n",
    "                    '''\n",
    "                    # plus and minus recordings from same device, \"bypass\"\n",
    "                    ref_plus_path = data_ref_dir+'recordings/ku_recordings/' \\\n",
    "                    +folders[ha_model+'_bypass_ku100']+'/' \\\n",
    "                    +folders[ha_model+'_bypass_ku100'] \\\n",
    "                    +'_plus_'+scene+'_'+degree+'deg.wav'\n",
    "\n",
    "                    ref_minus_path = data_ref_dir+'recordings/ku_recordings/' \\\n",
    "                    +folders[ha_model+'_bypass_ku100']+'/' \\\n",
    "                    +folders[ha_model+'_bypass_ku100'] \\\n",
    "                    +'_minus_'+scene+'_'+degree+'deg.wav'\n",
    "                    '''\n",
    "                else :\n",
    "                    try:\n",
    "                        # measurement is the bypass recording from the device processed by the dnn\n",
    "                        meas_path = data_ref_dir+ process_folders[processing] +'/ku_processed/'\\\n",
    "                        +folders[ha_model+'_bypass_ku100']+'/' \\\n",
    "                        +folders[ha_model+'_bypass_ku100'] \\\n",
    "                        +'_plus_'+scene+'_'+degree+'deg.wav'\n",
    "                    except:\n",
    "                        # measurement is the bypassed recording from the device processed by the dnn\n",
    "                        meas_path = data_ref_dir+ process_folders[processing] +'/ku_processed/'\\\n",
    "                        +folders[ha_model+'_bypassed_ku100']+'/' \\\n",
    "                        +folders[ha_model+'_bypassed_ku100'] \\\n",
    "                        +'_plus_'+scene+'_'+degree+'deg.wav'\n",
    "                    '''\n",
    "                    # reference is the (unprocessed) bypass recordings of the same device\n",
    "                    ref_plus_path = data_ref_dir+'recordings/ku_recordings/' \\\n",
    "                    +folders[ha_model+'_bypass_ku100']+'/' \\\n",
    "                    +folders[ha_model+'_bypass_ku100'] \\\n",
    "                    +'_plus_'+scene+'_'+degree+'deg.wav'\n",
    "\n",
    "                    ref_minus_path = data_ref_dir+'recordings/ku_recordings/' \\\n",
    "                    +folders[ha_model+'_bypass_ku100']+'/' \\\n",
    "                    +folders[ha_model+'_bypass_ku100'] \\\n",
    "                    +'_minus_'+scene+'_'+degree+'deg.wav'\n",
    "                    '''\n",
    "                target_path = '/home/ubuntu/Data/ha_listening_situations/SH_versions/normal/'+ \\\n",
    "                                'sharvard-target1-'+degree+'deg/'+scene+'_bin_deg'+degree+'_snr5_ane_48000hz.wav'\n",
    "            \n",
    "                df.append({'ha_model' : ha_model,\n",
    "                     'scene' : scene,\n",
    "                     'degree ': degree,\n",
    "                     'processing' : processing,\n",
    "                     'meas_path' : meas_path,\n",
    "                     'target_path' : target_path})\n",
    "                \n",
    "\n",
    "df = pd.DataFrame.from_dict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_obj_measures(idx, row):\n",
    "    # Function: Compute objective measures based on one row of a data frame \n",
    "    # ----- Input: -----\n",
    "    # ref_method - method for computing clean reference signal\n",
    "    # idx - index in the original data frame\n",
    "    # row - row containing filenames of plus and minus recording\n",
    "    # ----- Output: -----\n",
    "    # tuple of objective measures: \n",
    "    # - snr_val: snr estimated with phase inversion technique\n",
    "    # - mbstoi_val: binaural speech intelligibility model\n",
    "    # - hasqi_left_val: hearing aid speech quality for 1 ear\n",
    "    # - hasqi_left_val: hearing aid speech perception index for 1 ear\n",
    "    # - sisdr_val: sudo-rm-rf method for computing sdr\n",
    "    # ----------------------------------------------------------------------\n",
    "    # print sth when the row is done:    \n",
    "    meas, fs = sf.read(row['meas_path'])\n",
    "    target, fs_tar = sf.read(row['target_path'])\n",
    "\n",
    "    if fs!= FS_DNN :\n",
    "        meas = resample_poly(meas.astype(np.float32), FS_DNN, fs)\n",
    "        \n",
    "    if fs_tar != FS_DNN :\n",
    "        target = resample_poly(target.astype(np.float32), FS_DNN, fs_tar)\n",
    "    \n",
    "    # ---------- Compute clean reference signal for further methods ----------\n",
    "    # Synchronize signals \n",
    "    meas, target, lag =hlp.synch_sigs(meas,target)\n",
    "    #print(lag)\n",
    "    print( \"Processing row \" +str(idx)+ \". lag is : \"+str(lag))\n",
    "\n",
    "    crop = int(np.min([len(meas), len(target)]))\n",
    "    meas = meas[:crop, :]\n",
    "    target = target[:crop, :]\n",
    "    target *= np.sqrt((meas ** 2).sum() /((target ** 2).sum()))\n",
    "    norm_fac = np.max((np.max(np.abs(meas)), np.max(np.abs(target))))\n",
    "    meas /= norm_fac\n",
    "    target /= norm_fac\n",
    "\n",
    "    # ------------- Objective measure : SI-SDR -------------\n",
    "    sisdr_L = SISDR(target[:,0], meas[:,0]).item()\n",
    "    sisdr_R = SISDR(target[:,1], meas[:,1]).item()\n",
    "#    sisdr = max(sisdr_L, sisdr_R)\n",
    "    sisdr = SISDR(target, meas).item()\n",
    "\n",
    "    # ------------- Objective measure : SNR Losss -------------\n",
    "    snrloss_L=SNRLoss(torch.from_numpy(target[:,0]),torch.from_numpy(meas[:,0])).item() \n",
    "    snrloss_R=SNRLoss(torch.from_numpy(target[:,1]),torch.from_numpy(meas[:,1])).item() \n",
    "    snrloss = np.mean((snrloss_L, snrloss_R))\n",
    "    #snrloss = np.max((snrloss_L, snrloss_R))\n",
    "\n",
    "    # ------------- Objective measure : MBSTOI -------------\n",
    "    mbstoi_B = mbstoi(\n",
    "        left_ear_clean=target[:,0],\n",
    "        right_ear_clean=target[:,1],\n",
    "        left_ear_noisy=meas[:,0],\n",
    "        right_ear_noisy=meas[:,1],\n",
    "        fs_signal=FS_DNN,  # signal sample rate\n",
    "        sample_rate=9000,  # operating sample rate\n",
    "        fft_size_in_samples=64,\n",
    "        n_third_octave_bands=5,\n",
    "        centre_freq_first_third_octave_hz=500,\n",
    "        dyn_range=60,\n",
    "    )\n",
    "    # ------------- Objective measures : HASQI and HASPI -------------\n",
    "    hearing_loss = np.array([0, 0, 0, 0, 0, 0])\n",
    "    equalisation_mode=1\n",
    "    level1=70\n",
    "    sig_l_norm = np.sqrt(len(target[:,0]))\n",
    "    #hasqi_L, _, _, _ = hasqi_v2(norm_rms(target[:,0]), FS_DNN, norm_rms(meas[:,0]), FS_DNN, hearing_loss, equalisation_mode, level1)\n",
    "    hasqi_L, _, _, _ = hasqi_v2(norm_rms(target[:,0]), FS_DNN, meas[:,0], FS_DNN, hearing_loss, equalisation_mode, level1)\n",
    "    #hasqi_R, _, _, _ = hasqi_v2(norm_rms(target[:,1]), FS_DNN, norm_rms(meas[:,1]), FS_DNN, hearing_loss, equalisation_mode, level1)\n",
    "    hasqi_R, _, _, _ = hasqi_v2(norm_rms(target[:,1]), FS_DNN, meas[:,1], FS_DNN, hearing_loss, equalisation_mode, level1)\n",
    "    hasqi = np.mean((hasqi_L, hasqi_R))\n",
    "#    hasqi = np.max((hasqi_L, hasqi_R))\n",
    "\n",
    "    #haspi_L, _ = haspi_v2(norm_rms(target[:,0]), FS_DNN, norm_rms(meas[:,0]) , FS_DNN, hearing_loss, level1)\n",
    "    #haspi_R, _ = haspi_v2(norm_rms(target[:,1]), FS_DNN, norm_rms(meas[:,1]) , FS_DNN, hearing_loss, level1)\n",
    "    haspi_L, _ = haspi_v2(norm_rms(target[:,0]), FS_DNN, meas[:,0], FS_DNN, hearing_loss, level1)\n",
    "    haspi_R, _ = haspi_v2(norm_rms(target[:,1]), FS_DNN, meas[:,1], FS_DNN, hearing_loss, level1)\n",
    "# without haspiFIX:\n",
    "    #haspi_L, _ = haspi_v2(target[:,0], FS_DNN, hlp.add_signals(meas[:,0],target[:,0]) , FS_DNN, hearing_loss, level1)\n",
    "    #haspi_R, _ = haspi_v2(target[:,1], FS_DNN, hlp.add_signals(meas[:,1],target[:,1]) , FS_DNN, hearing_loss, level1)\n",
    "#    haspi = np.max((haspi_L, haspi_R))\n",
    "    haspi = np.mean((haspi_L, haspi_R))\n",
    "\n",
    "    # ------------- Magnitude square coherence -------------\n",
    "    return idx, hasqi_L, hasqi_R, hasqi, haspi_L, haspi_R, haspi, sisdr_L, sisdr_R, sisdr, snrloss_L, snrloss_R, snrloss, mbstoi_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0. lag is : 3057\n",
      "Processing row 5. lag is : 3042\n",
      "Processing row 4. lag is : 3057\n",
      "Processing row 1. lag is : 3057Processing row 3. lag is : 3058Processing row 2. lag is : 3057Processing row 7. lag is : 3059\n",
      "\n",
      "\n",
      "\n",
      "Processing row 6. lag is : 3059\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m results \u001b[39m=\u001b[39m [pool\u001b[39m.\u001b[39mapply_async(compute_obj_measures, [idx, row]) \u001b[39mfor\u001b[39;00m idx, row \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39miterrows()]\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m result \u001b[39min\u001b[39;00m results:\n\u001b[0;32m----> 7\u001b[0m     idx, hasqi_L, hasqi_R, hasqi, haspi_L, haspi_R, haspi, sisdr_L, sisdr_R, sisdr, snrloss_L, snrloss_R, snrloss, mbstoi \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39;49mget()\n\u001b[1;32m      8\u001b[0m     df\u001b[39m.\u001b[39mloc[idx, \u001b[39m'\u001b[39m\u001b[39mhaspi_L\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m haspi_L\n\u001b[1;32m      9\u001b[0m     df\u001b[39m.\u001b[39mloc[idx, \u001b[39m'\u001b[39m\u001b[39mhaspi_R\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m haspi_R\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    766\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout)\n",
      "File \u001b[0;32m/usr/lib/python3.8/threading.py:558\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    557\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 558\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    559\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    303\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    NUM_OF_WORKERS = 8\n",
    "    t0 = time.time()\n",
    "    with Pool(NUM_OF_WORKERS) as pool:\n",
    "        results = [pool.apply_async(compute_obj_measures, [idx, row]) for idx, row in df.iterrows()]\n",
    "        for result in results:\n",
    "            idx, hasqi_L, hasqi_R, hasqi, haspi_L, haspi_R, haspi, sisdr_L, sisdr_R, sisdr, snrloss_L, snrloss_R, snrloss, mbstoi = result.get()\n",
    "            df.loc[idx, 'haspi_L'] = haspi_L\n",
    "            df.loc[idx, 'haspi_R'] = haspi_R\n",
    "            df.loc[idx, 'haspi'] = haspi\n",
    "            df.loc[idx, 'hasqi_L'] = hasqi_L\n",
    "            df.loc[idx, 'hasqi_R'] = hasqi_R\n",
    "            df.loc[idx, 'hasqi'] = hasqi\n",
    "            df.loc[idx, 'sisdr_L'] = sisdr_L\n",
    "            df.loc[idx, 'sisdr_R'] = sisdr_R\n",
    "            df.loc[idx, 'sisdr'] = sisdr\n",
    "            df.loc[idx, 'snrloss_L'] = snrloss_L\n",
    "            df.loc[idx, 'snrloss_R'] = snrloss_R\n",
    "            df.loc[idx, 'snrloss'] = snrloss\n",
    "            df.loc[idx, 'mbstoi'] = mbstoi\n",
    "            \n",
    "df.to_csv('results_haspiFix_normRef.csv')\n",
    "print('Took '+ str(time.time()-t0)+' seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('results_haspiFix_normRef.csv')\n",
    "#df = pd.read_csv('results_haspiFix_normBoth_be.csv')\n",
    "#df = pd.read_csv('results_haspiFix_normBoth.csv')\n",
    "#df = pd.read_csv('results_haspiFix.csv')\n",
    "#df = pd.read_csv('results.csv')\n",
    "df = pd.read_csv('results_original.csv')\n",
    "\n",
    "'''\n",
    "1) results_original.csv -> the script as it is in the last commit. Does it match the plots in the paper?\n",
    "2) results_haspiFix.csv -> using meas instead of meas+target as measurement in HASPI. How bad is it?\n",
    "3) results_haspiFix_normRef -> same as (2) but normalizing TARGET (or reference) to amplitude 1 RMS\n",
    "4) results_haspiFix_normBoth -> same as (3) but normalizing both TARGET and MEAS\n",
    "5) results_haspiFix_normBoth_be -> same as (4) but using BEST EAR (max instead of mean) in all metrics\n",
    "6) results_haspiFix_exclude -> same as (2) but excluding the BAD devices (the ones that don't plus-minus well)\n",
    "    -> does SISDR on this last one match the paper?\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux=df[df['processing']!='dnn_mild_noncausal']\n",
    "\n",
    "aux=aux[aux['processing']!='dnn_mild_causal']\n",
    "\n",
    "aux['dev_group']=aux['ha_model']\n",
    "aux.loc[aux['dev_group'].str.contains('gn3'),'dev_group']='d1'\n",
    "aux.loc[aux['dev_group'].str.contains('gn5'),'dev_group']='d2'\n",
    "aux.loc[aux['dev_group'].str.contains('si3'),'dev_group']='d3'\n",
    "aux.loc[aux['dev_group'].str.contains('ph5'),'dev_group']='d4'\n",
    "aux.loc[aux['dev_group'].str.contains('ph4'),'dev_group']='d5'\n",
    "\n",
    "\n",
    "# create a reference dataframe with repeated resulta for bypass recording \n",
    "bypass=aux[aux[\"processing\"]==\"bypass\"]\n",
    "bypass=pd.concat([bypass]*3)\n",
    "\n",
    "# create a reference dataframe with results for all processing methods\n",
    "ha=aux[aux[\"processing\"]==\"ha\"]\n",
    "dnn1=aux[aux[\"processing\"]==\"dnn_normal_causal\"]\n",
    "dnn2=aux[aux[\"processing\"]==\"dnn_normal_noncausal\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "processed = pd.concat([ha, dnn1], ignore_index=True)\n",
    "processed = pd.concat([processed, dnn2], ignore_index=True)\n",
    "\n",
    "# make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sure the two dataframes that are going to be compared have values sorted in the same way\n",
    "bypass=bypass.reset_index(drop=True)\n",
    "processed=processed.reset_index(drop=True)\n",
    "print(bypass['scene'].equals(processed['scene']))\n",
    "print(bypass['ha_model'].equals(processed['ha_model']))\n",
    "print(bypass['degree '].equals(processed['degree ']))\n",
    "\n",
    "# dataframe with difference measures (benefit of each measure)\n",
    "aux_delta=processed\n",
    "aux_delta['haspi']=processed['haspi']-bypass['haspi']\n",
    "aux_delta['hasqi']=processed['hasqi']-bypass['hasqi']\n",
    "aux_delta['mbstoi']=processed['mbstoi']-bypass['mbstoi']\n",
    "aux_delta['sisdr']=processed['sisdr']-bypass['sisdr']\n",
    "\n",
    "print(len(aux_delta))\n",
    "sns.set(rc={'axes.facecolor':'lightgrey', 'figure.facecolor':'none'})\n",
    "fig, axes = plt.subplots(2, 2, figsize=(8, 5))\n",
    "print(axes.shape)\n",
    "sns.set(font_scale=0.7)\n",
    "sns.violinplot(ax=axes[0,0], data=aux_delta, y='haspi', x='processing',palette=\"colorblind\")\n",
    "sns.violinplot(ax=axes[0,1],data=aux_delta, y='hasqi', x='processing',palette=\"colorblind\")\n",
    "sns.violinplot(ax=axes[1,0],data=aux_delta, y='sisdr', x='processing',palette=\"colorblind\")\n",
    "sns.violinplot(ax=axes[1,1],data=aux_delta, y='mbstoi', x='processing',palette=\"colorblind\")\n",
    "axes[0,0].set_ylabel('$\\Delta$HASPI')\n",
    "axes[0,1].set_ylabel('$\\Delta$HASQI')\n",
    "axes[1,0].set_ylabel('$\\Delta$SISDR')\n",
    "axes[1,1].set_ylabel('$\\Delta$MBSTOI')\n",
    "axes[0,0].set_xlabel('')\n",
    "axes[0,1].set_xlabel('')\n",
    "axes[1,0].set_xlabel('')\n",
    "axes[1,1].set_xlabel('')\n",
    "#axes[0,0].set_ylim((-0.2,0.4))\n",
    "#axes[0,1].set_ylim((-0.2,0.3))\n",
    "#axes[1,1].set_ylim((-0.2,0.3))\n",
    "# axes[0,0].set_xticklabels(['HA','DNN','DNN-C'], rotation=0)\n",
    "# axes[0,1].set_xticklabels(['HA','DNN','DNN-C'], rotation=0)\n",
    "# axes[1,0].set_xticklabels(['HA','DNN','DNN-C'], rotation=0)\n",
    "# axes[1,1].set_xticklabels(['HA','DNN','DNN-C'], rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join('figures', 'basic_plot.pdf'))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(rc={'axes.facecolor':'lightgrey', 'figure.facecolor':'none'})\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 4))\n",
    "print(axes.shape)\n",
    "sns.set(font_scale=0.7)\n",
    "pal=sns.color_palette(palette=\"colorblind\", n_colors=15)\n",
    "sns.barplot(ax=axes[0,0],data=aux, y='haspi', x='processing',palette=\"colorblind\",hue='dev_group')\n",
    "sns.barplot(ax=axes[0,1],data=aux, y='hasqi', x='processing',palette=\"colorblind\",hue='dev_group')\n",
    "sns.barplot(ax=axes[1,0],data=aux, y='sisdr', x='processing',palette=\"colorblind\",hue='dev_group')\n",
    "sns.barplot(ax=axes[1,1],data=aux, y='mbstoi', x='processing',palette=\"colorblind\",hue='dev_group')\n",
    "# for i in ax.containers:\n",
    "#     ax.bar_label(i,)\n",
    "# ax = sns.barplot(ax=axes[0,1],data=aux, y='hasqi', x='processing',palette=\"muted\",hue='dev_group')\n",
    "# for i in ax.containers:\n",
    "#     ax.bar_label(i,)\n",
    "# ax = sns.barplot(ax=axes[1,0],data=aux, y='sisdr', x='processing',palette=\"muted\",hue='dev_group')\n",
    "# for i in ax.containers:\n",
    "#     ax.bar_label(i,)\n",
    "# ax = sns.barplot(ax=axes[1,1],data=aux, y='mbstoi', x='processing',palette=\"muted\",hue='dev_group')\n",
    "# for i in ax.containers:\n",
    "#     ax.bar_label(i,)\n",
    "axes[0,0].set_ylabel('HASPI')\n",
    "axes[0,1].set_ylabel('HASQI')\n",
    "axes[1,0].set_ylabel('SISDR')\n",
    "axes[1,1].set_ylabel('MBSTOI')\n",
    "axes[0,0].set_xlabel('')\n",
    "axes[0,1].set_xlabel('')\n",
    "axes[1,0].set_xlabel('')\n",
    "axes[1,1].set_xlabel('')\n",
    "#axes[0,0].set_ylim((0.7,1.1))\n",
    "#axes[0,1].set_ylim((0,0.4))\n",
    "#axes[1,1].set_ylim((0.3,0.8))\n",
    "axes[0,0].set_xticklabels(['Bypass','HA','DNN','DNN-C'], rotation=0)\n",
    "axes[0,1].set_xticklabels(['Bypass','HA','DNN','DNN-C'], rotation=0)\n",
    "axes[1,0].set_xticklabels(['Bypass','HA','DNN','DNN-C'], rotation=0)\n",
    "axes[1,1].set_xticklabels(['Bypass','HA','DNN','DNN-C'], rotation=0)\n",
    "axes[0,0].get_legend().remove() \n",
    "axes[0,1].get_legend().remove() \n",
    "axes[1,0].get_legend().remove() \n",
    "axes[1,1].get_legend().remove() \n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join('figures', 'bar_plot.pdf'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LibriMix3D",
   "language": "python",
   "name": "librimix3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

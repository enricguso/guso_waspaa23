{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.io import wavfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.fft\n",
    "from scipy.signal import resample_poly\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "\n",
    "\n",
    "# import my modules (helpers.py where I stored all the functions):\n",
    "import helpers as hlp\n",
    "import importlib \n",
    "importlib.reload(hlp)\n",
    "from clarity.evaluator.hasqi import hasqi_v2\n",
    "from clarity.evaluator.haspi import haspi_v2 \n",
    "from clarity.evaluator.mbstoi import mbstoi \n",
    "import torch\n",
    "import sys\n",
    "from multiprocessing import Pool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# All our directories in which we store recordings or dnn-processed recordings:\n",
    "data_source_dirs=[\n",
    "    '/home/ubuntu/Data/ha_listening_situations/recordings/ku_recordings/',\n",
    "    '/home/ubuntu/Data/ha_listening_situations/processed_m1_alldata_normal/ku_processed/',\n",
    "    '/home/ubuntu/Data/ha_listening_situations/processed_m3_alldata_mild/ku_processed/',\n",
    "    '/home/ubuntu/Data/ha_listening_situations/processed_m4_alldata_normal_causal/ku_processed/',\n",
    "    '/home/ubuntu/Data/ha_listening_situations/processed_m5_alldata_mild_causal/ku_processed/'\n",
    "]\n",
    "\n",
    "# Directory where all recordings used as reference are stored\n",
    "data_ref_dir='/home/ubuntu/Data/ha_listening_situations/recordings/ku_recordings/'\n",
    "\n",
    "# Names of hearing devices\n",
    "ha_models=[\"si3_s\",\"si3_m\",\"si3_p\",\"ph4_s\",\"ph4_m\",\"ph4_p\",\"ph5_s\",\"ph5_m\",\"ph5_p\",\n",
    "           \"gn5_l\",\"gn5_m\",\"gn5_h\",\"gn3_l\",\"gn3_m\",\"gn3_h\"]\n",
    "\n",
    "# Different listening scenes:\n",
    "scenenames=['party_0deg','party_30deg','restaurant_0deg','restaurant_30deg','meeting_0deg','meeting_30deg']\n",
    "\n",
    "# Initialize dataframe, in which each row will represent one pair of plus and minus recording\n",
    "# and all the info and objective measures associated with that pair. \n",
    "recordings_df=pd.DataFrame(columns=['device','dnn_applied','plus_file','minus_file', 'plus_ref_file','minus_ref_file', 'scene'])\n",
    "\n",
    "# initialize lists to be filled inside the loop\n",
    "dnntypes=[]\n",
    "pluses=[]\n",
    "minuses=[]\n",
    "bypass_pluses=[]\n",
    "bypass_minuses=[]\n",
    "rawku_pluses=[]\n",
    "rawku_minuses=[]\n",
    "scenes=[]\n",
    "devices=[]\n",
    "\n",
    "for i, data_source_dir in enumerate(data_source_dirs):\n",
    "    for item in sorted(os.listdir(data_source_dir)):\n",
    "        if os.path.isdir(data_source_dir+item):\n",
    "            recording_name=item\n",
    "            # this line identifies the current device name:\n",
    "            device_id=[model for model in ha_models if model in recording_name]\n",
    "            if len(device_id)>0:\n",
    "                # this line finds the corresponding bypass recording name:\n",
    "                ref_recording_name = [dirname for dirname in os.listdir(data_source_dir)\n",
    "                if os.path.isdir(data_source_dir+dirname) and device_id[0] in dirname and \"bypass\" in dirname][0]\n",
    "            else:\n",
    "                ref_recording_name=recording_name\n",
    "            \n",
    "            for scene in scenenames:\n",
    "                # paths for recorded plus and minus signals (data_source_dir + recording_name)\n",
    "                plusfilepath=data_source_dir+recording_name+'/'+recording_name+'_plus_'+scene+'.wav'\n",
    "                minusfilepath=data_source_dir+recording_name+'/'+recording_name+'_minus_'+scene+'.wav'\n",
    "                # paths for corresponding bypass plus and minus signals (data_ref_dir + ref_recording_name)\n",
    "                bypass_plusrefpath=data_ref_dir+ref_recording_name+'/'+ref_recording_name+'_plus_'+scene+'.wav'\n",
    "                bypass_minusrefpath=data_ref_dir+ref_recording_name+'/'+ref_recording_name+'_minus_'+scene+'.wav'\n",
    "                # paths for corresponding ku100 plus and minus signals \n",
    "                ku_plusrefpath=data_ref_dir+'001_ku100/001_ku100_plus_'+scene+'.wav'\n",
    "                ku_minusrefpath=data_ref_dir+'001_ku100/001_ku100_minus_'+scene+'.wav'\n",
    "                # append all lists:\n",
    "                applieddnntype=i\n",
    "                devices.append(recording_name)\n",
    "                pluses.append(plusfilepath)\n",
    "                minuses.append(minusfilepath)\n",
    "                bypass_pluses.append(bypass_plusrefpath)\n",
    "                bypass_minuses.append(bypass_minusrefpath)\n",
    "                rawku_pluses.append(ku_plusrefpath)\n",
    "                rawku_minuses.append(ku_minusrefpath)\n",
    "                scenes.append(scene)\n",
    "                dnntypes.append(applieddnntype)\n",
    "\n",
    "# fill the data frame with lists appended in the loop above:\n",
    "recordings_df['device']=devices            \n",
    "recordings_df['dnn_applied']=dnntypes\n",
    "recordings_df['plus_file']=pluses\n",
    "recordings_df['minus_file']=minuses\n",
    "recordings_df['plus_ref_bypass']=bypass_pluses\n",
    "recordings_df['minus_ref_bypass']=bypass_minuses\n",
    "recordings_df['plus_ref_ku']=rawku_pluses\n",
    "recordings_df['minus_ref_ku']=rawku_minuses\n",
    "recordings_df['scene']=scenes\n",
    "\n",
    "# Make sure to remove the lines where the \"enabled\" recording is processed and lines where ku100 recording is processed \n",
    "# (we are only interested in dnn-processed bypass recordings):\n",
    "print(f'before: {len(recordings_df)=}')\n",
    "recordings_df=recordings_df[~((recordings_df[\"device\"].str.contains(\"enabled\")) & (recordings_df[\"dnn_applied\"]>0))]\n",
    "recordings_df=recordings_df[~((recordings_df[\"device\"].str.contains(\"001_ku100\")) & (recordings_df[\"dnn_applied\"]>0))]\n",
    "recordings_df=recordings_df[~(recordings_df[\"device\"].str.contains(\"fulldenoising\"))]\n",
    "print(f'after: {len(recordings_df)=}')\n",
    "\n",
    "# Within the group that is not processed by any dnn model we have to distinguish 3 categories and give them labels: \n",
    "# ---> unprocessed reference: ku100 recordings without a hearing aid\n",
    "recordings_df.loc[recordings_df[\"device\"].str.contains(\"001_ku100\"), \"dnn_applied\"]=0.1\n",
    "# ---> unprocessed bypass: recordings with hearing aids in bypass\n",
    "recordings_df.loc[((recordings_df[\"device\"].str.contains(\"bypass\")) & (recordings_df[\"dnn_applied\"]==0)), \"dnn_applied\"]=0.2\n",
    "# ---> unprocessed enabled: recordings with hearing aids enabled\n",
    "recordings_df.loc[((recordings_df[\"device\"].str.contains(\"enabled\")) & (recordings_df[\"dnn_applied\"]==0)), \"dnn_applied\"]=0.3\n",
    "\n",
    "# Check if numbers match: \n",
    "print(f'Number of dnn-processed recordings should be {15*4*6}')\n",
    "print(len(recordings_df.loc[(recordings_df[\"dnn_applied\"]>=1)]))\n",
    "\n",
    "\n",
    "print(f'Number of enabled recordings should be {15*6}')\n",
    "print(len(recordings_df.loc[(recordings_df[\"dnn_applied\"]==0.3)])) \n",
    "\n",
    "\n",
    "print(f'Number of bypass recordings should be {15*6}')\n",
    "print(len(recordings_df.loc[(recordings_df[\"dnn_applied\"]==0.2)])) \n",
    "\n",
    "\n",
    "print(f'Number of ku100 recordings should be {6}')\n",
    "print(len(recordings_df.loc[(recordings_df[\"dnn_applied\"]==0.1)])) \n",
    "\n",
    "# Keep only recordings processed with HA or DNN\n",
    "recordings_only_processed=recordings_df[(recordings_df[\"dnn_applied\"]>0.2)]\n",
    "print(f'Number of all processed recordings should be {15*5*6}')\n",
    "print(len(recordings_only_processed))\n",
    "\n",
    "recordings_only_processed.to_csv('recordings_processed.csv')\n",
    "\n",
    "\n",
    "measures=pd.read_csv('recordings_processed.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HA_models = 15\n",
    "#DNNs = 5 (4 DNNs and 1 HA enabled)\n",
    "#scenes = 6\n",
    "\n",
    "#each has a path to the plus, and minus recordings\n",
    "#also a path to the plus and minus recordings of that device in bypass\n",
    "#finally a the path to the plus and minus of the KU100 without HA on that specific situation\n",
    "\n",
    "#TODO: add code for energy normalization between estimates and targets\n",
    "#TODO2:Use code above for syncing\n",
    "\n",
    "#now we compute (correcting the \"lag\" with cross-correlation for each reference/target if needed):\n",
    "#SNR_pm (plus minus method)\n",
    "#SNR_bp (estimate, target is bypass recording, approach https://github.com/csteinmetz1/auraloss/blob/c4f16e7df3aea1c5b0ac6ef981a02d8d60e5e7be/auraloss/time.py#L94)\n",
    "#SNR_ku (estimate, target is ku recording, approach https://github.com/csteinmetz1/auraloss/blob/c4f16e7df3aea1c5b0ac6ef981a02d8d60e5e7be/auraloss/time.py#L94)\n",
    "#SISDR_bp\n",
    "#SISDR_ku\n",
    "#stoi_bp\n",
    "#stop_ku\n",
    "#hasqui_bp\n",
    "#hasqui_ku\n",
    "#haspi_bp\n",
    "#haspi_ku\n",
    "\n",
    "#then we choose what makes more sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SISDR(s, s_hat):\n",
    "    \"\"\"Computes the Scale-Invariant SDR as in [1]_.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Le Roux, Jonathan, et al. \"SDR–half-baked or well done?.\" ICASSP 2019-2019 IEEE International Conference on\n",
    "    Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2019.\n",
    "    Parameters:\n",
    "        s: list of targets of any shape\n",
    "        s_hat: list of corresponding estimates of any shape\n",
    "    \"\"\"\n",
    "    s = torch.stack(s).view(-1)\n",
    "    EPS = torch.finfo(s.dtype).eps\n",
    "    s_hat = torch.stack(s_hat).view(-1)\n",
    "    a = (torch.dot(s_hat, s) * s) / ((s ** 2).sum() + EPS)\n",
    "    b = a - s_hat\n",
    "    return 10*torch.log10(((a*a).sum()) / ((b*b).sum()+EPS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = measures.loc[115]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row['plus_file'] #DNN1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row['minus_file'] #DNN1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row['plus_ref_bypass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row['plus_ref_ku']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FS_TARGET=16e3\n",
    "fs, plus = wavfile.read(row['plus_file'])\n",
    "fs, minus = wavfile.read(row['minus_file'])\n",
    "\n",
    "if fs!=16000:\n",
    "    plus = resample_poly(plus.astype(np.float32), FS_TARGET, fs)\n",
    "    minus = resample_poly(minus.astype(np.float32), FS_TARGET, fs)\n",
    "s = 0.5*(plus+minus)\n",
    "n = 0.5*(plus-minus)\n",
    "\n",
    "fs, ku_plus = wavfile.read(row['plus_ref_ku'])\n",
    "fs, ku_minus = wavfile.read(row['minus_ref_ku'])\n",
    "if fs!=16000:\n",
    "    ku_plus = resample_poly(ku_plus.astype(np.float32), FS_TARGET, fs)\n",
    "    ku_minus = resample_poly(ku_minus.astype(np.float32), FS_TARGET, fs)\n",
    "#\n",
    "ku_s = 0.5*(ku_plus+ku_minus)\n",
    "ku_n = 0.5*(ku_plus-ku_minus)\n",
    "\n",
    "fs, bp_plus = wavfile.read(row['plus_ref_bypass'])\n",
    "fs, bp_min = wavfile.read(row['minus_ref_bypass'])\n",
    "if fs!=16000:\n",
    "    bp_plus = resample_poly(bp_plus.astype(np.float32), FS_TARGET, fs)\n",
    "    bp_min = resample_poly(bp_min.astype(np.float32), FS_TARGET, fs)\n",
    "bp_s = 0.5*(bp_plus+bp_min)\n",
    "bp_n = 0.5*(bp_plus-bp_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(s.T, rate=FS_TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(n.T, rate=FS_TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(bp_s.T, rate=FS_TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(bp_n.T, rate=FS_TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(ku_s.T, rate=FS_TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(ku_n.T, rate=FS_TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SISDR([torch.from_numpy(ku_s)], [torch.from_numpy(plus)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SISDR([torch.from_numpy(bp_s)], [torch.from_numpy(plus)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_bp = scipy.signal.correlate(plus[:,0], bp_s[:,0], 'full')\n",
    "\n",
    "lag_bp = scipy.signal.correlation_lags(len(plus[:,0]), len(bp_s[:,0]), mode='full')[np.argmax(corr_bp)]\n",
    "\n",
    "lag_bp\n",
    "\n",
    "corr_ku = scipy.signal.correlate(plus[:,0], ku_s[:,0], 'full')\n",
    "lag_ku = scipy.signal.correlation_lags(len(plus[:,0]), len(ku_s[:,0]), mode='full')[np.argmax(corr_ku)]\n",
    "\n",
    "lag_ku\n",
    "\n",
    "if lag_bp > 0:\n",
    "    sisdr_bp = SISDR([torch.from_numpy(bp_s[0:-lag_bp, :])], [torch.from_numpy(plus[lag_bp:, :])])\n",
    "elif lag_bp < 0 :\n",
    "    sisdr_bp = SISDR([torch.from_numpy(bp_s[-lag_bp:, :])], [torch.from_numpy(plus[0:lag_bp, :])])\n",
    "else:\n",
    "    sisdr_bp = SISDR([torch.from_numpy(bp_s)], [torch.from_numpy(plus)])\n",
    "\n",
    "if lag_ku > 0:\n",
    "    sisdr_ku = SISDR([torch.from_numpy(ku_s[0:-lag_ku, :])], [torch.from_numpy(plus[lag_ku:, :])])\n",
    "elif lag_ku < 0:\n",
    "    sisdr_ku = SISDR([torch.from_numpy(ku_s[-lag_ku:, :])], [torch.from_numpy(plus[0:lag_ku, :])]) \n",
    "else:\n",
    "    sisdr_bp = SISDR([torch.from_numpy(ku_s)], [torch.from_numpy(plus)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sisdr_bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sisdr_ku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try another one\n",
    "row = measures.iloc[350]\n",
    "refs = measures[measures['device']=='001_ku100']\n",
    "\n",
    "ref = refs[refs['scene'] == row['scene']].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row['plus_file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row['plus_ref_file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref['plus_file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FS_TARGET=16e3\n",
    "fs, plus = wavfile.read(row['plus_file'])\n",
    "fs, minus = wavfile.read(row['minus_file'])\n",
    "\n",
    "if fs!=16000:\n",
    "    plus = resample_poly(plus.astype(np.float32), FS_TARGET, fs)\n",
    "    minus = resample_poly(minus.astype(np.float32), FS_TARGET, fs)\n",
    "\n",
    "fs, ku_plus = wavfile.read(ref['plus_file'])\n",
    "fs, ku_minus = wavfile.read(ref['minus_file'])\n",
    "if fs!=16000:\n",
    "    ku_plus = resample_poly(ku_plus.astype(np.float32), FS_TARGET, fs)\n",
    "    ku_minus = resample_poly(ku_minus.astype(np.float32), FS_TARGET, fs)\n",
    "#\n",
    "ku_s = 0.5*(ku_plus+ku_minus)\n",
    "\n",
    "fs, bp_plus = wavfile.read(row['plus_ref_file'])\n",
    "fs, bp_min = wavfile.read(row['minus_ref_file'])\n",
    "if fs!=16000:\n",
    "    bp_plus = resample_poly(bp_plus.astype(np.float32), FS_TARGET, fs)\n",
    "    bp_min = resample_poly(bp_min.astype(np.float32), FS_TARGET, fs)\n",
    "bp_s = 0.5*(bp_plus+bp_min)\n",
    "\n",
    "corr_bp = scipy.signal.correlate(plus[:,0], bp_s[:,0], 'full')\n",
    "\n",
    "lag_bp = scipy.signal.correlation_lags(len(plus[:,0]), len(bp_s[:,0]), mode='full')[np.argmax(corr_bp)]\n",
    "\n",
    "lag_bp\n",
    "\n",
    "corr_ku = scipy.signal.correlate(plus[:,0], ku_s[:,0], 'full')\n",
    "lag_ku = scipy.signal.correlation_lags(len(plus[:,0]), len(ku_s[:,0]), mode='full')[np.argmax(corr_ku)]\n",
    "\n",
    "lag_ku\n",
    "\n",
    "if lag_bp > 0:\n",
    "    sisdr_bp = SISDR([torch.from_numpy(bp_s[0:-lag_bp, :])], [torch.from_numpy(plus[lag_bp:, :])])\n",
    "elif lag_bp < 0 :\n",
    "    sisdr_bp = SISDR([torch.from_numpy(bp_s[-lag_bp:, :])], [torch.from_numpy(plus[0:lag_bp, :])])\n",
    "else:\n",
    "    sisdr_bp = SISDR([torch.from_numpy(bp_s)], [torch.from_numpy(plus)])\n",
    "\n",
    "if lag_ku > 0:\n",
    "    sisdr_ku = SISDR([torch.from_numpy(ku_s[0:-lag_ku, :])], [torch.from_numpy(plus[lag_ku:, :])])\n",
    "elif lag_ku < 0:\n",
    "    sisdr_ku = SISDR([torch.from_numpy(ku_s[-lag_ku:, :])], [torch.from_numpy(plus[0:lag_ku, :])]) \n",
    "else:\n",
    "    sisdr_bp = SISDR([torch.from_numpy(ku_s)], [torch.from_numpy(plus)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SISDR([torch.from_numpy(ku_s)], [torch.from_numpy(plus)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SISDR([torch.from_numpy(bp_s)], [torch.from_numpy(plus)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sisdr_bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sisdr_ku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now SISDR with the HA_bypass signal (row[ref])\n",
    "corr = scipy.signal.correlate(plus[:,0], ref_s[:,0], 'full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sisdr_ku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech = 0.5 * (plus + minus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(speech.T, rate=FS_TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = 0.5 * (plus - minus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(noise.T, rate=FS_TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SISDR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SISDR(s, s_hat):\n",
    "    \"\"\"Computes the Scale-Invariant SDR as in [1]_.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Le Roux, Jonathan, et al. \"SDR–half-baked or well done?.\" ICASSP 2019-2019 IEEE International Conference on\n",
    "    Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2019.\n",
    "    Parameters:\n",
    "        s: list of targets of any shape\n",
    "        s_hat: list of corresponding estimates of any shape\n",
    "    \"\"\"\n",
    "    s = torch.stack(s).view(-1)\n",
    "    EPS = torch.finfo(s.dtype).eps\n",
    "    s_hat = torch.stack(s_hat).view(-1)\n",
    "    a = (torch.dot(s_hat, s) * s) / ((s ** 2).sum() + EPS)\n",
    "    b = a - s_hat\n",
    "    return -10*torch.log10(((a*a).sum()) / ((b*b).sum()+EPS))\n",
    "\n",
    "def compute_obj_measures(idx, row):\n",
    "    # Function: Compute objective measures based on one row of a data frame \n",
    "    # ----- Input: -----\n",
    "    # idx - index in the original data frame\n",
    "    # row - row containing filenames of plus and minus recording\n",
    "    # ----- Output: -----\n",
    "    # tuple of objective measures: \n",
    "    # - snr_val: snr estimated with phase inversion technique\n",
    "    # - mbstoi_val: binaural speech intelligibility model\n",
    "    # - hasqi_left_val: hearing aid speech quality for 1 ear\n",
    "    # - hasqi_left_val: hearing aid speech perception index for 1 ear\n",
    "    # - sisdr_val: sudo-rm-rf method for computing sdr\n",
    "    # ----------------------------------------------------------------------\n",
    "    FS_TARGET=16e3\n",
    "    fs, plus = wavfile.read(row['plus_file'])\n",
    "    fs, minus = wavfile.read(row['minus_file'])\n",
    "    if fs!=16000:\n",
    "        plus = resample_poly(plus.astype(np.float32), FS_TARGET, fs)\n",
    "        minus = resample_poly(minus.astype(np.float32), FS_TARGET, fs)\n",
    "\n",
    "    fs, refplus = wavfile.read(row['plus_ref_file'])\n",
    "    fs, refminus = wavfile.read(row['minus_ref_file'])\n",
    "    if fs!=16000:\n",
    "        refplus = resample_poly(refplus.astype(np.float32), FS_TARGET, fs)\n",
    "        refminus = resample_poly(refminus.astype(np.float32), FS_TARGET, fs)\n",
    "    # ---------- Compute clean reference signal ----------\n",
    "    ref_s=0.5*(refplus+refminus)\n",
    "    # ------------- Objective measure 1: SNR -------------\n",
    "    s=0.5*(plus+minus)\n",
    "    n=0.5*(plus-minus)\n",
    "    snr_left_val = 10 * np.log10(hlp.power(s[:,0]) / hlp.power(n[:,0]))\n",
    "    snr_right_val = 10 * np.log10(hlp.power(s[:,1]) / hlp.power(n[:,1]))\n",
    "    snr_val =10 * np.log10(hlp.power(s) / hlp.power(n))\n",
    "    # ------------- Objective measure 2: MBSTOI -------------\n",
    "    mbstoi_val = mbstoi(\n",
    "        left_ear_clean=ref_s[:,0],\n",
    "        right_ear_clean=ref_s[:,1],\n",
    "        left_ear_noisy=plus[:,0],\n",
    "        right_ear_noisy=plus[:,1],\n",
    "        fs_signal=FS_TARGET,  # signal sample rate\n",
    "        sample_rate=9000,  # operating sample rate\n",
    "        fft_size_in_samples=64,\n",
    "        n_third_octave_bands=5,\n",
    "        centre_freq_first_third_octave_hz=500,\n",
    "        dyn_range=60,\n",
    "    )\n",
    "    # ------------- Objective measure 3 & 4: HASQI and HASPI -------------\n",
    "    hearing_loss = np.array([0, 0, 0, 0, 0, 0])\n",
    "    equalisation_mode=1\n",
    "    level1=65\n",
    "    hasqi_left_val, _, _, _ = hasqi_v2(ref_s[:,0], FS_TARGET, plus[:,0], FS_TARGET, hearing_loss, equalisation_mode, level1)\n",
    "    haspi_left_val, _ = haspi_v2(ref_s[:,0], FS_TARGET, plus[:,0] + ref_s[:,0], FS_TARGET, hearing_loss, level1)\n",
    "\n",
    "    # ------------- Objective measure 5: SI-SDR -------------\n",
    "    sisdr_val=SISDR([torch.from_numpy(ref_s)],[torch.from_numpy(plus)]).item()\n",
    "    print(str(idx)+ \"row\")\n",
    "    return idx, snr_left_val,snr_right_val,snr_val, mbstoi_val, hasqi_left_val, haspi_left_val,sisdr_val \n",
    "\n",
    "\n",
    "# The main script has to be in the same cell as the definition of the function\n",
    "if __name__ == '__main__':\n",
    "    NUM_OF_WORKERS = 8\n",
    "    with Pool(NUM_OF_WORKERS) as pool:\n",
    "        results = [pool.apply_async(compute_obj_measures, [idx, row]) for idx, row in measures.iterrows()]\n",
    "        for result in results:\n",
    "            idx, snr_left, snr_right, snr, mbstoi_v, hasqi_left, haspi_left, sisdr = result.get()\n",
    "            measures.loc[idx, 'snr_left'] = snr_left\n",
    "            measures.loc[idx, 'snr_right'] = snr_right\n",
    "            measures.loc[idx, 'snr'] = snr\n",
    "            measures.loc[idx, 'mbstoi'] = mbstoi_v\n",
    "            measures.loc[idx, 'hasqi_left'] = hasqi_left\n",
    "            measures.loc[idx, 'haspi_left'] = haspi_left\n",
    "            measures.loc[idx, 'sisdr'] = sisdr\n",
    "\n",
    "measures.to_csv('objective_measures2.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some important edits before plotting: \n",
    "\n",
    "# read dataframe \n",
    "measures_computed=pd.read_csv('objective_measures2.csv')\n",
    "\n",
    "# Make sure to remove the lines where the \"enabled\" recording is processed and lines where ku100 recording is processed \n",
    "# (we are only interested in dnn-processed bypass recordings):\n",
    "print(f'before: {len(measures)=}')\n",
    "measures_computed=measures_computed[~((measures_computed[\"device\"].str.contains(\"enabled\")) & (measures_computed[\"dnn_applied\"]>0))]\n",
    "measures_computed=measures_computed[~((measures_computed[\"device\"].str.contains(\"001_ku100\")) & (measures_computed[\"dnn_applied\"]>0))]\n",
    "measures_computed=measures_computed[~((measures_computed[\"device\"].str.contains(\"fulldenoising\")) & (measures_computed[\"dnn_applied\"]>0))]\n",
    "print(f'after: {len(measures_computed)=}')\n",
    "\n",
    "# Within the group that is not processed by any dnn model we have to distinguish 3 categories and give them labels: \n",
    "# ---> unprocessed reference: ku100 recordings without a hearing aid\n",
    "measures_computed.loc[measures_computed[\"device\"].str.contains(\"001_ku100\"), \"dnn_applied\"]=0.1\n",
    "# ---> unprocessed bypass: recordings with hearing aids in bypass\n",
    "measures_computed.loc[((measures_computed[\"device\"].str.contains(\"bypass\")) & (measures_computed[\"dnn_applied\"]==0)), \"dnn_applied\"]=0.2\n",
    "# ---> unprocessed enabled: recordings with hearing aids enabled\n",
    "measures_computed.loc[((measures_computed[\"device\"].str.contains(\"enabled\")) & (measures_computed[\"dnn_applied\"]==0)), \"dnn_applied\"]=0.3\n",
    "measures_computed.loc[((measures_computed[\"device\"].str.contains(\"fulldenoising\")) & (measures_computed[\"dnn_applied\"]==0)), \"dnn_applied\"]=0.3\n",
    "\n",
    "# For a better visibility, we add one column which specifies the hearing aid model (without division into different receivers)\n",
    "ha_models=[\"gn3\",\"gn5\",\"ph5\",\"ph4\",\"si3\",\"fulldenoising\",\"001_ku\"]\n",
    "for modelname in ha_models:\n",
    "    measures_computed.loc[measures_computed['device'].str.contains(modelname), \"device_group\"]=modelname\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import warnings\n",
    "  \n",
    "# Settings the warnings to be ignored\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def plot_1_measure(df,measure):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(25, 5), sharey=True) \n",
    "    sns.set(font_scale=0.8)\n",
    "    sns.stripplot(ax=axes[1],data=df,x=\"dnn_applied\", y=measure, hue=\"device_group\")\n",
    "    sns.stripplot(ax=axes[2],data=df,x=\"dnn_applied\", y=measure, hue=\"scene\")\n",
    "    df.boxplot(ax=axes[0],column=measure,by=\"dnn_applied\")\n",
    "    axes[0].set_xlabel('')\n",
    "    axes[1].set_xlabel('')\n",
    "    axes[2].set_xlabel('')\n",
    "    axes[0].set_title('Standard boxplot')\n",
    "    axes[1].set_title('Colored by devices')\n",
    "    axes[2].set_title('Colored by scene')\n",
    "    axes[0].set_xticklabels(['ref','bypass','HA','DNN-normal','DNN-mild','DNN-normal_C','DNN-mild_C'], rotation=45)\n",
    "    axes[1].set_xticklabels(['ref','bypass','HA','DNN-normal','DNN-mild','DNN-normal_C','DNN-mild_C'], rotation=45)\n",
    "    axes[2].set_xticklabels(['ref','bypass','HA','DNN-normal','DNN-mild','DNN-normal_C','DNN-mild_C'], rotation=45)\n",
    "    fig.suptitle('Measure: '+ measure)\n",
    "    plt.show()\n",
    "\n",
    "# Plot all measures:\n",
    "plot_1_measure(measures_computed,\"snr_left\")\n",
    "plot_1_measure(measures_computed,\"sisdr\")\n",
    "plot_1_measure(measures_computed,\"hasqi_left\")\n",
    "plot_1_measure(measures_computed,\"haspi_left\")\n",
    "plot_1_measure(measures_computed,\"mbstoi\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

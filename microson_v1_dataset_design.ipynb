{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77da5d49",
   "metadata": {},
   "source": [
    "# Meta-data generation script for Microson enhancement dataset (V1)\n",
    "\n",
    "Perse Multilingual-LibriSpeech-Spanish (MLLSS) and WHAM! noise datasets and define situations and augmentations for each MLLSS instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979138dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import masp as srs\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from IPython.display import Audio\n",
    "import pandas as pd\n",
    "import os\n",
    "from os.path import join as pjoin\n",
    "from multiprocessing import Pool\n",
    "import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaab4889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import my modules (helpers.py where I stored all the functions):\n",
    "import helpers as hlp\n",
    "import importlib\n",
    "importlib.reload(hlp);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0859d8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WE DEFINE THE CHUNK LENGHT TO 4 SECONDS (DEFAULT TO USING SUDO-RM-RF)\n",
    "# SET PATHS:\n",
    "mls_path = '/home/ubuntu/Data/mls_spanish'\n",
    "wham_path = '/home/ubuntu/Data/wham'\n",
    "output_path = '/home/ubuntu/Data/ha_scenes_sounds/'\n",
    "fs = 16000\n",
    "fs_n = 'wav16k'\n",
    "mode = 'min'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c6a378",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5b9fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_chunks_by_duration(seconds_list):\n",
    "    # Files that can reasonably be padded will be padded.\n",
    "    # Otherwise we crop\n",
    "    out = []\n",
    "    chunk = []\n",
    "    low_bound = np.array([(x+1)*2 for x in list(range(11))])   \n",
    "    hi_bound = np.array([(x+2)*2 for x in list(range(11))])\n",
    "    n_chunks = np.repeat(np.array([x+1 for x in list(range(6))]), 2)\n",
    "    n_chunks = n_chunks[:len(low_bound)]\n",
    "    for s in seconds_list:\n",
    "        x = n_chunks[np.argmax(np.logical_and(s > low_bound, s < hi_bound))]\n",
    "        out.append(x)\n",
    "        chunk.append(list(range(x)))\n",
    "    return out, chunk   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e448a3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_info = []\n",
    "for split in ['tr', 'cv', 'tt']:\n",
    "    split_path = pjoin(pjoin(wham_path, 'wham_noise'), split)\n",
    "    for audio_path in  tqdm.tqdm(os.listdir(split_path)):\n",
    "        audio, fs = sf.read(pjoin(split_path, audio_path))\n",
    "        noise_info.append({'split': split, 'audio_path': pjoin(audio_path), 'fs_noise': fs, 'shape':audio.shape})\n",
    "        \n",
    "\n",
    "ometa = pd.read_csv(pjoin(mls_path, 'metainfo.txt'), sep= '|')\n",
    "ometa.columns = ometa.columns.str.strip()\n",
    "ometa['PARTITION'] = ometa['PARTITION'].str.strip()\n",
    "\n",
    "info = []\n",
    "for split in ['train', 'test', 'dev']:\n",
    "    split_path = pjoin(pjoin(mls_path, split), 'audio')\n",
    "    speakers = os.listdir(split_path)\n",
    "    for speaker in speakers:\n",
    "        speaker_path = pjoin(split_path, speaker)\n",
    "        books = os.listdir(speaker_path)\n",
    "        for book in books:\n",
    "            book_path = pjoin(speaker_path, book)\n",
    "            audio_paths = os.listdir(book_path)\n",
    "            for audio_path in tqdm.tqdm(audio_paths):\n",
    "                gender = list(ometa[ometa['SPEAKER']==int(speaker)]['GENDER'])[0].strip()\n",
    "                info.append({'split': split, 'speaker': speaker, 'book': book, 'speech_path': audio_path, 'gender': gender})\n",
    "df_s = pd.DataFrame(info)\n",
    "df_n = pd.DataFrame(noise_info)\n",
    "\n",
    "\n",
    "lens = list(df_n['shape'])\n",
    "\n",
    "#df_s.to_pickle(\"mls_info.pkl\")\n",
    "#df_n.to_pickle(\"wham_info.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e594b501",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_s = pd.read_pickle(\"mls_info.pkl\")\n",
    "#df_n = pd.read_pickle(\"wham_info.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4272d6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_wham_train_set(tr, speech_len, fs):\n",
    "    tr = tr.reset_index(drop=True)\n",
    "    # Store lenght (in samples and seconds) from shape\n",
    "    tr.insert(2, \"len_samp\", [x[0] for x in list(tr['shape'])], True)\n",
    "    tr.insert(2, \"len_s\", [x[0]/fs for x in list(tr['shape'])], True)\n",
    "    \n",
    "    # Assign a number of chunks. Chunks from [2,4]s are expanded to one 4s chunk. \n",
    "    # Chunks from [4,6]s are cropped to one 4s chunk\n",
    "    nchunks, chunk = assign_chunks_by_duration(list(tr['len_s']))\n",
    "    tr.insert(2, \"num_chunks\", nchunks, True)\n",
    "    lentr = len(tr)\n",
    "    tr = tr.reindex(tr.index.repeat(tr.num_chunks))\n",
    "    tr = tr.reset_index(drop=True)\n",
    "    tr.insert(2, \"chunk\", [item for sublist in chunk for item in sublist], True)\n",
    "    # One copy will have phase inversion (*(-1))\n",
    "    L = [False, True]\n",
    "    tr = (pd.DataFrame(np.repeat(tr.values, 2, axis=0), columns=tr.columns)\n",
    "               .assign(phase_inv = np.tile(L, len(tr))))\n",
    "    # The other copy will have a swap of left and right channels\n",
    "    tr = (pd.DataFrame(np.repeat(tr.values, 2, axis=0), columns=tr.columns)\n",
    "               .assign(lr_inv = np.tile(L, len(tr))))\n",
    "    # The rest of utterances we have to augment will randomly time-streched\n",
    "    stretch_utt = speech_len - len(tr)\n",
    "    stretch  = np.concatenate((np.zeros(len(tr)), np.random.uniform(low=0.9, high=1.1, size=(stretch_utt))))\n",
    "    tr = pd.concat([tr, tr[0:stretch_utt]])\n",
    "    tr.insert(10, \"stretch\", stretch, True)\n",
    "    tr = tr.reset_index(drop=True)\n",
    "    tr = tr.rename(columns={'audio_path': 'noise_path'})\n",
    "    tr = tr.rename(columns={'split': 'wham_split'})\n",
    "    return tr\n",
    "\n",
    "def crop_wham_test_set(tr, speech_len, fs):\n",
    "    tr = tr.reset_index(drop=True)\n",
    "    tr.insert(2, \"len_samp\", [x[0] for x in list(tr['shape'])], True)\n",
    "    tr.insert(2, \"len_s\", [x[0]/fs for x in list(tr['shape'])], True)\n",
    "    tr = tr[tr.len_s > 4.]\n",
    "    tr = tr[:speech_len]\n",
    "    tr = tr.reset_index(drop=True)\n",
    "    tr.insert(2, \"chunk\", [0]*len(tr))\n",
    "    tr.insert(2, \"num_chunks\", [1]*len(tr))\n",
    "    tr.insert(2, \"phase_inv\", [False]*len(tr))\n",
    "    tr.insert(2, \"lr_inv\", [False]*len(tr))\n",
    "    tr.insert(2, \"stretch\", np.zeros(len(tr)))\n",
    "    tr = tr.rename(columns={'audio_path': 'noise_path'})\n",
    "    tr = tr.rename(columns={'split': 'wham_split'})\n",
    "    return tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31aab8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = augment_wham_train_set(df_n[df_n['split']=='tr'], len(df_s[df_s['split']=='train']), fs)\n",
    "cv = crop_wham_test_set(df_n[df_n['split']=='cv'], len(df_s[df_s['split']=='dev']), fs)\n",
    "tt = crop_wham_test_set(df_n[df_n['split']=='tt'], len(df_s[df_s['split']=='test']), fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ef54fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_wham = pd.concat([tr, tt, cv], axis=0)\n",
    "aug_wham = aug_wham.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc93d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we merge the augmented wham metadata with the MLS-spanish metadata\n",
    "df = pd.concat([df_s, aug_wham], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debfea90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import my modules (helpers.py where I stored all the functions):\n",
    "import helpers as hlp\n",
    "import importlib\n",
    "importlib.reload(hlp);\n",
    "\n",
    "head_orient_azi = np.random.uniform(low = -45, high = 45, size = len(df))\n",
    "head_orient_ele = np.random.uniform(low = -10, high = 10, size = len(df))\n",
    "\n",
    "angle = np.random.uniform(low = -45, high = 45, size = len(df))\n",
    "dist = np.random.uniform(low = 0.5, high = 3, size = len(df))\n",
    "snr = np.random.uniform(low = 0, high = 6, size = len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c01244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "room_x = np.random.uniform(low = 3., high = 30., size = len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599087b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "room_y = room_x * np.random.uniform(low=0.5, high=1, size=len(room_x)) #avoid tunnels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bb743b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#room_y = np.random.uniform(low = 2., high = 30., size = len(df))\n",
    "room_z = np.random.uniform(low = 2.5, high = 5., size = len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d52c430",
   "metadata": {},
   "outputs": [],
   "source": [
    "t60s =  np.random.uniform(low = .1, high = 1., size = len(df))\n",
    "t60s = np.sort(t60s)\n",
    "volumes = room_x * room_y * room_z\n",
    "volumes = np.sort(volumes)\n",
    "dist = np.sort(dist)\n",
    "perm = np.random.permutation(len(volumes))\n",
    "room_x = room_x[perm]\n",
    "room_y = room_y[perm]\n",
    "room_z = room_z[perm]\n",
    "dist = dist[perm]\n",
    "t60s = t60s[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de951870",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_pos = []\n",
    "for k in range(len(room_x)):\n",
    "    head_pos.append(np.array([np.random.uniform(low = 0.35*room_x[k], high = 0.65*room_x[k]),\n",
    "                        np.random.uniform(low = 0.35*room_y[k], high = 0.65*room_y[k]),\n",
    "                        np.random.uniform(low = 1., high = 2.)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad33695",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_pos = np.array(head_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e713e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "room = np.array((room_x, room_y, room_z)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60acff81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import my modules (helpers.py where I stored all the functions):\n",
    "import helpers as hlp\n",
    "import importlib\n",
    "importlib.reload(hlp);\n",
    "\n",
    "target_pos = []\n",
    "for k in tqdm.tqdm(range(len(room_x))):\n",
    "    target_pos.append(hlp.place_on_circle_in_room(head_pos[k], dist[k], \n",
    "                                                               angle[k]+head_orient_azi[k], room[k]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0975b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pos = np.squeeze(np.array(target_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95485c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(target_pos > 0.) # all targets are positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08830e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks:\n",
    "np.all(target_pos < room) # all targets are in the room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1f5f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(head_pos < room) # all heads are in the room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ea9daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's check the ears:\n",
    "ears_pos = []\n",
    "for k in range(head_pos.shape[0]):\n",
    "    ears_pos.append(np.array(hlp.head_2_ku_ears(head_pos[k], np.array([head_orient_azi[k],head_orient_ele[k]]))))\n",
    "\n",
    "ears_pos = np.array(ears_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e078be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(ears_pos[:, 0, :] < room) # all left ears are in the room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72fb7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(ears_pos[:, 1, :] < room) # all right are in the room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ee7876",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(ears_pos > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5550b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final MINIMUM distance between head and target (check we don't have an intra-craneal target)\n",
    "min(np.sqrt(np.sum((target_pos - head_pos)**2, axis=1))) > 0.0875 * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a36857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum distance of ears against a wall\n",
    "min ( min(room[:, 0] - ears_pos[:, 0, 0]), min(room[:, 0] - ears_pos[:, 1, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd075f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "min ( min(room[:, 1] - ears_pos[:, 0, 1]), min(room[:, 1] - ears_pos[:, 1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fa0b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "min ( min(room[:, 2] - ears_pos[:, 0, 2]), min(room[:, 2] - ears_pos[:, 1, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1462969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum distance of targets against a wall\n",
    "min(min(room[:, 0] - target_pos[:, 0]), min(room[:, 1] - target_pos[:, 1]), min(room[:, 2] - target_pos[:, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61390f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'split': 'mls_split'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6135472e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ad8019",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(14, \"room_x\", room[:, 0])\n",
    "df.insert(15, \"room_y\", room[:, 1])\n",
    "df.insert(16, \"room_z\", room[:, 2])\n",
    "df.insert(17, \"rt60\", t60s)\n",
    "df.insert(18, \"headC_x\", head_pos[:,0])\n",
    "df.insert(19, \"headC_y\", head_pos[:,1])\n",
    "df.insert(20, \"headC_z\", head_pos[:,2])\n",
    "df.insert(21, \"src_x\", target_pos[:,0])\n",
    "df.insert(22, \"src_y\", target_pos[:,1])\n",
    "df.insert(23, \"src_z\", target_pos[:,2])\n",
    "df.insert(24, \"headOrient_azi\", head_orient_azi)\n",
    "df.insert(25, \"headOrient_ele\", head_orient_ele)\n",
    "df.insert(26, \"snr\", snr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76109516",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['idx'] = range(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f31f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# generate a figure for each situation:\n",
    "for k in tqdm.tqdm(range(head_pos.shape[0])):\n",
    "    hlp.plot_scene(room[k], head_pos[k], np.array([head_orient_azi[k], head_orient_ele[k]])\n",
    "                   , ears_pos[k],[target_pos[k]], perspective=\"xy\")\n",
    "    plt.title(str(head_orient_azi[k])+ '_' + str(angle[k]))\n",
    "    plt.savefig(pjoin('situation_plots_rot', os.path.splitext(os.path.basename(df.iloc[k].audio_path))[0]+'.pdf'))\n",
    "    plt.close('all')\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700bec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('meta_microson_v1.csv', index=False, compression='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017cb9d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LibriMix3D",
   "language": "python",
   "name": "librimix3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

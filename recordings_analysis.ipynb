{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.io import wavfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.fft\n",
    "from scipy.signal import resample_poly\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "\n",
    "import tqdm\n",
    "import time\n",
    "import seaborn as sns\n",
    "# import my modules (helpers.py where I stored all the functions):\n",
    "import helpers as hlp\n",
    "import importlib \n",
    "importlib.reload(hlp)\n",
    "from clarity.evaluator.hasqi import hasqi_v2\n",
    "from clarity.evaluator.haspi import haspi_v2 \n",
    "from clarity.evaluator.mbstoi import mbstoi \n",
    "import torch\n",
    "import sys\n",
    "from multiprocessing import Pool\n",
    "import copy\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spl(x):\n",
    "    # returns the equivalent spl value of our studio recordings\n",
    "    return 20 * np.log10(np.sqrt(np.mean( x ** 2))) + 127.9\n",
    "\n",
    "def norm_rms(x):\n",
    "    # normalizes the signal so it has an RMS value of 1\n",
    "    y = copy.deepcopy(x)\n",
    "    return y / np.sqrt(np.mean(x ** 2))\n",
    "\n",
    "def SISDR(s, s_hat):\n",
    "    \"\"\"Computes the Scale-Invariant SDR as in [1]_.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Le Roux, Jonathan, et al. \"SDRâ€“half-baked or well done?.\" ICASSP 2019-2019 IEEE International Conference on\n",
    "    Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2019.\n",
    "    Parameters:\n",
    "        s: targets of any shape\n",
    "        s_hat: corresponding estimates of any shape\n",
    "    \"\"\"\n",
    "    s = torch.from_numpy(s)\n",
    "    s_hat = torch.from_numpy(s_hat)\n",
    "    s = s.view(-1)\n",
    "    EPS = torch.finfo(s.dtype).eps\n",
    "    s_hat = s_hat.view(-1)\n",
    "    a = (torch.dot(s_hat, s) * s) / ((s ** 2).sum() + EPS)\n",
    "    b = a - s_hat\n",
    "    return 10*torch.log10(((a*a).sum()) / ((b*b).sum()+EPS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''DATAFRAME: we need to build a dataframe with the following columns:\n",
    "ha_model -> the HA device model and receiver combination, e.g. GN5_L\n",
    "scene -> {party, meeting, restaurant}\n",
    "degree -> {0, 30}\n",
    "processing -> {bypass, ha, dnn, dnn_causal}\n",
    "meas_path -> absolute path to that measurement wav file\n",
    "target_path -> absolute path to the target or reference (the anechoic binaural downmix of the situation)\n",
    "''';\n",
    "\n",
    "# Directory where all recordings used as reference are stored\n",
    "data_ref_dir='/home/ubuntu/Data/ha_listening_situations/'\n",
    "folders = os.listdir(data_ref_dir+'recordings/ku_recordings/')\n",
    "recnames = ['_'.join(x.split('_')[1:]) for x in folders]\n",
    "folders = {recnames[i]: folders[i] for i in range(len(folders))}\n",
    "\n",
    "FS_DNN = 16000\n",
    "\n",
    "# Names of hearing devices\n",
    "ha_models=[\"si3_s\",\"si3_m\",\"si3_p\",\"ph4_s\",\"ph4_m\",\"ph4_p\",\"ph5_s\",\"ph5_m\",\"ph5_p\",\n",
    "           \"gn5_l\",\"gn5_m\",\"gn5_h\",\"gn3_l\",\"gn3_m\",\"gn3_h\"]\n",
    "           \n",
    "# Different listening scenes:\n",
    "scenes=['party','restaurant','meeting']\n",
    "\n",
    "degrees = ['0', '30']\n",
    "\n",
    "processings = ['bypass', 'ha', 'dnn_normal_noncausal', 'dnn_normal_causal', 'dnn_mild_noncausal', 'dnn_mild_causal']\n",
    "\n",
    "process_folders = {'dnn_normal_noncausal' : 'processed_m1_alldata_normal',\n",
    "                  'dnn_normal_causal' : 'processed_m4_alldata_normal_causal',\n",
    "                  'dnn_mild_noncausal' : 'processed_m3_alldata_mild',\n",
    "                  'dnn_mild_causal' : 'processed_m5_alldata_mild_causal'}\n",
    "\n",
    "\n",
    "df = []\n",
    "\n",
    "for ha_model in ha_models:\n",
    "    for scene in scenes:\n",
    "        for degree in degrees:\n",
    "            for processing in processings:\n",
    "                # first let's listen to GN3_H\n",
    "                if processing == 'ha':\n",
    "                    # the plus recording from that device, \"enabled\"\n",
    "                    meas_path = data_ref_dir+'recordings/ku_recordings/' \\\n",
    "                    +folders[ha_model+'_enabled_ku100']+'/' \\\n",
    "                    +folders[ha_model+'_enabled_ku100'] \\\n",
    "                    +'_plus_'+scene+'_'+degree+'deg.wav'\n",
    "                    \n",
    "                elif processing == 'bypass':\n",
    "                    try:\n",
    "                        # measurement is the bypass recording from the device processed by the dnn\n",
    "                        meas_path = data_ref_dir+'recordings/ku_recordings/' \\\n",
    "                        +folders[ha_model+'_bypass_ku100']+'/' \\\n",
    "                        +folders[ha_model+'_bypass_ku100'] \\\n",
    "                        +'_plus_'+scene+'_'+degree+'deg.wav'\n",
    "                    except:\n",
    "                        # measurement is the bypassed recording from the device processed by the dnn\n",
    "                        meas_path = data_ref_dir+'recordings/ku_recordings/' \\\n",
    "                        +folders[ha_model+'_bypassed_ku100']+'/' \\\n",
    "                        +folders[ha_model+'_bypassed_ku100'] \\\n",
    "                        +'_plus_'+scene+'_'+degree+'deg.wav'\n",
    "                else :\n",
    "                    try:\n",
    "                        # measurement is the bypass recording from the device processed by the dnn\n",
    "                        meas_path = data_ref_dir+ process_folders[processing] +'/ku_processed/'\\\n",
    "                        +folders[ha_model+'_bypass_ku100']+'/' \\\n",
    "                        +folders[ha_model+'_bypass_ku100'] \\\n",
    "                        +'_plus_'+scene+'_'+degree+'deg.wav'\n",
    "                    except:\n",
    "                        # measurement is the bypassed recording from the device processed by the dnn\n",
    "                        meas_path = data_ref_dir+ process_folders[processing] +'/ku_processed/'\\\n",
    "                        +folders[ha_model+'_bypassed_ku100']+'/' \\\n",
    "                        +folders[ha_model+'_bypassed_ku100'] \\\n",
    "                        +'_plus_'+scene+'_'+degree+'deg.wav'\n",
    "                target_path = '/home/ubuntu/Data/ha_listening_situations/SH_versions/normal/'+ \\\n",
    "                                'sharvard-target1-'+degree+'deg/'+scene+'_bin_deg'+degree+'_snr5_ane_48000hz.wav'\n",
    "            \n",
    "                df.append({'ha_model' : ha_model,\n",
    "                     'scene' : scene,\n",
    "                     'degree ': degree,\n",
    "                     'processing' : processing,\n",
    "                     'meas_path' : meas_path,\n",
    "                     'target_path' : target_path})\n",
    "                \n",
    "\n",
    "df = pd.DataFrame.from_dict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_obj_measures(idx, row):\n",
    "    # Function: Compute objective measures based on one row of a data frame \n",
    "    # ----- Input: -----\n",
    "    # idx - index in the original data frame\n",
    "    # row - row containing filenames of plus and minus recording\n",
    "    # ----- Output: -----\n",
    "    # tuple of objective measures: \n",
    "    # - hasqi_L: hearing aid speech quality for left ear\n",
    "    # - hasqi_R: hearing aid speech quality for right ear\n",
    "    # - hasqi: hearing aid speech quality for best ear \n",
    "    # - haspi_L: hearing aid speech perception index for left ear \n",
    "    # - haspi_R: hearing aid speech perception index for right ear\n",
    "    # - haspi: hearing aid speech perception index for best ear\n",
    "    # - sisdr_L: scale-invariant signal to distortion ratio for left ear\n",
    "    # - sisdr_R: scale-invariant signal to distortion ratio for right ear\n",
    "    # - sisdr: scale-invariant signal to distortion ratio for best ear \n",
    "    # - mbstoi_B: modified binaural speech to objective intelligibility metric\n",
    "    # ----------------------------------------------------------------------\n",
    "    \n",
    "    # Load audio and resmple if needed\n",
    "    meas, fs = sf.read(row['meas_path'])\n",
    "    target, fs_tar = sf.read(row['target_path'])\n",
    "\n",
    "    if fs!= FS_DNN :\n",
    "        meas = resample_poly(meas.astype(np.float32), FS_DNN, fs)\n",
    "        \n",
    "    if fs_tar != FS_DNN :\n",
    "        target = resample_poly(target.astype(np.float32), FS_DNN, fs_tar)\n",
    "    \n",
    "    # ---------- Compute clean reference signal for further methods ----------\n",
    "    # Synchronize signals \n",
    "    meas, target, lag =hlp.synch_sigs(meas,target)\n",
    "    print( \"Processing row \" +str(idx)+ \". lag is : \"+str(lag))\n",
    "    \n",
    "    # Store original SPLs\n",
    "    meas_spl_l = get_spl(meas[:,0])\n",
    "    meas_spl_r = get_spl(meas[:,1])\n",
    "\n",
    "    # match lengtha and signal energy, make sure they don't clip\n",
    "    crop = int(np.min([len(meas), len(target)]))\n",
    "    meas = meas[:crop, :]\n",
    "    target = target[:crop, :]\n",
    "    target *= np.sqrt((meas ** 2).sum() /((target ** 2).sum()))\n",
    "    norm_fac = np.max((np.max(np.abs(meas)), np.max(np.abs(target))))\n",
    "    meas /= norm_fac\n",
    "    target /= norm_fac\n",
    "\n",
    "    # ------------- Objective measure : SI-SDR -------------\n",
    "    sisdr_L = SISDR(target[:,0], meas[:,0]).item()\n",
    "    sisdr_R = SISDR(target[:,1], meas[:,1]).item()\n",
    "    sisdr = max(sisdr_L, sisdr_R)\n",
    "\n",
    "    # ------------- Objective measure : MBSTOI -------------\n",
    "    mbstoi_B = mbstoi(\n",
    "        left_ear_clean=target[:,0],\n",
    "        right_ear_clean=target[:,1],\n",
    "        left_ear_noisy=meas[:,0],\n",
    "        right_ear_noisy=meas[:,1],\n",
    "        fs_signal=FS_DNN,  # signal sample rate\n",
    "        sample_rate=9000,  # operating sample rate\n",
    "        fft_size_in_samples=64,\n",
    "        n_third_octave_bands=5,\n",
    "        centre_freq_first_third_octave_hz=500,\n",
    "        dyn_range=60,\n",
    "    )\n",
    "    # ------------- Objective measures : HASQI and HASPI -------------\n",
    "    hearing_loss = np.array([0, 0, 0, 0, 0, 0])\n",
    "    equalisation_mode=1\n",
    "    level1=70 # the calibrated level of the reference signal\n",
    "    \n",
    "    # compute spl for each channel of the measure\n",
    "    meas_spl_l -= level1\n",
    "    meas_spl_r -= level1\n",
    "    gain_l = 10**(meas_spl_l / 20) # spl gain compared to the 70dB reference\n",
    "    gain_r = 10**(meas_spl_r / 20)\n",
    "\n",
    "    # normalize to RMS==1\n",
    "    meas_l = norm_rms(meas[:,0])\n",
    "    meas_r = norm_rms(meas[:,1])\n",
    "    target_l = norm_rms(target[:, 0])\n",
    "    target_r = norm_rms(target[:,1])\n",
    "    \n",
    "    # apply gain\n",
    "    meas_l *= gain_l\n",
    "    meas_r *= gain_r\n",
    "    \n",
    "    hasqi_L, _, _, _ = hasqi_v2(target_l, FS_DNN, meas_l, FS_DNN, hearing_loss, equalisation_mode, level1)\n",
    "    hasqi_R, _, _, _ = hasqi_v2(target_r, FS_DNN, meas_r, FS_DNN, hearing_loss, equalisation_mode, level1)\n",
    "    hasqi = np.max((hasqi_L, hasqi_R))\n",
    "\n",
    "    haspi_L, _ = haspi_v2(target_l, FS_DNN, meas_l, FS_DNN, hearing_loss, level1)\n",
    "    haspi_R, _ = haspi_v2(target_r, FS_DNN, meas_r, FS_DNN, hearing_loss, level1)\n",
    "    haspi = np.max((haspi_L, haspi_R))\n",
    "\n",
    "    # ------------- Magnitude square coherence -------------\n",
    "    return idx, hasqi_L, hasqi_R, hasqi, haspi_L, haspi_R, haspi, sisdr_L, sisdr_R, sisdr, mbstoi_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    NUM_OF_WORKERS = 8\n",
    "    t0 = time.time()\n",
    "    with Pool(NUM_OF_WORKERS) as pool:\n",
    "        results = [pool.apply_async(compute_obj_measures, [idx, row]) for idx, row in df.iterrows()]\n",
    "        for result in results:\n",
    "            idx, hasqi_L, hasqi_R, hasqi, haspi_L, haspi_R, haspi, sisdr_L, sisdr_R, sisdr, mbstoi = result.get()\n",
    "            df.loc[idx, 'haspi_L'] = haspi_L\n",
    "            df.loc[idx, 'haspi_R'] = haspi_R\n",
    "            df.loc[idx, 'haspi'] = haspi\n",
    "            df.loc[idx, 'hasqi_L'] = hasqi_L\n",
    "            df.loc[idx, 'hasqi_R'] = hasqi_R\n",
    "            df.loc[idx, 'hasqi'] = hasqi\n",
    "            df.loc[idx, 'sisdr_L'] = sisdr_L\n",
    "            df.loc[idx, 'sisdr_R'] = sisdr_R\n",
    "            df.loc[idx, 'sisdr'] = sisdr\n",
    "            df.loc[idx, 'mbstoi'] = mbstoi\n",
    "            \n",
    "df.to_csv('results.csv')\n",
    "print('Took '+ str(time.time()-t0)+' seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('results.csv')\n",
    "\n",
    "aux=df[df['processing']!='dnn_mild_noncausal']\n",
    "\n",
    "aux=aux[aux['processing']!='dnn_mild_causal']\n",
    "\n",
    "aux['dev_group']=aux['ha_model']\n",
    "aux.loc[aux['dev_group'].str.contains('gn3'),'dev_group']='d1'\n",
    "aux.loc[aux['dev_group'].str.contains('gn5'),'dev_group']='d2'\n",
    "aux.loc[aux['dev_group'].str.contains('si3'),'dev_group']='d3'\n",
    "aux.loc[aux['dev_group'].str.contains('ph5'),'dev_group']='d4'\n",
    "aux.loc[aux['dev_group'].str.contains('ph4'),'dev_group']='d5'\n",
    "\n",
    "\n",
    "# create a reference dataframe with repeated resulta for bypass recording \n",
    "bypass=aux[aux[\"processing\"]==\"bypass\"]\n",
    "bypass=pd.concat([bypass]*3)\n",
    "\n",
    "# create a reference dataframe with results for all processing methods\n",
    "ha=aux[aux[\"processing\"]==\"ha\"]\n",
    "dnn1=aux[aux[\"processing\"]==\"dnn_normal_causal\"]\n",
    "dnn2=aux[aux[\"processing\"]==\"dnn_normal_noncausal\"]\n",
    "\n",
    "\n",
    "\n",
    "processed = pd.concat([ha, dnn1], ignore_index=True)\n",
    "processed = pd.concat([processed, dnn2], ignore_index=True)\n",
    "\n",
    "# make\n",
    "\n",
    "# sure the two dataframes that are going to be compared have values sorted in the same way\n",
    "bypass=bypass.reset_index(drop=True)\n",
    "processed=processed.reset_index(drop=True)\n",
    "print(bypass['scene'].equals(processed['scene']))\n",
    "print(bypass['ha_model'].equals(processed['ha_model']))\n",
    "print(bypass['degree '].equals(processed['degree ']))\n",
    "\n",
    "# dataframe with difference measures (benefit of each measure)\n",
    "aux_delta=processed\n",
    "aux_delta['haspi']=processed['haspi']-bypass['haspi']\n",
    "aux_delta['hasqi']=processed['hasqi']-bypass['hasqi']\n",
    "aux_delta['mbstoi']=processed['mbstoi']-bypass['mbstoi']\n",
    "aux_delta['sisdr']=processed['sisdr']-bypass['sisdr']\n",
    "\n",
    "aux_delta = aux_delta.replace('ha', 'HA')\n",
    "aux_delta = aux_delta.replace('dnn_normal_noncausal', 'DNN')\n",
    "aux_delta = aux_delta.replace('dnn_normal_causal', 'DNN-C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(len(aux_delta))\n",
    "sns.set(rc={'axes.facecolor':'lightgrey', 'figure.facecolor':'none'})\n",
    "fig, axes = plt.subplots(2, 2, figsize=(8, 5))\n",
    "print(axes.shape)\n",
    "sns.set(font_scale=0.7)\n",
    "sns.violinplot(ax=axes[0,0], data=aux_delta, y='haspi', x='processing',palette=\"colorblind\")\n",
    "sns.violinplot(ax=axes[0,1],data=aux_delta, y='hasqi', x='processing',palette=\"colorblind\")\n",
    "sns.violinplot(ax=axes[1,0],data=aux_delta, y='sisdr', x='processing',palette=\"colorblind\")\n",
    "sns.violinplot(ax=axes[1,1],data=aux_delta, y='mbstoi', x='processing',palette=\"colorblind\")\n",
    "axes[0,0].set_title('$\\Delta$HASPI', fontsize=13)\n",
    "axes[0,1].set_title('$\\Delta$HASQI', fontsize=13)\n",
    "axes[1,0].set_title('$\\Delta$SISDR', fontsize=13)\n",
    "axes[1,1].set_title('$\\Delta$MBSTOI', fontsize=13)\n",
    "axes[0,0].set_xlabel('')\n",
    "axes[0,1].set_xlabel('')\n",
    "axes[1,0].set_xlabel('')\n",
    "axes[1,1].set_xlabel('')\n",
    "axes[0,0].set_ylabel('')\n",
    "axes[0,1].set_ylabel('')\n",
    "axes[1,0].set_ylabel('')\n",
    "axes[1,1].set_ylabel('')\n",
    "#axes[0,0].set_ylim((-0.2,0.4))\n",
    "#axes[0,1].set_ylim((-0.2,0.3))\n",
    "#axes[1,1].set_ylim((-0.2,0.3))\n",
    "# axes[0,0].set_xticklabels(['HA','DNN','DNN-C'], rotation=0)\n",
    "# axes[0,1].set_xticklabels(['HA','DNN','DNN-C'], rotation=0)\n",
    "# axes[1,0].set_xticklabels(['HA','DNN','DNN-C'], rotation=0)\n",
    "# axes[1,1].set_xticklabels(['HA','DNN','DNN-C'], rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join('figures', 'basic_plot.pdf'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "aux = aux.replace('gn3_h', 'device 1')\n",
    "aux = aux.replace('gn3_l', 'device 1')\n",
    "aux = aux.replace('gn3_m', 'device 1')\n",
    "aux = aux.replace('gn5_h', 'device 2')\n",
    "aux = aux.replace('gn5_l', 'device 2')\n",
    "aux = aux.replace('gn5_m', 'device 2')\n",
    "aux = aux.replace('ph4_m', 'device 3')\n",
    "aux = aux.replace('ph4_s', 'device 3')\n",
    "aux = aux.replace('ph4_p', 'device 3')\n",
    "aux = aux.replace('ph5_m', 'device 4')\n",
    "aux = aux.replace('ph5_s', 'device 4')\n",
    "aux = aux.replace('ph5_p', 'device 4')\n",
    "aux = aux.replace('si3_m', 'device 5')\n",
    "aux = aux.replace('si3_s', 'device 5')\n",
    "aux = aux.replace('si3_p', 'device 5')\n",
    "'''\n",
    "aux = aux.replace('d1', 'device 5')\n",
    "aux = aux.replace('d2', 'device 4')\n",
    "aux = aux.replace('d3', 'device 1')\n",
    "aux = aux.replace('d4', 'device 3')\n",
    "aux = aux.replace('d5', 'device 2')\n",
    "\n",
    "aux = aux.replace('bypass', 'Bypass')\n",
    "aux = aux.replace('ha', 'HA')\n",
    "aux = aux.replace('dnn_normal_noncausal', 'DNN')\n",
    "aux = aux.replace('dnn_normal_causal', 'DNN-C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'axes.facecolor':'lightgrey', 'figure.facecolor':'none'})\n",
    "plt.figure(figsize=(5, 8))\n",
    "plt.subplot(4,1,1)\n",
    "sns.barplot(data=aux, y='sisdr', x='processing',palette=\"colorblind\",hue='dev_group')\n",
    "plt.ylabel('SISDR')\n",
    "plt.xlabel('')\n",
    "plt.legend().set_visible(False)\n",
    "plt.tight_layout()\n",
    "plt.legend(bbox_to_anchor=(0.50, 1.5), loc=\"upper center\", ncol=3)\n",
    "plt.ylim([-15, 0])\n",
    "plt.yticks([-12, -9, -6, -3, 0])\n",
    "plt.subplot(4,1,2)\n",
    "\n",
    "sns.barplot(data=aux, y='haspi', x='processing',palette=\"colorblind\",hue='dev_group')\n",
    "plt.ylabel('HASPI')\n",
    "plt.xlabel('')\n",
    "plt.legend().set_visible(False)\n",
    "plt.tight_layout()\n",
    "plt.ylim([0.2, 0.9])\n",
    "plt.yticks([0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "plt.subplot(4,1,3)\n",
    "sns.barplot(data=aux, y='hasqi', x='processing',palette=\"colorblind\",hue='dev_group')\n",
    "plt.ylabel('HASQI')\n",
    "plt.xlabel('')\n",
    "plt.legend().set_visible(False)\n",
    "plt.tight_layout()\n",
    "plt.ylim([0.05, 0.23])\n",
    "plt.yticks([0.05, 0.1, 0.15, 0.2, 0.25])\n",
    "\n",
    "\n",
    "plt.subplot(4,1,4)\n",
    "sns.barplot(data=aux, y='mbstoi', x='processing',palette=\"colorblind\",hue='dev_group')\n",
    "plt.ylabel('MBSTOI')\n",
    "plt.xlabel('')\n",
    "plt.legend().set_visible(False)\n",
    "plt.tight_layout()\n",
    "plt.ylim([0.3, 0.75]);\n",
    "plt.yticks([0.3, 0.4, 0.5, 0.6, 0.7])\n",
    "plt.savefig(os.path.join('figures', 'bar_plot.pdf'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LibriMix3D",
   "language": "python",
   "name": "librimix3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

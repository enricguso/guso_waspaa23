{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.io import wavfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.fft\n",
    "from scipy.signal import resample_poly\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "\n",
    "\n",
    "# import my modules (helpers.py where I stored all the functions):\n",
    "import helpers as hlp\n",
    "import importlib \n",
    "importlib.reload(hlp)\n",
    "from clarity.evaluator.hasqi import hasqi_v2\n",
    "from clarity.evaluator.haspi import haspi_v2 \n",
    "from clarity.evaluator.mbstoi import mbstoi \n",
    "import torch\n",
    "import sys\n",
    "from multiprocessing import Pool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All our directories in which we store recordings or dnn-processed recordings:\n",
    "data_source_dirs=[\n",
    "    '/home/ubuntu/Data/ha_listening_situations/recordings/ku_recordings/',\n",
    "    '/home/ubuntu/Data/ha_listening_situations/processed_m1_alldata_normal/ku_processed/',\n",
    "    '/home/ubuntu/Data/ha_listening_situations/processed_m3_alldata_mild/ku_processed/',\n",
    "    '/home/ubuntu/Data/ha_listening_situations/processed_m4_alldata_normal_causal/ku_processed/',\n",
    "    '/home/ubuntu/Data/ha_listening_situations/processed_m5_alldata_mild_causal/ku_processed/'\n",
    "]\n",
    "\n",
    "# Directory where all recordings used as reference are stored\n",
    "data_ref_dir='/home/ubuntu/Data/ha_listening_situations/recordings/ku_recordings/'\n",
    "\n",
    "# Names of hearing devices\n",
    "ha_models=[\"si3_s\",\"si3_m\",\"si3_p\",\"ph4_s\",\"ph4_m\",\"ph4_p\",\"ph5_s\",\"ph5_m\",\"ph5_p\",\n",
    "           \"gn5_l\",\"gn5_m\",\"gn5_h\",\"gn3_l\",\"gn3_m\",\"gn3_h\"]\n",
    "\n",
    "# Different listening scenes:\n",
    "scenenames=['party_0deg','party_30deg','restaurant_0deg','restaurant_30deg','meeting_0deg','meeting_30deg']\n",
    "\n",
    "# Initialize dataframe, in which each row will represent one pair of plus and minus recording\n",
    "# and all the info and objective measures associated with that pair. \n",
    "measures=pd.DataFrame(columns=['device','dnn_applied','plus_file','minus_file', 'plus_ref_file','minus_ref_file', 'scene'])\n",
    "\n",
    "dnntypes=[]\n",
    "pluses=[]\n",
    "minuses=[]\n",
    "refpluses=[]\n",
    "refminuses=[]\n",
    "scenes=[]\n",
    "devices=[]\n",
    "for i, data_source_dir in enumerate(data_source_dirs):\n",
    "    for item in sorted(os.listdir(data_source_dir)):\n",
    "        if os.path.isdir(data_source_dir+item):\n",
    "            recording_name=item\n",
    "            # this line identifies the current device name:\n",
    "            device_id=[model for model in ha_models if model in recording_name]\n",
    "            if len(device_id)>0:\n",
    "                # this line finds the corresponding bypass recording name:\n",
    "                ref_recording_name = [dirname for dirname in os.listdir(data_source_dir)\n",
    "                if os.path.isdir(data_source_dir+dirname) and device_id[0] in dirname and \"bypass\" in dirname][0]\n",
    "            else:\n",
    "                ref_recording_name=recording_name\n",
    "            \n",
    "            for scene in scenenames:\n",
    "                # paths for recorded plus and minus signals (data_source_dir + recording_name)\n",
    "                plusfilepath=data_source_dir+recording_name+'/'+recording_name+'_plus_'+scene+'.wav'\n",
    "                minusfilepath=data_source_dir+recording_name+'/'+recording_name+'_minus_'+scene+'.wav'\n",
    "                # paths for reference plus and minus signals (data_ref_dir + ref_recording_name)\n",
    "                plusrefpath=data_ref_dir+ref_recording_name+'/'+ref_recording_name+'_plus_'+scene+'.wav'\n",
    "                minusrefpath=data_ref_dir+ref_recording_name+'/'+ref_recording_name+'_minus_'+scene+'.wav'\n",
    "\n",
    "                applieddnntype=i\n",
    "                devices.append(recording_name)\n",
    "                pluses.append(plusfilepath)\n",
    "                minuses.append(minusfilepath)\n",
    "                refpluses.append(plusrefpath)\n",
    "                refminuses.append(minusrefpath)\n",
    "                scenes.append(scene)\n",
    "                dnntypes.append(applieddnntype)\n",
    "\n",
    "measures['device']=devices            \n",
    "measures['dnn_applied']=dnntypes\n",
    "measures['plus_file']=pluses\n",
    "measures['minus_file']=minuses\n",
    "measures['plus_ref_file']=refpluses\n",
    "measures['minus_ref_file']=refminuses\n",
    "measures['scene']=scenes\n",
    "\n",
    "\n",
    "# Make sure to remove the lines where the \"enabled\" recording is processed and lines where ku100 recording is processed \n",
    "# (we are only interested in dnn-processed bypass recordings):\n",
    "print(f'before: {len(measures)=}')\n",
    "measures=measures[~((measures[\"device\"].str.contains(\"enabled\")) & (measures[\"dnn_applied\"]>0))]\n",
    "measures=measures[~((measures[\"device\"].str.contains(\"001_ku100\")) & (measures[\"dnn_applied\"]>0))]\n",
    "measures=measures[~((measures[\"device\"].str.contains(\"fulldenoising\")) & (measures[\"dnn_applied\"]>0))]\n",
    "print(f'after: {len(measures)=}')\n",
    "\n",
    "# Within the group that is not processed by any dnn model we have to distinguish 3 categories and give them labels: \n",
    "# ---> unprocessed reference: ku100 recordings without a hearing aid\n",
    "measures.loc[measures[\"device\"].str.contains(\"001_ku100\"), \"dnn_applied\"]=0.1\n",
    "# ---> unprocessed bypass: recordings with hearing aids in bypass\n",
    "measures.loc[((measures[\"device\"].str.contains(\"bypass\")) & (measures[\"dnn_applied\"]==0)), \"dnn_applied\"]=0.2\n",
    "# ---> unprocessed enabled: recordings with hearing aids enabled\n",
    "measures.loc[((measures[\"device\"].str.contains(\"enabled\")) & (measures[\"dnn_applied\"]==0)), \"dnn_applied\"]=0.3\n",
    "measures.loc[((measures[\"device\"].str.contains(\"fulldenoising\")) & (measures[\"dnn_applied\"]==0)), \"dnn_applied\"]=0.3\n",
    "\n",
    "measures.to_csv('meas.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SISDR(s, s_hat):\n",
    "    \"\"\"Computes the Scale-Invariant SDR as in [1]_.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Le Roux, Jonathan, et al. \"SDRâ€“half-baked or well done?.\" ICASSP 2019-2019 IEEE International Conference on\n",
    "    Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2019.\n",
    "    Parameters:\n",
    "        s: list of targets of any shape\n",
    "        s_hat: list of corresponding estimates of any shape\n",
    "    \"\"\"\n",
    "    s = torch.stack(s).view(-1)\n",
    "    EPS = torch.finfo(s.dtype).eps\n",
    "    s_hat = torch.stack(s_hat).view(-1)\n",
    "    a = (torch.dot(s_hat, s) * s) / ((s ** 2).sum() + EPS)\n",
    "    b = a - s_hat\n",
    "    return -10*torch.log10(((a*a).sum()) / ((b*b).sum()+EPS))\n",
    "\n",
    "def compute_obj_measures(idx, row):\n",
    "    # Function: Compute objective measures based on one row of a data frame \n",
    "    # ----- Input: -----\n",
    "    # idx - index in the original data frame\n",
    "    # row - row containing filenames of plus and minus recording\n",
    "    # ----- Output: -----\n",
    "    # tuple of objective measures: \n",
    "    # - snr_val: snr estimated with phase inversion technique\n",
    "    # - mbstoi_val: binaural speech intelligibility model\n",
    "    # - hasqi_left_val: hearing aid speech quality for 1 ear\n",
    "    # - hasqi_left_val: hearing aid speech perception index for 1 ear\n",
    "    # - sisdr_val: sudo-rm-rf method for computing sdr\n",
    "    # ----------------------------------------------------------------------\n",
    "    FS_TARGET=16e3\n",
    "    fs, plus = wavfile.read(row['plus_file'])\n",
    "    fs, minus = wavfile.read(row['minus_file'])\n",
    "    if fs!=16000:\n",
    "        plus = resample_poly(plus.astype(np.float32), FS_TARGET, fs)\n",
    "        minus = resample_poly(minus.astype(np.float32), FS_TARGET, fs)\n",
    "\n",
    "    fs, refplus = wavfile.read(row['plus_ref_file'])\n",
    "    fs, refminus = wavfile.read(row['minus_ref_file'])\n",
    "    if fs!=16000:\n",
    "        refplus = resample_poly(refplus.astype(np.float32), FS_TARGET, fs)\n",
    "        refminus = resample_poly(refminus.astype(np.float32), FS_TARGET, fs)\n",
    "    # ---------- Compute clean reference signal ----------\n",
    "    ref_s=0.5*(refplus+refminus)\n",
    "    # ------------- Objective measure 1: SNR -------------\n",
    "    s=0.5*(plus+minus)\n",
    "    n=0.5*(plus-minus)\n",
    "    snr_left_val = 10 * np.log10(hlp.power(s[:,0]) / hlp.power(n[:,0]))\n",
    "    snr_right_val = 10 * np.log10(hlp.power(s[:,1]) / hlp.power(n[:,1]))\n",
    "    snr_val =10 * np.log10(hlp.power(s) / hlp.power(n))\n",
    "    # ------------- Objective measure 2: MBSTOI -------------\n",
    "    mbstoi_val = mbstoi(\n",
    "        left_ear_clean=ref_s[:,0],\n",
    "        right_ear_clean=ref_s[:,1],\n",
    "        left_ear_noisy=plus[:,0],\n",
    "        right_ear_noisy=plus[:,1],\n",
    "        fs_signal=FS_TARGET,  # signal sample rate\n",
    "        sample_rate=9000,  # operating sample rate\n",
    "        fft_size_in_samples=64,\n",
    "        n_third_octave_bands=5,\n",
    "        centre_freq_first_third_octave_hz=500,\n",
    "        dyn_range=60,\n",
    "    )\n",
    "    # ------------- Objective measure 3 & 4: HASQI and HASPI -------------\n",
    "    hearing_loss = np.array([0, 0, 0, 0, 0, 0])\n",
    "    equalisation_mode=1\n",
    "    level1=65\n",
    "    hasqi_left_val, _, _, _ = hasqi_v2(ref_s[:,0], FS_TARGET, plus[:,0], FS_TARGET, hearing_loss, equalisation_mode, level1)\n",
    "    haspi_left_val, _ = haspi_v2(ref_s[:,0], FS_TARGET, plus[:,0] + ref_s[:,0], FS_TARGET, hearing_loss, level1)\n",
    "\n",
    "    # ------------- Objective measure 5: SI-SDR -------------\n",
    "    sisdr_val=SISDR([torch.from_numpy(ref_s)],[torch.from_numpy(plus)]).item()\n",
    "    print(str(idx)+ \"row\")\n",
    "    return idx, snr_left_val,snr_right_val,snr_val, mbstoi_val, hasqi_left_val, haspi_left_val,sisdr_val \n",
    "\n",
    "\n",
    "# The main script has to be in the same cell as the definition of the function\n",
    "if __name__ == '__main__':\n",
    "    NUM_OF_WORKERS = 8\n",
    "    with Pool(NUM_OF_WORKERS) as pool:\n",
    "        results = [pool.apply_async(compute_obj_measures, [idx, row]) for idx, row in measures.iterrows()]\n",
    "        for result in results:\n",
    "            idx, snr_left, snr_right, snr, mbstoi_v, hasqi_left, haspi_left, sisdr = result.get()\n",
    "            measures.loc[idx, 'snr_left'] = snr_left\n",
    "            measures.loc[idx, 'snr_right'] = snr_right\n",
    "            measures.loc[idx, 'snr'] = snr\n",
    "            measures.loc[idx, 'mbstoi'] = mbstoi_v\n",
    "            measures.loc[idx, 'hasqi_left'] = hasqi_left\n",
    "            measures.loc[idx, 'haspi_left'] = haspi_left\n",
    "            measures.loc[idx, 'sisdr'] = sisdr\n",
    "\n",
    "measures.to_csv('objective_measures2.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some important edits before plotting: \n",
    "\n",
    "# read dataframe \n",
    "measures_computed=pd.read_csv('objective_measures.csv')\n",
    "\n",
    "# Make sure to remove the lines where the \"enabled\" recording is processed and lines where ku100 recording is processed \n",
    "# (we are only interested in dnn-processed bypass recordings):\n",
    "print(f'before: {len(measures_computed)=}')\n",
    "measures_computed=measures_computed[~((measures_computed[\"device\"].str.contains(\"enabled\")) & (measures_computed[\"dnn_applied\"]>0))]\n",
    "measures_computed=measures_computed[~((measures_computed[\"device\"].str.contains(\"001_ku100\")) & (measures_computed[\"dnn_applied\"]>0))]\n",
    "measures_computed=measures_computed[~((measures_computed[\"device\"].str.contains(\"fulldenoising\")) & (measures_computed[\"dnn_applied\"]>0))]\n",
    "print(f'after: {len(measures_computed)=}')\n",
    "\n",
    "# Within the group that is not processed by any dnn model we have to distinguish 3 categories and give them labels: \n",
    "# ---> unprocessed reference: ku100 recordings without a hearing aid\n",
    "measures_computed.loc[measures_computed[\"device\"].str.contains(\"001_ku100\"), \"dnn_applied\"]=0.1\n",
    "# ---> unprocessed bypass: recordings with hearing aids in bypass\n",
    "measures_computed.loc[((measures_computed[\"device\"].str.contains(\"bypass\")) & (measures_computed[\"dnn_applied\"]==0)), \"dnn_applied\"]=0.2\n",
    "# ---> unprocessed enabled: recordings with hearing aids enabled\n",
    "measures_computed.loc[((measures_computed[\"device\"].str.contains(\"enabled\")) & (measures_computed[\"dnn_applied\"]==0)), \"dnn_applied\"]=0.3\n",
    "measures_computed.loc[((measures_computed[\"device\"].str.contains(\"fulldenoising\")) & (measures_computed[\"dnn_applied\"]==0)), \"dnn_applied\"]=0.3\n",
    "\n",
    "# For a better visibility, we add one column which specifies the hearing aid model (without division into different receivers)\n",
    "ha_models=[\"gn3\",\"gn5\",\"ph5\",\"ph4\",\"si3\",\"fulldenoising\",\"001_ku\"]\n",
    "for modelname in ha_models:\n",
    "    measures_computed.loc[measures_computed['device'].str.contains(modelname), \"device_group\"]=modelname\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import warnings\n",
    "  \n",
    "# Settings the warnings to be ignored\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def plot_1_measure(df,measure):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(25, 5), sharey=True) \n",
    "    sns.set(font_scale=0.8)\n",
    "    sns.swarmplot(ax=axes[1],data=df,x=\"dnn_applied\", y=measure, hue=\"device_group\")\n",
    "    sns.swarmplot(ax=axes[2],data=df,x=\"dnn_applied\", y=measure, hue=\"scene\")\n",
    "    df.boxplot(ax=axes[0],column=measure,by=\"dnn_applied\")\n",
    "    axes[0].set_xlabel('')\n",
    "    axes[1].set_xlabel('')\n",
    "    axes[2].set_xlabel('')\n",
    "    axes[0].set_title('Standard boxplot')\n",
    "    axes[1].set_title('Colored by devices')\n",
    "    axes[2].set_title('Colored by scene')\n",
    "    axes[0].set_xticklabels(['ref','bypass','HA','DNN-normal','DNN-mild','DNN-normal_C','DNN-mild_C'], rotation=45)\n",
    "    axes[1].set_xticklabels(['ref','bypass','HA','DNN-normal','DNN-mild','DNN-normal_C','DNN-mild_C'], rotation=45)\n",
    "    axes[2].set_xticklabels(['ref','bypass','HA','DNN-normal','DNN-mild','DNN-normal_C','DNN-mild_C'], rotation=45)\n",
    "    fig.suptitle('Measure: '+ measure)\n",
    "    plt.show()\n",
    "\n",
    "# Plot all measures:\n",
    "plot_1_measure(measures_computed,\"snr_left\")\n",
    "plot_1_measure(measures_computed,\"sisdr\")\n",
    "plot_1_measure(measures_computed,\"hasqi_left\")\n",
    "plot_1_measure(measures_computed,\"haspi_left\")\n",
    "plot_1_measure(measures_computed,\"mbstoi\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anova analysis...\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# perform three-way anova: how snr_left depends on 3 categorical variables (processing type, scene, and device group)\n",
    "model = ols(\"\"\"snr_left ~ C(dnn_applied) + C(scene) + C(device_group) +\n",
    "               C(dnn_applied):C(scene) + C(dnn_applied):C(device_group) + C(scene):C(device_group) +\n",
    "               C(dnn_applied):C(scene):C(device_group)\"\"\", data=measures_computed).fit()\n",
    "\n",
    "sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# TODO: Why isn't dnn_applied significant??? \n",
    "# TODO: bypass (plus/minus) vs processed (plus)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

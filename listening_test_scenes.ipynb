{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "import scipy.signal as sig\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import mat73\n",
    "import os\n",
    "import masp as srs\n",
    "from os.path import join as pjoin\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import my modules (helpers.py where I stored all the functions):\n",
    "import helpers as hlp\n",
    "import importlib\n",
    "importlib.reload(hlp);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_ANGLE=30\n",
    "target_snr = 5.\n",
    "fs=48000\n",
    "chunk_len = 30 #seconds\n",
    "tag='normal' #change to inverse when running for the second time\n",
    "speech_path = 'listening_situations_target_speech'\n",
    "arte_path = '/home/ubuntu/Data/ARTE'\n",
    "output_path = '/home/ubuntu/Data/ha_listening_situations/SH_versions/'+tag\n",
    "maxlim = 2\n",
    "ambi_order = 10\n",
    "rims_d = .0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mono2biSH(mono_sig, sh_rir):\n",
    "    # Apply audio to SH IR\n",
    "    left = sig.fftconvolve(np.tile(mono_sig[0], (121,1)).T, sh_rir[:,:,0, 0], 'full', 0)   \n",
    "    right = sig.fftconvolve(np.tile(mono_sig[0], (121,1)).T, sh_rir[:,:,1, 0], 'full', 0)\n",
    "    return np.array([left, right])\n",
    "def biSH2bin(sh_sig, decoder):\n",
    "    left = sig.fftconvolve(sh_sig[0], decoder[:,:,0], 'full', 0).sum(1)\n",
    "    right = sig.fftconvolve(sh_sig[1], decoder[:,:,1], 'full', 0).sum(1)\n",
    "    return np.array([left,right])\n",
    "\n",
    "def mono2sh(mono_sig, sh_rir):\n",
    "    # Apply audio to SH IR\n",
    "    left = sig.fftconvolve(np.tile(mono_sig[0], (121,1)).T, sh_rir[:,:,2, 0], 'full', 0)   \n",
    "    return left\n",
    "\n",
    "def sh2bin(sh_sig, decoder):\n",
    "    left = sig.fftconvolve(sh_sig, decoder[:,:,0], 'full', 0).sum(1)\n",
    "    right = sig.fftconvolve(sh_sig, decoder[:,:,1], 'full', 0).sum(1)\n",
    "    return np.array([left,right])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------- DECODE TO BINAURAL ----------------\n",
    "decoder = mat73.loadmat(pjoin('decoders_ord10', 'Ku100_ALFE_Window_sinEQ_bimag.mat'))['hnm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCENE 1: PARTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------- DESIGN SCENE ----------------\n",
    "room = np.array([15., 10., 3.5]) \n",
    "rt60 = np.array([.4])\n",
    "head_pos= np.array([room[0]/2, room[1]/2, 1.6]) # Listener coordinates\n",
    "target_pos= hlp.place_on_circle(head_pos,1,TARGET_ANGLE)\n",
    "head_orient = np.array([0, 0]) # Head rotation\n",
    "ears_pos=hlp.head_2_ku_ears(head_pos,head_orient)\n",
    "\n",
    "# --------------- COMPUTE ECHOGRAMS ----------------\n",
    "# Compute absorption coefficients for desired rt60 and room dimensions\n",
    "abs_walls,rt60_true = srs.find_abs_coeffs_from_rt(room, rt60)\n",
    "# Small correction for sound absorption coefficients:\n",
    "if sum(rt60_true-rt60>0.05*rt60_true)>0 :\n",
    "    abs_walls,rt60_true = srs.find_abs_coeffs_from_rt(room, rt60_true + abs(rt60-rt60_true))\n",
    "# Generally, we simulate up to RT60:\n",
    "limits = np.minimum(rt60, maxlim)\n",
    "\n",
    "mic = np.array([ears_pos[0], ears_pos[1], list(head_pos)]) #two positions for the binaural, one for the SH\n",
    "src = np.array(target_pos)\n",
    "nRec = mic.shape[0]\n",
    "nSrc = src.shape[0]\n",
    "\n",
    "# Compute the echograms, which means how many reflections, at what time and from which coordinates:\n",
    "abs_echograms = srs.compute_echograms_sh(room, src, mic, abs_walls, limits, ambi_order, rims_d, head_orient)\n",
    "ane_echograms = hlp.crop_echogram(copy.deepcopy(abs_echograms))\n",
    "# --------------- RENDER ECHOGRAMS ----------------\n",
    "band_centerfreqs=np.array([1000])\n",
    "mic_rirs = srs.render_rirs_sh(abs_echograms, band_centerfreqs, fs)\n",
    "ane_rirs = srs.render_rirs_sh(ane_echograms, band_centerfreqs, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hlp.plot_scene(room,head_pos,head_orient,ears_pos,target_pos,perspective=\"xy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- SOUND FILES -----------------\n",
    "# Noise in ambisonics:\n",
    "noise_sig, fs_noise = sf.read(pjoin(arte_path,'09_Dinner_party_MOA_31ch.wav'))\n",
    "noise_sig = sig.resample_poly(noise_sig, fs, fs_noise)\n",
    "noise_sig = noise_sig[:chunk_len*fs] \n",
    "# pad noise signal to 121 channels \n",
    "zeropads=np.zeros([noise_sig.shape[0],121-31])\n",
    "noise_sig =np.concatenate((noise_sig,zeropads),axis=1)\n",
    "\n",
    "# Target in mono:\n",
    "#target_sig, fs_targ = sf.read(pjoin(speech_path, 'esp_libri_speech_female_48k.wav'))\n",
    "target_sig, fs_targ = sf.read(pjoin(speech_path, 'target1.wav'))\n",
    "target_sig = np.squeeze(target_sig[:,0])\n",
    "target_sig = sig.resample_poly(target_sig, fs, fs_targ)\n",
    "# cut speech signal to the length of the noise (about 2 min)\n",
    "target_sig=target_sig[:noise_sig.shape[0]]\n",
    "target_sig=np.array(target_sig,ndmin=2)\n",
    "\n",
    "# Target to SH\n",
    "target_biSH = mono2biSH(target_sig, mic_rirs)\n",
    "ane_target_biSH = mono2biSH(target_sig, ane_rirs)\n",
    "target_sh = mono2sh(target_sig, mic_rirs)\n",
    "ane_target_sh = mono2sh(target_sig, ane_rirs)\n",
    "# crop all to equal length:\n",
    "target_biSH = target_biSH[:, :chunk_len*fs]\n",
    "ane_target_biSH = ane_target_biSH[:, :chunk_len*fs]\n",
    "target_sh = target_sh[:chunk_len*fs]\n",
    "ane_target_sh = ane_target_sh[:chunk_len*fs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the single soundfield case (for speaker reproduction)\n",
    "ini_snr = 10 * np.log10(hlp.power(sh2bin(target_sh, decoder)) / hlp.power(sh2bin(noise_sig, decoder)))\n",
    "target_snr = 5.\n",
    "noise_gain_db = ini_snr - target_snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_noise = noise_sig * np.power(10, noise_gain_db/20)\n",
    "# normalize SH signals so that the binaural mixture is in [-1, 1] and it doesn't clip\n",
    "norm_fact = np.max(np.abs(sh2bin(target_sh + scaled_noise, decoder)))\n",
    "\n",
    "target_sh /= norm_fact\n",
    "scaled_noise /= norm_fact\n",
    "ane_target_sh /= norm_fact\n",
    "if tag == 'inverse': \n",
    "    scaled_noise = -scaled_noise\n",
    "mixture = target_sh + scaled_noise\n",
    "reverb = target_sh - ane_target_sh\n",
    "\n",
    "snr = 10 * np.log10(hlp.power(sh2bin(target_sh, decoder)) / hlp.power(sh2bin(scaled_noise, decoder)))\n",
    "\n",
    "sf.write(pjoin(speech_path, f\"{tag}_party_SH_deg{TARGET_ANGLE}_snr{int(target_snr)}_{fs}hz.wav\"), mixture, fs, subtype='FLOAT')\n",
    "\n",
    "Audio(sh2bin(mixture, decoder), rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we downmix to binaural only for listening purpose (combine single noise soundfield with two source soundfiels):\n",
    "bin_noise = sh2bin(noise_sig, decoder)\n",
    "bin_target = biSH2bin(target_biSH, decoder)\n",
    "bin_ane = biSH2bin(ane_target_biSH, decoder)\n",
    "\n",
    "bin_snr = 10 * np.log10(hlp.power(bin_target) / hlp.power(bin_noise))\n",
    "\n",
    "noise_gain_db = bin_snr - target_snr\n",
    "\n",
    "bin_noise = bin_noise * np.power(10, noise_gain_db/20)\n",
    "norm_fact = np.max(np.abs(bin_noise + bin_target))\n",
    "\n",
    "\n",
    "bin_noise /= norm_fact\n",
    "bin_target /= norm_fact\n",
    "bin_ane /= norm_fact\n",
    "\n",
    "if tag == 'inverse': \n",
    "    bin_noise = -bin_noise\n",
    "    \n",
    "bin_mixture = bin_noise + bin_target\n",
    "bin_reverb = bin_target - bin_ane\n",
    "\n",
    "bin_mildmix = 0.25*bin_noise + 0.25*bin_reverb + bin_ane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(bin_mildmix, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(bin_ane, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(bin_target, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(bin_reverb, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.write(pjoin(speech_path,f\"{tag}_party_bin_deg{TARGET_ANGLE}_snr{int(target_snr)}_mixture_{fs}hz.wav\"), bin_mixture.T, fs, subtype='FLOAT')\n",
    "sf.write(pjoin(speech_path,f\"{tag}_party_bin_deg{TARGET_ANGLE}_snr{int(target_snr)}_mildmix_{fs}hz.wav\"), bin_mildmix.T, fs, subtype='FLOAT')\n",
    "sf.write(pjoin(speech_path,f\"{tag}_party_bin_deg{TARGET_ANGLE}_snr{int(target_snr)}_noise_{fs}hz.wav\"), bin_noise.T, fs, subtype='FLOAT')\n",
    "sf.write(pjoin(speech_path,f\"{tag}_party_bin_deg{TARGET_ANGLE}_snr{int(target_snr)}_ane_{fs}hz.wav\"), bin_ane.T, fs, subtype='FLOAT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCENE 2: RESTAURANT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------- DESIGN SCENE ----------------\n",
    "room = np.array([28., 17., 4.2]) \n",
    "rt60 = np.array([1.1]) * 0.5 # i feel this is too much... sounds like a cave\n",
    "head_pos= np.array([room[0]/2, room[1]/2, 1.3]) # Listener coordinates\n",
    "target_pos= hlp.place_on_circle(head_pos,1,TARGET_ANGLE)\n",
    "head_orient = np.array([0, 0]) # Head rotation\n",
    "ears_pos=hlp.head_2_ku_ears(head_pos,head_orient)\n",
    "\n",
    "# --------------- COMPUTE ECHOGRAMS ----------------\n",
    "# Compute absorption coefficients for desired rt60 and room dimensions\n",
    "abs_walls,rt60_true = srs.find_abs_coeffs_from_rt(room, rt60)\n",
    "# Small correction for sound absorption coefficients:\n",
    "if sum(rt60_true-rt60>0.05*rt60_true)>0 :\n",
    "    abs_walls,rt60_true = srs.find_abs_coeffs_from_rt(room, rt60_true + abs(rt60-rt60_true))\n",
    "# Generally, we simulate up to RT60:\n",
    "limits = np.minimum(rt60, maxlim)\n",
    "\n",
    "mic = np.array([ears_pos[0], ears_pos[1], list(head_pos)]) #two positions for the binaural, one for the SH\n",
    "src = np.array(target_pos)\n",
    "nRec = mic.shape[0]\n",
    "nSrc = src.shape[0]\n",
    "\n",
    "# Compute the echograms, which means how many reflections, at what time and from which coordinates:\n",
    "abs_echograms = srs.compute_echograms_sh(room, src, mic, abs_walls, limits, ambi_order, rims_d, head_orient)\n",
    "ane_echograms = hlp.crop_echogram(copy.deepcopy(abs_echograms))\n",
    "# --------------- RENDER ECHOGRAMS ----------------\n",
    "band_centerfreqs=np.array([1000])\n",
    "mic_rirs = srs.render_rirs_sh(abs_echograms, band_centerfreqs, fs)\n",
    "ane_rirs = srs.render_rirs_sh(ane_echograms, band_centerfreqs, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hlp.plot_scene(room,head_pos,head_orient,ears_pos,target_pos,perspective=\"xy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- SOUND FILES -----------------\n",
    "# Noise in ambisonics:\n",
    "noise_sig, fs_noise = sf.read(pjoin(speech_path, '07_Cafe_1_MOA_31ch.wav'))\n",
    "noise_sig = sig.resample_poly(noise_sig, fs, fs_noise)\n",
    "noise_sig = noise_sig[:chunk_len*fs] \n",
    "# pad noise signal to 121 channels \n",
    "zeropads=np.zeros([noise_sig.shape[0],121-31])\n",
    "noise_sig =np.concatenate((noise_sig,zeropads),axis=1)\n",
    "\n",
    "# Target in mono:\n",
    "target_sig, fs_targ = sf.read(pjoin(speech_path, 'target1.wav'))\n",
    "target_sig = np.squeeze(target_sig[:,0])\n",
    "target_sig = sig.resample_poly(target_sig, fs, fs_targ)\n",
    "# cut speech signal to the length of the noise (about 2 min)\n",
    "target_sig=target_sig[:noise_sig.shape[0]]\n",
    "target_sig=np.array(target_sig,ndmin=2)\n",
    "\n",
    "# Target to SH\n",
    "target_biSH = mono2biSH(target_sig, mic_rirs)\n",
    "ane_target_biSH = mono2biSH(target_sig, ane_rirs)\n",
    "target_sh = mono2sh(target_sig, mic_rirs)\n",
    "ane_target_sh = mono2sh(target_sig, ane_rirs)\n",
    "# crop all to equal length:\n",
    "target_biSH = target_biSH[:, :chunk_len*fs]\n",
    "ane_target_biSH = ane_target_biSH[:, :chunk_len*fs]\n",
    "target_sh = target_sh[:chunk_len*fs]\n",
    "ane_target_sh = ane_target_sh[:chunk_len*fs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the single soundfield case (for speaker reproduction)\n",
    "ini_snr = 10 * np.log10(hlp.power(sh2bin(target_sh, decoder)) / hlp.power(sh2bin(noise_sig, decoder)))\n",
    "target_snr = 5.\n",
    "noise_gain_db = ini_snr - target_snr\n",
    "    \n",
    "scaled_noise = noise_sig * np.power(10, noise_gain_db/20)\n",
    "# normalize SH signals so that the binaural mixture is in [-1, 1] and it doesn't clip\n",
    "norm_fact = np.max(np.abs(sh2bin(target_sh + scaled_noise, decoder)))\n",
    "\n",
    "target_sh /= norm_fact\n",
    "scaled_noise /= norm_fact\n",
    "ane_target_sh /= norm_fact\n",
    "if tag == 'inverse': \n",
    "    scaled_noise = -scaled_noise\n",
    "mixture = target_sh + scaled_noise  \n",
    "reverb = target_sh - ane_target_sh\n",
    "\n",
    "snr = 10 * np.log10(hlp.power(sh2bin(target_sh, decoder)) / hlp.power(sh2bin(scaled_noise, decoder)))\n",
    "\n",
    "\n",
    "sf.write(pjoin(speech_path, f\"{tag}_restaurant_SH_deg{TARGET_ANGLE}_snr{int(target_snr)}_{fs}hz.wav\"), mixture, fs, subtype='FLOAT')\n",
    "Audio(sh2bin(mixture, decoder), rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we downmix to binaural only for listening purpose (combine single noise soundfield with two source soundfiels):\n",
    "bin_noise = sh2bin(noise_sig, decoder)\n",
    "bin_target = biSH2bin(target_biSH, decoder)\n",
    "bin_ane = biSH2bin(ane_target_biSH, decoder)\n",
    "\n",
    "bin_snr = 10 * np.log10(hlp.power(bin_target) / hlp.power(bin_noise))\n",
    "\n",
    "noise_gain_db = bin_snr - target_snr\n",
    "\n",
    "bin_noise = bin_noise * np.power(10, noise_gain_db/20)\n",
    "norm_fact = np.max(np.abs(bin_noise + bin_target))\n",
    "\n",
    "\n",
    "bin_noise /= norm_fact\n",
    "bin_target /= norm_fact\n",
    "bin_ane /= norm_fact\n",
    "if tag == 'inverse': \n",
    "    bin_noise = -bin_noise\n",
    "bin_mixture = bin_noise + bin_target\n",
    "bin_reverb = bin_target - bin_ane\n",
    "\n",
    "bin_mildmix = 0.25*bin_noise + 0.25*bin_reverb + bin_ane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(bin_ane, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(bin_target, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(bin_reverb, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.write(pjoin(speech_path,f\"{tag}_restaurant_bin_deg{TARGET_ANGLE}_snr{int(target_snr)}_mixture_{fs}hz.wav\"), bin_mixture.T, fs, subtype='FLOAT')\n",
    "sf.write(pjoin(speech_path,f\"{tag}_restaurant_bin_deg{TARGET_ANGLE}_snr{int(target_snr)}_mildmix_{fs}hz.wav\"), bin_mildmix.T, fs, subtype='FLOAT')\n",
    "sf.write(pjoin(speech_path,f\"{tag}_restaurant_bin_deg{TARGET_ANGLE}_snr{int(target_snr)}_noise_{fs}hz.wav\"), bin_noise.T, fs, subtype='FLOAT')\n",
    "sf.write(pjoin(speech_path,f\"{tag}_restaurant_bin_deg{TARGET_ANGLE}_snr{int(target_snr)}_ane_{fs}hz.wav\"), bin_ane.T, fs, subtype='FLOAT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCENE 3: MEETING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------- DESIGN SCENE ----------------\n",
    "room = np.array([5., 2., 2.5]) \n",
    "rt60 = np.array([0.2]) * 0.6\n",
    "head_pos= np.array([room[0]/2, room[1]/2, 1.3]) # Listener coordinates\n",
    "target_pos= hlp.place_on_circle(head_pos,1,TARGET_ANGLE)\n",
    "head_orient = np.array([0, 0]) # Head rotation\n",
    "ears_pos=hlp.head_2_ku_ears(head_pos,head_orient)\n",
    "\n",
    "# --------------- COMPUTE ECHOGRAMS ----------------\n",
    "# Compute absorption coefficients for desired rt60 and room dimensions\n",
    "abs_walls,rt60_true = srs.find_abs_coeffs_from_rt(room, rt60)\n",
    "# Small correction for sound absorption coefficients:\n",
    "if sum(rt60_true-rt60>0.05*rt60_true)>0 :\n",
    "    abs_walls,rt60_true = srs.find_abs_coeffs_from_rt(room, rt60_true + abs(rt60-rt60_true))\n",
    "# Generally, we simulate up to RT60:\n",
    "limits = np.minimum(rt60, maxlim)\n",
    "\n",
    "mic = np.array([ears_pos[0], ears_pos[1], list(head_pos)]) #two positions for the binaural, one for the SH\n",
    "src = np.array(target_pos)\n",
    "nRec = mic.shape[0]\n",
    "nSrc = src.shape[0]\n",
    "\n",
    "# Compute the echograms, which means how many reflections, at what time and from which coordinates:\n",
    "abs_echograms = srs.compute_echograms_sh(room, src, mic, abs_walls, limits, ambi_order, rims_d, head_orient)\n",
    "ane_echograms = hlp.crop_echogram(copy.deepcopy(abs_echograms))\n",
    "# --------------- RENDER ECHOGRAMS ----------------\n",
    "band_centerfreqs=np.array([1000])\n",
    "mic_rirs = srs.render_rirs_sh(abs_echograms, band_centerfreqs, fs)\n",
    "ane_rirs = srs.render_rirs_sh(ane_echograms, band_centerfreqs, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hlp.plot_scene(room,head_pos,head_orient,ears_pos,target_pos,perspective=\"xy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- SOUND FILES -----------------\n",
    "# Noise in ambisonics:\n",
    "noise_sig, fs_noise = sf.read(pjoin(speech_path, '02_Office_MOA_31ch.wav'))\n",
    "noise_sig = sig.resample_poly(noise_sig, fs, fs_noise)\n",
    "noise_sig = noise_sig[:chunk_len*fs] \n",
    "# pad noise signal to 121 channels \n",
    "zeropads=np.zeros([noise_sig.shape[0],121-31])\n",
    "noise_sig =np.concatenate((noise_sig,zeropads),axis=1)\n",
    "\n",
    "# Target in mono:\n",
    "target_sig, fs_targ = sf.read(pjoin(speech_path, 'target1.wav'))\n",
    "target_sig = np.squeeze(target_sig[:,0])\n",
    "target_sig = sig.resample_poly(target_sig, fs, fs_targ)\n",
    "# cut speech signal to the length of the noise (about 2 min)\n",
    "target_sig=target_sig[:noise_sig.shape[0]]\n",
    "target_sig=np.array(target_sig,ndmin=2)\n",
    "\n",
    "# Target to SH\n",
    "target_biSH = mono2biSH(target_sig, mic_rirs)\n",
    "ane_target_biSH = mono2biSH(target_sig, ane_rirs)\n",
    "target_sh = mono2sh(target_sig, mic_rirs)\n",
    "ane_target_sh = mono2sh(target_sig, ane_rirs)\n",
    "# crop all to equal length:\n",
    "target_biSH = target_biSH[:, :chunk_len*fs]\n",
    "ane_target_biSH = ane_target_biSH[:, :chunk_len*fs]\n",
    "target_sh = target_sh[:chunk_len*fs]\n",
    "ane_target_sh = ane_target_sh[:chunk_len*fs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the single soundfield case (for speaker reproduction)\n",
    "ini_snr = 10 * np.log10(hlp.power(sh2bin(target_sh, decoder)) / hlp.power(sh2bin(noise_sig, decoder)))\n",
    "target_snr = 5.\n",
    "noise_gain_db = ini_snr - target_snr\n",
    "    \n",
    "scaled_noise = noise_sig * np.power(10, noise_gain_db/20)\n",
    "# normalize SH signals so that the binaural mixture is in [-1, 1] and it doesn't clip\n",
    "norm_fact = np.max(np.abs(sh2bin(target_sh + scaled_noise, decoder)))\n",
    "\n",
    "target_sh /= norm_fact\n",
    "scaled_noise /= norm_fact\n",
    "ane_target_sh /= norm_fact\n",
    "if tag == 'inverse': \n",
    "    scaled_noise = -scaled_noise\n",
    "mixture = target_sh + scaled_noise \n",
    "reverb = target_sh - ane_target_sh\n",
    "\n",
    "snr = 10 * np.log10(hlp.power(sh2bin(target_sh, decoder)) / hlp.power(sh2bin(scaled_noise, decoder)))\n",
    "\n",
    "sf.write(pjoin(speech_path, f\"{tag}_meeting_SH_deg{TARGET_ANGLE}_snr{int(target_snr)}_{fs}hz.wav\"), mixture, fs, subtype='FLOAT')\n",
    "\n",
    "Audio(sh2bin(mixture, decoder), rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we downmix to binaural only for listening purpose (combine single noise soundfield with two source soundfiels):\n",
    "bin_noise = sh2bin(noise_sig, decoder)\n",
    "bin_target = biSH2bin(target_biSH, decoder)\n",
    "bin_ane = biSH2bin(ane_target_biSH, decoder)\n",
    "\n",
    "bin_snr = 10 * np.log10(hlp.power(bin_target) / hlp.power(bin_noise))\n",
    "\n",
    "noise_gain_db = bin_snr - target_snr\n",
    "\n",
    "bin_noise = bin_noise * np.power(10, noise_gain_db/20)\n",
    "norm_fact = np.max(np.abs(bin_noise + bin_target))\n",
    "\n",
    "\n",
    "bin_noise /= norm_fact\n",
    "bin_target /= norm_fact\n",
    "bin_ane /= norm_fact\n",
    "if tag == 'inverse': \n",
    "    bin_noise = -bin_noise\n",
    "bin_mixture = bin_noise + bin_target\n",
    "bin_reverb = bin_target - bin_ane\n",
    "\n",
    "bin_mildmix = 0.25*bin_noise + 0.25*bin_reverb + bin_ane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(bin_ane, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(bin_target, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(bin_reverb, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.write(pjoin(speech_path,f\"{tag}_meeting_bin_deg{TARGET_ANGLE}_snr{int(target_snr)}_mixture_{fs}hz.wav\"), bin_mixture.T, fs, subtype='FLOAT')\n",
    "sf.write(pjoin(speech_path,f\"{tag}_meeting_bin_deg{TARGET_ANGLE}_snr{int(target_snr)}_mildmix_{fs}hz.wav\"), bin_mildmix.T, fs, subtype='FLOAT')\n",
    "sf.write(pjoin(speech_path,f\"{tag}_meeting_bin_deg{TARGET_ANGLE}_snr{int(target_snr)}_noise_{fs}hz.wav\"), bin_noise.T, fs, subtype='FLOAT')\n",
    "sf.write(pjoin(speech_path,f\"{tag}_meeting_bin_deg{TARGET_ANGLE}_snr{int(target_snr)}_ane_{fs}hz.wav\"), bin_ane.T, fs, subtype='FLOAT')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "librinew",
   "language": "python",
   "name": "librinew"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

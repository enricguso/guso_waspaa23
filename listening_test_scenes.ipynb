{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "import scipy.signal as sig\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import mat73\n",
    "import os\n",
    "import masp as srs\n",
    "from os.path import join as pjoin\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import my modules (helpers.py where I stored all the functions):\n",
    "import helpers as hlp\n",
    "import importlib\n",
    "importlib.reload(hlp);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_ANGLE=30\n",
    "target_snr = 5.\n",
    "fs=48000\n",
    "chunk_len = 30 #seconds\n",
    "tag='normal' #change to inverse when running for the second time\n",
    "speech_path = 'listening_situations_target_speech'\n",
    "arte_path = '/home/ubuntu/Data/ARTE'\n",
    "output_path = '/home/ubuntu/Data/ha_listening_situations/SH_versions/'+tag\n",
    "maxlim = 2\n",
    "ambi_order = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mono2biSH(mono_sig, sh_rir):\n",
    "    # Apply audio to SH IR\n",
    "    left = sig.fftconvolve(np.tile(mono_sig[0], (121,1)).T, sh_rir[:,:,0, 0], 'full', 0)   \n",
    "    right = sig.fftconvolve(np.tile(mono_sig[0], (121,1)).T, sh_rir[:,:,1, 0], 'full', 0)\n",
    "    return np.array([left, right])\n",
    "def biSH2bin(sh_sig, decoder):\n",
    "    left = sig.fftconvolve(sh_sig[0], decoder[:,:,0], 'full', 0).sum(1)\n",
    "    right = sig.fftconvolve(sh_sig[1], decoder[:,:,1], 'full', 0).sum(1)\n",
    "    return np.array([left,right])\n",
    "\n",
    "def mono2sh(mono_sig, sh_rir):\n",
    "    # Apply audio to SH IR\n",
    "    left = sig.fftconvolve(np.tile(mono_sig[0], (121,1)).T, sh_rir[:,:,2, 0], 'full', 0)   \n",
    "    return left\n",
    "\n",
    "def sh2bin(sh_sig, decoder):\n",
    "    left = sig.fftconvolve(sh_sig, decoder[:,:,0], 'full', 0).sum(1)\n",
    "    right = sig.fftconvolve(sh_sig, decoder[:,:,1], 'full', 0).sum(1)\n",
    "    return np.array([left,right])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------- DECODE TO BINAURAL ----------------\n",
    "decoder = mat73.loadmat(pjoin('decoders_ord10', 'Ku100_ALFE_Window_sinEQ_bimag.mat'))['hnm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCENE 1: PARTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute echogram: Source 0 - Receiver 0\n",
      "Compute echogram: Source 0 - Receiver 1\n",
      "Compute echogram: Source 0 - Receiver 2\n",
      "Apply SH directivites\n",
      "Apply absorption: Source 0 - Receiver 0\n",
      "Apply absorption: Source 0 - Receiver 1\n",
      "Apply absorption: Source 0 - Receiver 2\n",
      "Rendering echogram: Source 0 - Receiver 0\n",
      "     Filtering and combining bands\n",
      "Rendering echogram: Source 0 - Receiver 1\n",
      "     Filtering and combining bands\n",
      "Rendering echogram: Source 0 - Receiver 2\n",
      "     Filtering and combining bands\n",
      "Rendering echogram: Source 0 - Receiver 0\n",
      "     Filtering and combining bands\n",
      "Rendering echogram: Source 0 - Receiver 1\n",
      "     Filtering and combining bands\n",
      "Rendering echogram: Source 0 - Receiver 2\n",
      "     Filtering and combining bands\n"
     ]
    }
   ],
   "source": [
    "# --------------- DESIGN SCENE ----------------\n",
    "room = np.array([15., 10., 3.5]) \n",
    "rt60 = np.array([.4])\n",
    "head_pos= np.array([room[0]/2, room[1]/2, 1.6]) # Listener coordinates\n",
    "target_pos= hlp.place_on_circle(head_pos,1,TARGET_ANGLE)\n",
    "head_orient = np.array([0, 0]) # Head rotation\n",
    "ears_pos=hlp.head_2_ku_ears(head_pos,head_orient)\n",
    "\n",
    "# --------------- COMPUTE ECHOGRAMS ----------------\n",
    "# Compute absorption coefficients for desired rt60 and room dimensions\n",
    "abs_walls,rt60_true = srs.find_abs_coeffs_from_rt(room, rt60)\n",
    "# Small correction for sound absorption coefficients:\n",
    "if sum(rt60_true-rt60>0.05*rt60_true)>0 :\n",
    "    abs_walls,rt60_true = srs.find_abs_coeffs_from_rt(room, rt60_true + abs(rt60-rt60_true))\n",
    "# Generally, we simulate up to RT60:\n",
    "limits = np.minimum(rt60, maxlim)\n",
    "\n",
    "mic = np.array([ears_pos[0], ears_pos[1], list(head_pos)]) #two positions for the binaural, one for the SH\n",
    "src = np.array(target_pos)\n",
    "nRec = mic.shape[0]\n",
    "nSrc = src.shape[0]\n",
    "\n",
    "# Compute the echograms, which means how many reflections, at what time and from which coordinates:\n",
    "abs_echograms = srs.compute_echograms_sh(room, src, mic, abs_walls, limits, ambi_order, head_orient)\n",
    "ane_echograms = hlp.crop_echogram(copy.deepcopy(abs_echograms))\n",
    "# --------------- RENDER ECHOGRAMS ----------------\n",
    "band_centerfreqs=np.array([1000])\n",
    "mic_rirs = srs.render_rirs_sh(abs_echograms, band_centerfreqs, fs)\n",
    "ane_rirs = srs.render_rirs_sh(ane_echograms, band_centerfreqs, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hlp.plot_scene(room,head_pos,head_orient,ears_pos,target_pos,perspective=\"xy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- SOUND FILES -----------------\n",
    "# Noise in ambisonics:\n",
    "noise_sig, fs_noise = sf.read(pjoin(arte_path,'09_Dinner_party_MOA_31ch.wav'))\n",
    "noise_sig = sig.resample_poly(noise_sig, fs, fs_noise)\n",
    "noise_sig = noise_sig[:chunk_len*fs] \n",
    "# pad noise signal to 121 channels \n",
    "zeropads=np.zeros([noise_sig.shape[0],121-31])\n",
    "noise_sig =np.concatenate((noise_sig,zeropads),axis=1)\n",
    "\n",
    "# Target in mono:\n",
    "#target_sig, fs_targ = sf.read(pjoin(speech_path, 'esp_libri_speech_female_48k.wav'))\n",
    "target_sig, fs_targ = sf.read(pjoin(speech_path, 'target1.wav'))\n",
    "target_sig = np.squeeze(target_sig[:,0])\n",
    "target_sig = sig.resample_poly(target_sig, fs, fs_targ)\n",
    "# cut speech signal to the length of the noise (about 2 min)\n",
    "target_sig=target_sig[:noise_sig.shape[0]]\n",
    "target_sig=np.array(target_sig,ndmin=2)\n",
    "\n",
    "# Target to SH\n",
    "target_biSH = mono2biSH(target_sig, mic_rirs)\n",
    "ane_target_biSH = mono2biSH(target_sig, ane_rirs)\n",
    "target_sh = mono2sh(target_sig, mic_rirs)\n",
    "ane_target_sh = mono2sh(target_sig, ane_rirs)\n",
    "# crop all to equal length:\n",
    "target_biSH = target_biSH[:, :chunk_len*fs]\n",
    "ane_target_biSH = ane_target_biSH[:, :chunk_len*fs]\n",
    "target_sh = target_sh[:chunk_len*fs]\n",
    "ane_target_sh = ane_target_sh[:chunk_len*fs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the single soundfield case (for speaker reproduction)\n",
    "ini_snr = 10 * np.log10(hlp.power(sh2bin(target_sh, decoder)) / hlp.power(sh2bin(noise_sig, decoder)))\n",
    "target_snr = 5.\n",
    "noise_gain_db = ini_snr - target_snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_noise = noise_sig * np.power(10, noise_gain_db/20)\n",
    "# normalize SH signals so that the binaural mixture is in [-1, 1] and it doesn't clip\n",
    "norm_fact = np.max(np.abs(sh2bin(target_sh + scaled_noise, decoder)))\n",
    "\n",
    "target_sh /= norm_fact\n",
    "scaled_noise /= norm_fact\n",
    "ane_target_sh /= norm_fact\n",
    "if tag == 'inverse': \n",
    "    scaled_noise = -scaled_noise\n",
    "mixture = target_sh + scaled_noise\n",
    "reverb = target_sh - ane_target_sh\n",
    "\n",
    "snr = 10 * np.log10(hlp.power(sh2bin(target_sh, decoder)) / hlp.power(sh2bin(scaled_noise, decoder)))\n",
    "\n",
    "sf.write(pjoin(speech_path, f\"{tag}_party_SH_deg{TARGET_ANGLE}_snr{int(target_snr)}_{fs}hz.wav\"), mixture, fs, subtype='FLOAT')\n",
    "\n",
    "Audio(sh2bin(mixture, decoder), rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we downmix to binaural only for listening purpose (combine single noise soundfield with two source soundfiels):\n",
    "bin_noise = sh2bin(noise_sig, decoder)\n",
    "bin_target = biSH2bin(target_biSH, decoder)\n",
    "bin_ane = biSH2bin(ane_target_biSH, decoder)\n",
    "\n",
    "bin_snr = 10 * np.log10(hlp.power(bin_target) / hlp.power(bin_noise))\n",
    "\n",
    "noise_gain_db = bin_snr - target_snr\n",
    "\n",
    "bin_noise = bin_noise * np.power(10, noise_gain_db/20)\n",
    "norm_fact = np.max(np.abs(bin_noise + bin_target))\n",
    "\n",
    "\n",
    "bin_noise /= norm_fact\n",
    "bin_target /= norm_fact\n",
    "bin_ane /= norm_fact\n",
    "\n",
    "if tag == 'inverse': \n",
    "    bin_noise = -bin_noise\n",
    "    \n",
    "bin_mixture = bin_noise + bin_target\n",
    "bin_reverb = bin_target - bin_ane\n",
    "\n",
    "bin_mildmix = 0.25*bin_noise + 0.25*bin_reverb + bin_ane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(bin_mildmix, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(bin_ane, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(bin_target, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(bin_reverb, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.write(pjoin(speech_path,f\"{tag}_party_bin_deg{TARGET_ANGLE}_snr{int(target_snr)}_mixture_{fs}hz.wav\"), bin_mixture.T, fs, subtype='FLOAT')\n",
    "sf.write(pjoin(speech_path,f\"{tag}_party_bin_deg{TARGET_ANGLE}_snr{int(target_snr)}_mildmix_{fs}hz.wav\"), bin_mildmix.T, fs, subtype='FLOAT')\n",
    "sf.write(pjoin(speech_path,f\"{tag}_party_bin_deg{TARGET_ANGLE}_snr{int(target_snr)}_noise_{fs}hz.wav\"), bin_noise.T, fs, subtype='FLOAT')\n",
    "sf.write(pjoin(speech_path,f\"{tag}_party_bin_deg{TARGET_ANGLE}_snr{int(target_snr)}_ane_{fs}hz.wav\"), bin_ane.T, fs, subtype='FLOAT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCENE 2: RESTAURANT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------- DESIGN SCENE ----------------\n",
    "room = np.array([28., 17., 4.2]) \n",
    "rt60 = np.array([1.1]) * 0.5 # i feel this is too much... sounds like a cave\n",
    "head_pos= np.array([room[0]/2, room[1]/2, 1.3]) # Listener coordinates\n",
    "target_pos= hlp.place_on_circle(head_pos,1,TARGET_ANGLE)\n",
    "head_orient = np.array([0, 0]) # Head rotation\n",
    "ears_pos=hlp.head_2_ku_ears(head_pos,head_orient)\n",
    "\n",
    "# --------------- COMPUTE ECHOGRAMS ----------------\n",
    "# Compute absorption coefficients for desired rt60 and room dimensions\n",
    "abs_walls,rt60_true = srs.find_abs_coeffs_from_rt(room, rt60)\n",
    "# Small correction for sound absorption coefficients:\n",
    "if sum(rt60_true-rt60>0.05*rt60_true)>0 :\n",
    "    abs_walls,rt60_true = srs.find_abs_coeffs_from_rt(room, rt60_true + abs(rt60-rt60_true))\n",
    "# Generally, we simulate up to RT60:\n",
    "limits = np.minimum(rt60, maxlim)\n",
    "\n",
    "mic = np.array([ears_pos[0], ears_pos[1], list(head_pos)]) #two positions for the binaural, one for the SH\n",
    "src = np.array(target_pos)\n",
    "nRec = mic.shape[0]\n",
    "nSrc = src.shape[0]\n",
    "\n",
    "# Compute the echograms, which means how many reflections, at what time and from which coordinates:\n",
    "abs_echograms = srs.compute_echograms_sh(room, src, mic, abs_walls, limits, ambi_order, head_orient)\n",
    "ane_echograms = hlp.crop_echogram(copy.deepcopy(abs_echograms))\n",
    "# --------------- RENDER ECHOGRAMS ----------------\n",
    "band_centerfreqs=np.array([1000])\n",
    "mic_rirs = srs.render_rirs_sh(abs_echograms, band_centerfreqs, fs)\n",
    "ane_rirs = srs.render_rirs_sh(ane_echograms, band_centerfreqs, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hlp.plot_scene(room,head_pos,head_orient,ears_pos,target_pos,perspective=\"xy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- SOUND FILES -----------------\n",
    "# Noise in ambisonics:\n",
    "noise_sig, fs_noise = sf.read(pjoin(speech_path, '07_Cafe_1_MOA_31ch.wav'))\n",
    "noise_sig = sig.resample_poly(noise_sig, fs, fs_noise)\n",
    "noise_sig = noise_sig[:chunk_len*fs] \n",
    "# pad noise signal to 121 channels \n",
    "zeropads=np.zeros([noise_sig.shape[0],121-31])\n",
    "noise_sig =np.concatenate((noise_sig,zeropads),axis=1)\n",
    "\n",
    "# Target in mono:\n",
    "target_sig, fs_targ = sf.read(pjoin(speech_path, 'target1.wav'))\n",
    "target_sig = np.squeeze(target_sig[:,0])\n",
    "target_sig = sig.resample_poly(target_sig, fs, fs_targ)\n",
    "# cut speech signal to the length of the noise (about 2 min)\n",
    "target_sig=target_sig[:noise_sig.shape[0]]\n",
    "target_sig=np.array(target_sig,ndmin=2)\n",
    "\n",
    "# Target to SH\n",
    "target_biSH = mono2biSH(target_sig, mic_rirs)\n",
    "ane_target_biSH = mono2biSH(target_sig, ane_rirs)\n",
    "target_sh = mono2sh(target_sig, mic_rirs)\n",
    "ane_target_sh = mono2sh(target_sig, ane_rirs)\n",
    "# crop all to equal length:\n",
    "target_biSH = target_biSH[:, :chunk_len*fs]\n",
    "ane_target_biSH = ane_target_biSH[:, :chunk_len*fs]\n",
    "target_sh = target_sh[:chunk_len*fs]\n",
    "ane_target_sh = ane_target_sh[:chunk_len*fs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the single soundfield case (for speaker reproduction)\n",
    "ini_snr = 10 * np.log10(hlp.power(sh2bin(target_sh, decoder)) / hlp.power(sh2bin(noise_sig, decoder)))\n",
    "target_snr = 5.\n",
    "noise_gain_db = ini_snr - target_snr\n",
    "    \n",
    "scaled_noise = noise_sig * np.power(10, noise_gain_db/20)\n",
    "# normalize SH signals so that the binaural mixture is in [-1, 1] and it doesn't clip\n",
    "norm_fact = np.max(np.abs(sh2bin(target_sh + scaled_noise, decoder)))\n",
    "\n",
    "target_sh /= norm_fact\n",
    "scaled_noise /= norm_fact\n",
    "ane_target_sh /= norm_fact\n",
    "if tag == 'inverse': \n",
    "    scaled_noise = -scaled_noise\n",
    "mixture = target_sh + scaled_noise  \n",
    "reverb = target_sh - ane_target_sh\n",
    "\n",
    "snr = 10 * np.log10(hlp.power(sh2bin(target_sh, decoder)) / hlp.power(sh2bin(scaled_noise, decoder)))\n",
    "\n",
    "\n",
    "sf.write(pjoin(speech_path, f\"{tag}_restaurant_SH_deg{TARGET_ANGLE}_snr{int(target_snr)}_{fs}hz.wav\"), mixture, fs, subtype='FLOAT')\n",
    "Audio(sh2bin(mixture, decoder), rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we downmix to binaural only for listening purpose (combine single noise soundfield with two source soundfiels):\n",
    "bin_noise = sh2bin(noise_sig, decoder)\n",
    "bin_target = biSH2bin(target_biSH, decoder)\n",
    "bin_ane = biSH2bin(ane_target_biSH, decoder)\n",
    "\n",
    "bin_snr = 10 * np.log10(hlp.power(bin_target) / hlp.power(bin_noise))\n",
    "\n",
    "noise_gain_db = bin_snr - target_snr\n",
    "\n",
    "bin_noise = bin_noise * np.power(10, noise_gain_db/20)\n",
    "norm_fact = np.max(np.abs(bin_noise + bin_target))\n",
    "\n",
    "\n",
    "bin_noise /= norm_fact\n",
    "bin_target /= norm_fact\n",
    "bin_ane /= norm_fact\n",
    "if tag == 'inverse': \n",
    "    bin_noise = -bin_noise\n",
    "bin_mixture = bin_noise + bin_target\n",
    "bin_reverb = bin_target - bin_ane\n",
    "\n",
    "bin_mildmix = 0.25*bin_noise + 0.25*bin_reverb + bin_ane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(bin_ane, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(bin_target, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(bin_reverb, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.write(pjoin(speech_path,f\"{tag}_restaurant_bin_deg{TARGET_ANGLE}_snr{int(target_snr)}_mixture_{fs}hz.wav\"), bin_mixture.T, fs, subtype='FLOAT')\n",
    "sf.write(pjoin(speech_path,f\"{tag}_restaurant_bin_deg{TARGET_ANGLE}_snr{int(target_snr)}_mildmix_{fs}hz.wav\"), bin_mildmix.T, fs, subtype='FLOAT')\n",
    "sf.write(pjoin(speech_path,f\"{tag}_restaurant_bin_deg{TARGET_ANGLE}_snr{int(target_snr)}_noise_{fs}hz.wav\"), bin_noise.T, fs, subtype='FLOAT')\n",
    "sf.write(pjoin(speech_path,f\"{tag}_restaurant_bin_deg{TARGET_ANGLE}_snr{int(target_snr)}_ane_{fs}hz.wav\"), bin_ane.T, fs, subtype='FLOAT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCENE 3: MEETING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------- DESIGN SCENE ----------------\n",
    "room = np.array([5., 2., 2.5]) \n",
    "rt60 = np.array([0.2]) * 0.6\n",
    "head_pos= np.array([room[0]/2, room[1]/2, 1.3]) # Listener coordinates\n",
    "target_pos= hlp.place_on_circle(head_pos,1,TARGET_ANGLE)\n",
    "head_orient = np.array([0, 0]) # Head rotation\n",
    "ears_pos=hlp.head_2_ku_ears(head_pos,head_orient)\n",
    "\n",
    "# --------------- COMPUTE ECHOGRAMS ----------------\n",
    "# Compute absorption coefficients for desired rt60 and room dimensions\n",
    "abs_walls,rt60_true = srs.find_abs_coeffs_from_rt(room, rt60)\n",
    "# Small correction for sound absorption coefficients:\n",
    "if sum(rt60_true-rt60>0.05*rt60_true)>0 :\n",
    "    abs_walls,rt60_true = srs.find_abs_coeffs_from_rt(room, rt60_true + abs(rt60-rt60_true))\n",
    "# Generally, we simulate up to RT60:\n",
    "limits = np.minimum(rt60, maxlim)\n",
    "\n",
    "mic = np.array([ears_pos[0], ears_pos[1], list(head_pos)]) #two positions for the binaural, one for the SH\n",
    "src = np.array(target_pos)\n",
    "nRec = mic.shape[0]\n",
    "nSrc = src.shape[0]\n",
    "\n",
    "# Compute the echograms, which means how many reflections, at what time and from which coordinates:\n",
    "abs_echograms = srs.compute_echograms_sh(room, src, mic, abs_walls, limits, ambi_order, head_orient)\n",
    "ane_echograms = hlp.crop_echogram(copy.deepcopy(abs_echograms))\n",
    "# --------------- RENDER ECHOGRAMS ----------------\n",
    "band_centerfreqs=np.array([1000])\n",
    "mic_rirs = srs.render_rirs_sh(abs_echograms, band_centerfreqs, fs)\n",
    "ane_rirs = srs.render_rirs_sh(ane_echograms, band_centerfreqs, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hlp.plot_scene(room,head_pos,head_orient,ears_pos,target_pos,perspective=\"xy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- SOUND FILES -----------------\n",
    "# Noise in ambisonics:\n",
    "noise_sig, fs_noise = sf.read(pjoin(speech_path, '02_Office_MOA_31ch.wav'))\n",
    "noise_sig = sig.resample_poly(noise_sig, fs, fs_noise)\n",
    "noise_sig = noise_sig[:chunk_len*fs] \n",
    "# pad noise signal to 121 channels \n",
    "zeropads=np.zeros([noise_sig.shape[0],121-31])\n",
    "noise_sig =np.concatenate((noise_sig,zeropads),axis=1)\n",
    "\n",
    "# Target in mono:\n",
    "target_sig, fs_targ = sf.read(pjoin(speech_path, 'target1.wav'))\n",
    "target_sig = np.squeeze(target_sig[:,0])\n",
    "target_sig = sig.resample_poly(target_sig, fs, fs_targ)\n",
    "# cut speech signal to the length of the noise (about 2 min)\n",
    "target_sig=target_sig[:noise_sig.shape[0]]\n",
    "target_sig=np.array(target_sig,ndmin=2)\n",
    "\n",
    "# Target to SH\n",
    "target_biSH = mono2biSH(target_sig, mic_rirs)\n",
    "ane_target_biSH = mono2biSH(target_sig, ane_rirs)\n",
    "target_sh = mono2sh(target_sig, mic_rirs)\n",
    "ane_target_sh = mono2sh(target_sig, ane_rirs)\n",
    "# crop all to equal length:\n",
    "target_biSH = target_biSH[:, :chunk_len*fs]\n",
    "ane_target_biSH = ane_target_biSH[:, :chunk_len*fs]\n",
    "target_sh = target_sh[:chunk_len*fs]\n",
    "ane_target_sh = ane_target_sh[:chunk_len*fs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the single soundfield case (for speaker reproduction)\n",
    "ini_snr = 10 * np.log10(hlp.power(sh2bin(target_sh, decoder)) / hlp.power(sh2bin(noise_sig, decoder)))\n",
    "target_snr = 5.\n",
    "noise_gain_db = ini_snr - target_snr\n",
    "    \n",
    "scaled_noise = noise_sig * np.power(10, noise_gain_db/20)\n",
    "# normalize SH signals so that the binaural mixture is in [-1, 1] and it doesn't clip\n",
    "norm_fact = np.max(np.abs(sh2bin(target_sh + scaled_noise, decoder)))\n",
    "\n",
    "target_sh /= norm_fact\n",
    "scaled_noise /= norm_fact\n",
    "ane_target_sh /= norm_fact\n",
    "if tag == 'inverse': \n",
    "    scaled_noise = -scaled_noise\n",
    "mixture = target_sh + scaled_noise \n",
    "reverb = target_sh - ane_target_sh\n",
    "\n",
    "snr = 10 * np.log10(hlp.power(sh2bin(target_sh, decoder)) / hlp.power(sh2bin(scaled_noise, decoder)))\n",
    "\n",
    "sf.write(pjoin(speech_path, f\"{tag}_meeting_SH_deg{TARGET_ANGLE}_snr{int(target_snr)}_{fs}hz.wav\"), mixture, fs, subtype='FLOAT')\n",
    "\n",
    "Audio(sh2bin(mixture, decoder), rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we downmix to binaural only for listening purpose (combine single noise soundfield with two source soundfiels):\n",
    "bin_noise = sh2bin(noise_sig, decoder)\n",
    "bin_target = biSH2bin(target_biSH, decoder)\n",
    "bin_ane = biSH2bin(ane_target_biSH, decoder)\n",
    "\n",
    "bin_snr = 10 * np.log10(hlp.power(bin_target) / hlp.power(bin_noise))\n",
    "\n",
    "noise_gain_db = bin_snr - target_snr\n",
    "\n",
    "bin_noise = bin_noise * np.power(10, noise_gain_db/20)\n",
    "norm_fact = np.max(np.abs(bin_noise + bin_target))\n",
    "\n",
    "\n",
    "bin_noise /= norm_fact\n",
    "bin_target /= norm_fact\n",
    "bin_ane /= norm_fact\n",
    "if tag == 'inverse': \n",
    "    bin_noise = -bin_noise\n",
    "bin_mixture = bin_noise + bin_target\n",
    "bin_reverb = bin_target - bin_ane\n",
    "\n",
    "bin_mildmix = 0.25*bin_noise + 0.25*bin_reverb + bin_ane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(bin_ane, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(bin_target, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(bin_reverb, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.write(pjoin(speech_path,f\"{tag}_meeting_bin_deg{TARGET_ANGLE}_snr{int(target_snr)}_mixture_{fs}hz.wav\"), bin_mixture.T, fs, subtype='FLOAT')\n",
    "sf.write(pjoin(speech_path,f\"{tag}_meeting_bin_deg{TARGET_ANGLE}_snr{int(target_snr)}_mildmix_{fs}hz.wav\"), bin_mildmix.T, fs, subtype='FLOAT')\n",
    "sf.write(pjoin(speech_path,f\"{tag}_meeting_bin_deg{TARGET_ANGLE}_snr{int(target_snr)}_noise_{fs}hz.wav\"), bin_noise.T, fs, subtype='FLOAT')\n",
    "sf.write(pjoin(speech_path,f\"{tag}_meeting_bin_deg{TARGET_ANGLE}_snr{int(target_snr)}_ane_{fs}hz.wav\"), bin_ane.T, fs, subtype='FLOAT')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LibriMix3D",
   "language": "python",
   "name": "librimix3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

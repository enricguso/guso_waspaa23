{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b9e3547",
   "metadata": {},
   "source": [
    "# Debug1 : ROTATING THE SOURCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679bf1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "import scipy.signal as sig\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import mat73\n",
    "import masp as srs\n",
    "# import my modules (helpers.py where I stored all the functions):\n",
    "import helpers as hlp\n",
    "import importlib\n",
    "importlib.reload(hlp);\n",
    "# --------------- DESIGN SCENE ----------------\n",
    "room = np.array([4., 4., 3.]) # Room dimensions\n",
    "rt60 = np.array([.2])\n",
    "sources_pos= [[2., 1., 1.6]] # Sources coordinates \n",
    "head_pos= np.array([room[0]/2, room[1]/2, 1.6]) # Listener coordinates\n",
    "head_orient = np.array([0, 0]) # Head rotation in degrees\n",
    "ears_pos=hlp.head_2_ku_ears(head_pos,head_orient)\n",
    "\n",
    "# --------------- PLOT SCENE ----------------\n",
    "hlp.plot_scene(room,head_pos,head_orient,ears_pos,sources_pos,perspective=\"xy\")\n",
    "\n",
    "# --------------- COMPUTE ECHOGRAMS ----------------\n",
    "\n",
    "# some constants:\n",
    "mic_specs = np.array([  [1, 0, 0, 1], [1, 0, 0, 1] ] ) #two omni mics facing to the front\n",
    "fs = 48000 #sampling rate\n",
    "maxlim = 2 # maximum reflection time in seconds. Stop simulating if it goes beyond that time.\n",
    "ambi_order = 10 # ambisonics order\n",
    "rims_d = 0.0 # displacement for Randomized Image Source method. Default is 0.\n",
    "\n",
    "# Compute absorption coefficients for desired rt60 and room dimensions\n",
    "abs_walls,rt60_true = srs.find_abs_coeffs_from_rt(room, rt60)\n",
    "# Small correction for sound absorption coefficients:\n",
    "if sum(rt60_true-rt60>0.05*rt60_true)>0 :\n",
    "    abs_walls,rt60_true = srs.find_abs_coeffs_from_rt(room, rt60_true + abs(rt60-rt60_true))\n",
    "# Generally, we simulate up to RT60:\n",
    "limits = np.minimum(rt60, maxlim)\n",
    "\n",
    "mic = np.array(ears_pos)\n",
    "src = np.array(sources_pos)\n",
    "nRec = mic.shape[0]\n",
    "nSrc = src.shape[0]\n",
    "\n",
    "# Compute the echograms, which means how many reflections, at what time and from which coordinates:\n",
    "abs_echograms = srs.compute_echograms_sh(room, src, mic, abs_walls, limits, ambi_order, rims_d, head_orient)\n",
    "\n",
    "# --------------- RENDER ECHOGRAMS ----------------\n",
    "band_centerfreqs=np.array([1000])\n",
    "mic_rirs = srs.render_rirs_sh(abs_echograms, band_centerfreqs, fs)\n",
    "\n",
    "# --------------- DECODE TO BINAURAL ----------------\n",
    "dec_ku = mat73.loadmat('decoders_ord10/Ku100_ALFE_Window_sinEQ_bimag.mat')['hnm']\n",
    "dec_ku = np.roll(dec_ku,500,axis=0)\n",
    "dec_ric = mat73.loadmat('decoders_ord10/RIC_Front_Omni_ALFE_Window_SinEQ_bimag.mat')['hnm']\n",
    "dec_ric = np.roll(dec_ric,500,axis=0)\n",
    "\n",
    "# Load source signals:\n",
    "source0, fs2 = sf.read('test1.wav')# male\n",
    "#source1, fs2 = sf.read('test2.wav')# child\n",
    "#source2, fs2 = sf.read('test3.wav')# female (rat Arthur)\n",
    "#source3, fs2 = sf.read('test4.wav')# female Harvard\n",
    "\n",
    "# function to resample the signal and pick only one channel\n",
    "def resampled_mono(src,fs,fs2):\n",
    "    return sig.resample_poly(src[:,0] if len(src.shape)>1 else src, fs, fs2)\n",
    "\n",
    "# create list of resampled, mono source signals\n",
    "sources_sigs=[]\n",
    "sources_sigs.append(resampled_mono(source0,fs,fs2))\n",
    "#sources_sigs.append(resampled_mono(source1,fs,fs2))\n",
    "#sources_sigs.append(resampled_mono(source2,fs,fs2))\n",
    "#sources_sigs.append(resampled_mono(source3,fs,fs2))\n",
    "\n",
    "# set levels for all sources (this is level at the source, distance attenuation is applied by convolving with irs):\n",
    "levels=[-45]#,-45,-45,-45] \n",
    "\n",
    "# generate a mixture signal with localized sources\n",
    "mixture_ku=hlp.generate_scenes(sources_sigs,levels,mic_rirs,dec_ku)\n",
    "Audio(mixture_ku, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e43ce6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture_ric=hlp.generate_scenes(sources_sigs,levels,mic_rirs,dec_ric)\n",
    "Audio(mixture_ric, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f370b4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "import scipy.signal as sig\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import mat73\n",
    "import os\n",
    "import masp as srs\n",
    "# import my modules (helpers.py where I stored all the functions):\n",
    "import helpers as hlp\n",
    "import importlib\n",
    "importlib.reload(hlp);\n",
    "# --------------- DESIGN SCENE ----------------\n",
    "room = np.array([4., 4., 3.]) # Room dimensions\n",
    "rt60 = np.array([.2])\n",
    "sources_pos= [[2., 3., 1.6]] # Sources coordinates \n",
    "head_pos= np.array([room[0]/2, room[1]/2, 1.6]) # Listener coordinates\n",
    "head_orient = np.array([0, 0]) # Head rotation in degrees\n",
    "ears_pos=hlp.head_2_ku_ears(head_pos,head_orient)\n",
    "\n",
    "# --------------- PLOT SCENE ----------------\n",
    "hlp.plot_scene(room,head_pos,head_orient,ears_pos,sources_pos,perspective=\"xy\")\n",
    "\n",
    "# --------------- COMPUTE ECHOGRAMS ----------------\n",
    "\n",
    "# some constants:\n",
    "mic_specs = np.array([  [1, 0, 0, 1], [1, 0, 0, 1] ] ) #two omni mics facing to the front\n",
    "fs = 48000 #sampling rate\n",
    "maxlim = 2 # maximum reflection time in seconds. Stop simulating if it goes beyond that time.\n",
    "ambi_order = 10 # ambisonics order\n",
    "rims_d = 0.0 # displacement for Randomized Image Source method. Default is 0.\n",
    "\n",
    "# Compute absorption coefficients for desired rt60 and room dimensions\n",
    "abs_walls,rt60_true = srs.find_abs_coeffs_from_rt(room, rt60)\n",
    "# Small correction for sound absorption coefficients:\n",
    "if sum(rt60_true-rt60>0.05*rt60_true)>0 :\n",
    "    abs_walls,rt60_true = srs.find_abs_coeffs_from_rt(room, rt60_true + abs(rt60-rt60_true))\n",
    "# Generally, we simulate up to RT60:\n",
    "limits = np.minimum(rt60, maxlim)\n",
    "\n",
    "mic = np.array(ears_pos)\n",
    "src = np.array(sources_pos)\n",
    "nRec = mic.shape[0]\n",
    "nSrc = src.shape[0]\n",
    "\n",
    "# Compute the echograms, which means how many reflections, at what time and from which coordinates:\n",
    "abs_echograms = srs.compute_echograms_sh(room, src, mic, abs_walls, limits, ambi_order, rims_d, head_orient)\n",
    "\n",
    "# --------------- RENDER ECHOGRAMS ----------------\n",
    "band_centerfreqs=np.array([1000])\n",
    "mic_rirs = srs.render_rirs_sh(abs_echograms, band_centerfreqs, fs)\n",
    "\n",
    "# --------------- DECODE TO BINAURAL ----------------\n",
    "dec_ku = mat73.loadmat('decoders_ord10/Ku100_ALFE_Window_sinEQ_bimag.mat')['hnm']\n",
    "dec_ku = np.roll(dec_ku,500,axis=0)\n",
    "dec_ric = mat73.loadmat('decoders_ord10/RIC_Front_Omni_ALFE_Window_SinEQ_bimag.mat')['hnm']\n",
    "dec_ric = np.roll(dec_ric,500,axis=0)\n",
    "\n",
    "# Load source signals:\n",
    "source0, fs2 = sf.read('test1.wav')# male\n",
    "#source1, fs2 = sf.read('test2.wav')# child\n",
    "#source2, fs2 = sf.read('test3.wav')# female (rat Arthur)\n",
    "#source3, fs2 = sf.read('test4.wav')# female Harvard\n",
    "\n",
    "# function to resample the signal and pick only one channel\n",
    "def resampled_mono(src,fs,fs2):\n",
    "    return sig.resample_poly(src[:,0] if len(src.shape)>1 else src, fs, fs2)\n",
    "\n",
    "# create list of resampled, mono source signals\n",
    "sources_sigs=[]\n",
    "sources_sigs.append(resampled_mono(source0,fs,fs2))\n",
    "#sources_sigs.append(resampled_mono(source1,fs,fs2))\n",
    "#sources_sigs.append(resampled_mono(source2,fs,fs2))\n",
    "#sources_sigs.append(resampled_mono(source3,fs,fs2))\n",
    "\n",
    "# set levels for all sources (this is level at the source, distance attenuation is applied by convolving with irs):\n",
    "levels=[-45]#,-45,-45,-45] \n",
    "\n",
    "# generate a mixture signal with localized sources\n",
    "mixture_ku=hlp.generate_scenes(sources_sigs,levels,mic_rirs,dec_ku)\n",
    "Audio(mixture_ku, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41e337a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture_ric=hlp.generate_scenes(sources_sigs,levels,mic_rirs,dec_ric)\n",
    "Audio(mixture_ric, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60953c4c",
   "metadata": {},
   "source": [
    "# Debug2 : ROTATING THE HEAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2ef0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "import scipy.signal as sig\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import mat73\n",
    "import os\n",
    "import masp as srs\n",
    "# import my modules (helpers.py where I stored all the functions):\n",
    "import helpers as hlp\n",
    "import importlib\n",
    "importlib.reload(hlp);\n",
    "# --------------- DESIGN SCENE ----------------\n",
    "room = np.array([4., 4., 3.]) # Room dimensions\n",
    "rt60 = np.array([.2])\n",
    "sources_pos= [[3., 2., 1.6]] # Sources coordinates \n",
    "head_pos= np.array([room[0]/2, room[1]/2, 1.6]) # Listener coordinates\n",
    "head_orient = np.array([90, 0]) # Head rotation in degrees\n",
    "ears_pos=hlp.head_2_ku_ears(head_pos,head_orient)\n",
    "\n",
    "# --------------- PLOT SCENE ----------------\n",
    "hlp.plot_scene(room,head_pos,head_orient,ears_pos,sources_pos,perspective=\"xy\")\n",
    "\n",
    "\n",
    "# --------------- COMPUTE ECHOGRAMS ----------------\n",
    "\n",
    "# some constants:\n",
    "mic_specs = np.array([  [1, 0, 0, 1], [1, 0, 0, 1] ] ) #two omni mics facing to the front\n",
    "fs = 48000 #sampling rate\n",
    "maxlim = 2 # maximum reflection time in seconds. Stop simulating if it goes beyond that time.\n",
    "ambi_order = 10 # ambisonics order\n",
    "rims_d = 0.0 # displacement for Randomized Image Source method. Default is 0.\n",
    "\n",
    "# Compute absorption coefficients for desired rt60 and room dimensions\n",
    "abs_walls,rt60_true = srs.find_abs_coeffs_from_rt(room, rt60)\n",
    "# Small correction for sound absorption coefficients:\n",
    "if sum(rt60_true-rt60>0.05*rt60_true)>0 :\n",
    "    abs_walls,rt60_true = srs.find_abs_coeffs_from_rt(room, rt60_true + abs(rt60-rt60_true))\n",
    "# Generally, we simulate up to RT60:\n",
    "limits = np.minimum(rt60, maxlim)\n",
    "\n",
    "mic = np.array(ears_pos)\n",
    "src = np.array(sources_pos)\n",
    "nRec = mic.shape[0]\n",
    "nSrc = src.shape[0]\n",
    "\n",
    "# Compute the echograms, which means how many reflections, at what time and from which coordinates:\n",
    "abs_echograms = srs.compute_echograms_sh(room, src, mic, abs_walls, limits, ambi_order, rims_d, head_orient)\n",
    "\n",
    "# --------------- RENDER ECHOGRAMS ----------------\n",
    "band_centerfreqs=np.array([1000])\n",
    "mic_rirs = srs.render_rirs_sh(abs_echograms, band_centerfreqs, fs)\n",
    "\n",
    "# --------------- DECODE TO BINAURAL ----------------\n",
    "dec_ku = mat73.loadmat('decoders_ord10/Ku100_ALFE_Window_sinEQ_bimag.mat')['hnm']\n",
    "dec_ku = np.roll(dec_ku,500,axis=0)\n",
    "dec_ric = mat73.loadmat('decoders_ord10/RIC_Front_Omni_ALFE_Window_SinEQ_bimag.mat')['hnm']\n",
    "dec_ric = np.roll(dec_ric,500,axis=0)\n",
    "\n",
    "# Load source signals:\n",
    "source0, fs2 = sf.read('test1.wav')# male\n",
    "#source1, fs2 = sf.read('test2.wav')# child\n",
    "#source2, fs2 = sf.read('test3.wav')# female (rat Arthur)\n",
    "#source3, fs2 = sf.read('test4.wav')# female Harvard\n",
    "\n",
    "# function to resample the signal and pick only one channel\n",
    "def resampled_mono(src,fs,fs2):\n",
    "    return sig.resample_poly(src[:,0] if len(src.shape)>1 else src, fs, fs2)\n",
    "\n",
    "# create list of resampled, mono source signals\n",
    "sources_sigs=[]\n",
    "sources_sigs.append(resampled_mono(source0,fs,fs2))\n",
    "#sources_sigs.append(resampled_mono(source1,fs,fs2))\n",
    "#sources_sigs.append(resampled_mono(source2,fs,fs2))\n",
    "#sources_sigs.append(resampled_mono(source3,fs,fs2))\n",
    "\n",
    "# set levels for all sources (this is level at the source, distance attenuation is applied by convolving with irs):\n",
    "levels=[-45]#,-45,-45,-45] \n",
    "\n",
    "# generate a mixture signal with localized sources\n",
    "mixture_ku=hlp.generate_scenes(sources_sigs,levels,mic_rirs,dec_ku)\n",
    "Audio(mixture_ku, rate=fs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550d91e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture_ric=hlp.generate_scenes(sources_sigs,levels,mic_rirs,dec_ric)\n",
    "Audio(mixture_ric, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7a4f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "import scipy.signal as sig\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import mat73\n",
    "import os\n",
    "import masp as srs\n",
    "# import my modules (helpers.py where I stored all the functions):\n",
    "import helpers as hlp\n",
    "import importlib\n",
    "importlib.reload(hlp);\n",
    "# --------------- DESIGN SCENE ----------------\n",
    "room = np.array([4., 4., 3.]) # Room dimensions\n",
    "rt60 = np.array([.2])\n",
    "sources_pos= [[3., 2., 1.6]] # Sources coordinates \n",
    "head_pos= np.array([room[0]/2, room[1]/2, 1.6]) # Listener coordinates\n",
    "head_orient = np.array([-90, 0]) # Head rotation in degrees\n",
    "ears_pos=hlp.head_2_ku_ears(head_pos,head_orient)\n",
    "\n",
    "# --------------- PLOT SCENE ----------------\n",
    "hlp.plot_scene(room,head_pos,head_orient,ears_pos,sources_pos,perspective=\"xy\")\n",
    "\n",
    "\n",
    "# --------------- COMPUTE ECHOGRAMS ----------------\n",
    "\n",
    "# some constants:\n",
    "mic_specs = np.array([  [1, 0, 0, 1], [1, 0, 0, 1] ] ) #two omni mics facing to the front\n",
    "fs = 48000 #sampling rate\n",
    "maxlim = 2 # maximum reflection time in seconds. Stop simulating if it goes beyond that time.\n",
    "ambi_order = 10 # ambisonics order\n",
    "rims_d = 0.0 # displacement for Randomized Image Source method. Default is 0.\n",
    "\n",
    "# Compute absorption coefficients for desired rt60 and room dimensions\n",
    "abs_walls,rt60_true = srs.find_abs_coeffs_from_rt(room, rt60)\n",
    "# Small correction for sound absorption coefficients:\n",
    "if sum(rt60_true-rt60>0.05*rt60_true)>0 :\n",
    "    abs_walls,rt60_true = srs.find_abs_coeffs_from_rt(room, rt60_true + abs(rt60-rt60_true))\n",
    "# Generally, we simulate up to RT60:\n",
    "limits = np.minimum(rt60, maxlim)\n",
    "\n",
    "mic = np.array(ears_pos)\n",
    "src = np.array(sources_pos)\n",
    "nRec = mic.shape[0]\n",
    "nSrc = src.shape[0]\n",
    "\n",
    "# Compute the echograms, which means how many reflections, at what time and from which coordinates:\n",
    "abs_echograms = srs.compute_echograms_sh(room, src, mic, abs_walls, limits, ambi_order, rims_d, head_orient)\n",
    "\n",
    "# --------------- RENDER ECHOGRAMS ----------------\n",
    "band_centerfreqs=np.array([1000])\n",
    "mic_rirs = srs.render_rirs_sh(abs_echograms, band_centerfreqs, fs)\n",
    "\n",
    "# --------------- DECODE TO BINAURAL ----------------\n",
    "dec_ku = mat73.loadmat('decoders_ord10/Ku100_ALFE_Window_sinEQ_bimag.mat')['hnm']\n",
    "dec_ku = np.roll(dec_ku,500,axis=0)\n",
    "dec_ric = mat73.loadmat('decoders_ord10/RIC_Front_Omni_ALFE_Window_SinEQ_bimag.mat')['hnm']\n",
    "dec_ric = np.roll(dec_ric,500,axis=0)\n",
    "\n",
    "# Load source signals:\n",
    "source0, fs2 = sf.read('test1.wav')# male\n",
    "#source1, fs2 = sf.read('test2.wav')# child\n",
    "#source2, fs2 = sf.read('test3.wav')# female (rat Arthur)\n",
    "#source3, fs2 = sf.read('test4.wav')# female Harvard\n",
    "\n",
    "# function to resample the signal and pick only one channel\n",
    "def resampled_mono(src,fs,fs2):\n",
    "    return sig.resample_poly(src[:,0] if len(src.shape)>1 else src, fs, fs2)\n",
    "\n",
    "# create list of resampled, mono source signals\n",
    "sources_sigs=[]\n",
    "sources_sigs.append(resampled_mono(source0,fs,fs2))\n",
    "#sources_sigs.append(resampled_mono(source1,fs,fs2))\n",
    "#sources_sigs.append(resampled_mono(source2,fs,fs2))\n",
    "#sources_sigs.append(resampled_mono(source3,fs,fs2))\n",
    "\n",
    "# set levels for all sources (this is level at the source, distance attenuation is applied by convolving with irs):\n",
    "levels=[-45]#,-45,-45,-45] \n",
    "\n",
    "# generate a mixture signal with localized sources\n",
    "mixture_ku=hlp.generate_scenes(sources_sigs,levels,mic_rirs,dec_ku)\n",
    "Audio(mixture_ku, rate=fs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae871e55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mixture_ric=hlp.generate_scenes(sources_sigs,levels,mic_rirs,dec_ric)\n",
    "Audio(mixture_ric, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770e6896",
   "metadata": {},
   "source": [
    "# Debug3 : Front and Back doesn't work much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09afd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "import scipy.signal as sig\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import mat73\n",
    "import os\n",
    "import masp as srs\n",
    "# import my modules (helpers.py where I stored all the functions):\n",
    "import helpers as hlp\n",
    "import importlib\n",
    "importlib.reload(hlp);\n",
    "# --------------- DESIGN SCENE ----------------\n",
    "room = np.array([4., 4., 3.]) # Room dimensions\n",
    "rt60 = np.array([.2])\n",
    "sources_pos= [[3., 3., 1.6]] # Sources coordinates \n",
    "head_pos= np.array([room[0]/2, room[1]/2, 1.6]) # Listener coordinates\n",
    "head_orient = np.array([0, 0]) # Head rotation in degrees\n",
    "ears_pos=hlp.head_2_ku_ears(head_pos,head_orient)\n",
    "\n",
    "# --------------- PLOT SCENE ----------------\n",
    "hlp.plot_scene(room,head_pos,head_orient,ears_pos,sources_pos,perspective=\"xy\")\n",
    "\n",
    "# --------------- COMPUTE ECHOGRAMS ----------------\n",
    "\n",
    "# some constants:\n",
    "mic_specs = np.array([  [1, 0, 0, 1], [1, 0, 0, 1] ] ) #two omni mics facing to the front\n",
    "fs = 48000 #sampling rate\n",
    "maxlim = 2 # maximum reflection time in seconds. Stop simulating if it goes beyond that time.\n",
    "ambi_order = 10 # ambisonics order\n",
    "rims_d = 0.0 # displacement for Randomized Image Source method. Default is 0.\n",
    "\n",
    "# Compute absorption coefficients for desired rt60 and room dimensions\n",
    "abs_walls,rt60_true = srs.find_abs_coeffs_from_rt(room, rt60)\n",
    "# Small correction for sound absorption coefficients:\n",
    "if sum(rt60_true-rt60>0.05*rt60_true)>0 :\n",
    "    abs_walls,rt60_true = srs.find_abs_coeffs_from_rt(room, rt60_true + abs(rt60-rt60_true))\n",
    "# Generally, we simulate up to RT60:\n",
    "limits = np.minimum(rt60, maxlim)\n",
    "\n",
    "mic = np.array(ears_pos)\n",
    "src = np.array(sources_pos)\n",
    "nRec = mic.shape[0]\n",
    "nSrc = src.shape[0]\n",
    "\n",
    "# Compute the echograms, which means how many reflections, at what time and from which coordinates:\n",
    "abs_echograms = srs.compute_echograms_sh(room, src, mic, abs_walls, limits, ambi_order, rims_d, head_orient)\n",
    "\n",
    "# --------------- RENDER ECHOGRAMS ----------------\n",
    "band_centerfreqs=np.array([1000])\n",
    "mic_rirs = srs.render_rirs_sh(abs_echograms, band_centerfreqs, fs)\n",
    "\n",
    "# --------------- DECODE TO BINAURAL ----------------\n",
    "dec_ku = mat73.loadmat('decoders_ord10/Ku100_ALFE_Window_sinEQ_bimag.mat')['hnm']\n",
    "dec_ku = np.roll(dec_ku,500,axis=0)\n",
    "dec_ric = mat73.loadmat('decoders_ord10/RIC_Front_Omni_ALFE_Window_SinEQ_bimag.mat')['hnm']\n",
    "dec_ric = np.roll(dec_ric,500,axis=0)\n",
    "\n",
    "# Load source signals:\n",
    "source0, fs2 = sf.read('test1.wav')# male\n",
    "#source1, fs2 = sf.read('test2.wav')# child\n",
    "#source2, fs2 = sf.read('test3.wav')# female (rat Arthur)\n",
    "#source3, fs2 = sf.read('test4.wav')# female Harvard\n",
    "\n",
    "# function to resample the signal and pick only one channel\n",
    "def resampled_mono(src,fs,fs2):\n",
    "    return sig.resample_poly(src[:,0] if len(src.shape)>1 else src, fs, fs2)\n",
    "\n",
    "# create list of resampled, mono source signals\n",
    "sources_sigs=[]\n",
    "sources_sigs.append(resampled_mono(source0,fs,fs2))\n",
    "#sources_sigs.append(resampled_mono(source1,fs,fs2))\n",
    "#sources_sigs.append(resampled_mono(source2,fs,fs2))\n",
    "#sources_sigs.append(resampled_mono(source3,fs,fs2))\n",
    "\n",
    "# set levels for all sources (this is level at the source, distance attenuation is applied by convolving with irs):\n",
    "levels=[-45]#,-45,-45,-45] \n",
    "\n",
    "# generate a mixture signal with localized sources\n",
    "mixture_ku=hlp.generate_scenes(sources_sigs,levels,mic_rirs,dec_ku)\n",
    "Audio(mixture_ku, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7f5024",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture_ric=hlp.generate_scenes(sources_sigs,levels,mic_rirs,dec_ric)\n",
    "Audio(mixture_ric, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bc06ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "import scipy.signal as sig\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import mat73\n",
    "import os\n",
    "import masp as srs\n",
    "# import my modules (helpers.py where I stored all the functions):\n",
    "import helpers as hlp\n",
    "import importlib\n",
    "importlib.reload(hlp);\n",
    "# --------------- DESIGN SCENE ----------------\n",
    "room = np.array([4., 4., 3.]) # Room dimensions\n",
    "rt60 = np.array([.2])\n",
    "sources_pos= [[1., 3., 1.6]] # Sources coordinates \n",
    "head_pos= np.array([room[0]/2, room[1]/2, 1.6]) # Listener coordinates\n",
    "head_orient = np.array([0, 0]) # Head rotation in degrees\n",
    "ears_pos=hlp.head_2_ku_ears(head_pos,head_orient)\n",
    "\n",
    "# --------------- PLOT SCENE ----------------\n",
    "hlp.plot_scene(room,head_pos,head_orient,ears_pos,sources_pos,perspective=\"xy\")\n",
    "\n",
    "# --------------- COMPUTE ECHOGRAMS ----------------\n",
    "\n",
    "# some constants:\n",
    "mic_specs = np.array([  [1, 0, 0, 1], [1, 0, 0, 1] ] ) #two omni mics facing to the front\n",
    "fs = 48000 #sampling rate\n",
    "maxlim = 2 # maximum reflection time in seconds. Stop simulating if it goes beyond that time.\n",
    "ambi_order = 10 # ambisonics order\n",
    "rims_d = 0.0 # displacement for Randomized Image Source method. Default is 0.\n",
    "\n",
    "# Compute absorption coefficients for desired rt60 and room dimensions\n",
    "abs_walls,rt60_true = srs.find_abs_coeffs_from_rt(room, rt60)\n",
    "# Small correction for sound absorption coefficients:\n",
    "if sum(rt60_true-rt60>0.05*rt60_true)>0 :\n",
    "    abs_walls,rt60_true = srs.find_abs_coeffs_from_rt(room, rt60_true + abs(rt60-rt60_true))\n",
    "# Generally, we simulate up to RT60:\n",
    "limits = np.minimum(rt60, maxlim)\n",
    "\n",
    "mic = np.array(ears_pos)\n",
    "src = np.array(sources_pos)\n",
    "nRec = mic.shape[0]\n",
    "nSrc = src.shape[0]\n",
    "\n",
    "# Compute the echograms, which means how many reflections, at what time and from which coordinates:\n",
    "abs_echograms = srs.compute_echograms_sh(room, src, mic, abs_walls, limits, ambi_order, rims_d, head_orient)\n",
    "\n",
    "# --------------- RENDER ECHOGRAMS ----------------\n",
    "band_centerfreqs=np.array([1000])\n",
    "mic_rirs = srs.render_rirs_sh(abs_echograms, band_centerfreqs, fs)\n",
    "\n",
    "# --------------- DECODE TO BINAURAL ----------------\n",
    "dec_ku = mat73.loadmat('decoders_ord10/Ku100_ALFE_Window_sinEQ_bimag.mat')['hnm']\n",
    "dec_ku = np.roll(dec_ku,500,axis=0)\n",
    "dec_ric = mat73.loadmat('decoders_ord10/RIC_Front_Omni_ALFE_Window_SinEQ_bimag.mat')['hnm']\n",
    "dec_ric = np.roll(dec_ric,500,axis=0)\n",
    "\n",
    "# Load source signals:\n",
    "source0, fs2 = sf.read('test1.wav')# male\n",
    "#source1, fs2 = sf.read('test2.wav')# child\n",
    "#source2, fs2 = sf.read('test3.wav')# female (rat Arthur)\n",
    "#source3, fs2 = sf.read('test4.wav')# female Harvard\n",
    "\n",
    "# function to resample the signal and pick only one channel\n",
    "def resampled_mono(src,fs,fs2):\n",
    "    return sig.resample_poly(src[:,0] if len(src.shape)>1 else src, fs, fs2)\n",
    "\n",
    "# create list of resampled, mono source signals\n",
    "sources_sigs=[]\n",
    "sources_sigs.append(resampled_mono(source0,fs,fs2))\n",
    "#sources_sigs.append(resampled_mono(source1,fs,fs2))\n",
    "#sources_sigs.append(resampled_mono(source2,fs,fs2))\n",
    "#sources_sigs.append(resampled_mono(source3,fs,fs2))\n",
    "\n",
    "# set levels for all sources (this is level at the source, distance attenuation is applied by convolving with irs):\n",
    "levels=[-45]#,-45,-45,-45] \n",
    "\n",
    "# generate a mixture signal with localized sources\n",
    "mixture_ku=hlp.generate_scenes(sources_sigs,levels,mic_rirs,dec_ku)\n",
    "Audio(mixture_ku, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b5f97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture_ric=hlp.generate_scenes(sources_sigs,levels,mic_rirs,dec_ric)\n",
    "Audio(mixture_ric, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4a1dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LibriMix3D",
   "language": "python",
   "name": "librimix3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
